from flask import Flask, render_template, request
import os

app = Flask(__name__)

# 10ä¸ªé‡‘èåº”ç”¨ä¸»é¢˜
FINANCIAL_TOPICS = [
    {"id": 1, "name": "è‚¡ç¥¨åˆ†æå·¥å…·", "description": "è‚¡ç¥¨æ•°æ®è·å–ã€åˆ†æå’Œå¯è§†åŒ–", "icon": "ğŸ“ˆ"},
    {"id": 2, "name": "é‡åŒ–äº¤æ˜“ç­–ç•¥", "description": "ç®—æ³•äº¤æ˜“å’Œç­–ç•¥å›æµ‹", "icon": "ğŸ¤–"},
    {"id": 3, "name": "é£é™©ç®¡ç†ç³»ç»Ÿ", "description": "é£é™©è¯„ä¼°å’ŒæŠ•èµ„ç»„åˆä¼˜åŒ–", "icon": "ğŸ›¡ï¸"},
    {"id": 4, "name": "è´¢åŠ¡æŠ¥è¡¨åˆ†æ", "description": "è´¢åŠ¡æ•°æ®å¤„ç†å’ŒæŠ¥è¡¨è§£è¯»", "icon": "ğŸ“Š"},
    {"id": 5, "name": "åŠ å¯†è´§å¸åˆ†æ", "description": "åŒºå—é“¾æ•°æ®å’ŒåŠ å¯†è´§å¸è¿½è¸ª", "icon": "â›“ï¸"},
    {"id": 6, "name": "å€ºåˆ¸è®¡ç®—å·¥å…·", "description": "å€ºåˆ¸å®šä»·å’Œæ”¶ç›Šç‡è®¡ç®—", "icon": "ğŸ’µ"},
    {"id": 7, "name": "æˆ¿åœ°äº§æŠ•èµ„åˆ†æ", "description": "æˆ¿äº§ä¼°å€¼å’ŒæŠ•èµ„å›æŠ¥è®¡ç®—", "icon": "ğŸ "},
    {"id": 8, "name": "é‡‘èé£é™©ç®¡ç†", "description": "VaRè®¡ç®—å’Œé£é™©åº¦é‡", "icon": "ğŸ“‰"},
    {"id": 9, "name": "å¤–æ±‡äº¤æ˜“ç³»ç»Ÿ", "description": "æ±‡ç‡åˆ†æå’Œäº¤æ˜“ä¿¡å·", "icon": "ğŸ’±"},
    {"id": 10, "name": "æ•°æ®åˆ†æå¯è§†åŒ–", "description": "é‡‘èæ•°æ®å¯è§†åŒ–å’Œå›¾è¡¨", "icon": "ğŸ¨"}
]

# æ¯ä¸ªä¸»é¢˜ä¸‹çš„6ä¸ªåˆ†ç±»
TOPIC_CATEGORIES = [
    {"id": 1, "name": "æ•°æ®è·å–", "description": "å¦‚ä½•ä»å„ç§APIè·å–é‡‘èæ•°æ®"},
    {"id": 2, "name": "æ•°æ®å¤„ç†", "description": "é‡‘èæ•°æ®çš„æ¸…æ´—å’Œé¢„å¤„ç†"},
    {"id": 3, "name": "æ•°æ®åˆ†æ", "description": "ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•åˆ†æé‡‘èæ•°æ®"},
    {"id": 4, "name": "å¯è§†åŒ–", "description": "é‡‘èæ•°æ®çš„å›¾è¡¨å±•ç¤º"},
    {"id": 5, "name": "æœºå™¨å­¦ä¹ ", "description": "AIåœ¨é‡‘èåˆ†æä¸­çš„åº”ç”¨"},
    {"id": 6, "name": "å®æˆ˜æ¡ˆä¾‹", "description": "å®Œæ•´çš„é‡‘èåº”ç”¨é¡¹ç›®æ¡ˆä¾‹"}
]

# ç¤ºä¾‹ä»£ç æ•°æ®
EXAMPLE_CODES = [
    # ä¸»é¢˜5ï¼šåŠ å¯†è´§å¸åˆ†æ
    {
        "topic_id": 5,
        "category_id": 1,
        "title": "åŠ å¯†è´§å¸å¸‚åœºæ•°æ®è·å–",
        "code": """import requests
import pandas as pd
from datetime import datetime

def get_crypto_prices(symbol, start_date, end_date):
    \"\"\"ä½¿ç”¨CoinGecko APIè·å–åŠ å¯†è´§å¸ä»·æ ¼æ•°æ®\"\"\"
    try:
        # æ„å»ºAPIè¯·æ±‚URL
        url = f\"https://api.coingecko.com/api/v3/coins/{symbol}/market_chart/range\"
        params = {
            "vs_currency": "usd",
            "from": int(datetime.strptime(start_date, "%Y-%m-%d").timestamp()),
            "to": int(datetime.strptime(end_date, "%Y-%m-%d").timestamp())
        }

        response = requests.get(url, params=params)
        data = response.json()

        # è½¬æ¢æ•°æ®æ ¼å¼
        prices = data['prices']
        df = pd.DataFrame(prices, columns=['timestamp', 'price'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        return df

    except Exception as e:
        print(f\"è·å–{symbol}ä»·æ ¼æ•°æ®å¤±è´¥: {str(e)}\")
        return pd.DataFrame()

def get_crypto_ohlc(symbol, days=30):
    \"\"\"è·å–åŠ å¯†è´§å¸OHLCæ•°æ®\"\"\"
    try:
        url = f\"https://api.coingecko.com/api/v3/coins/{symbol}/ohlc\"
        params = {
            "vs_currency": "usd",
            "days": days
        }

        response = requests.get(url, params=params)
        data = response.json()

        # è½¬æ¢æ•°æ®æ ¼å¼
        df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        return df

    except Exception as e:
        print(f\"è·å–{symbol}OHLCæ•°æ®å¤±è´¥: {str(e)}\")
        return pd.DataFrame()

def get_crypto_listings():
    \"\"\"è·å–åŠ å¯†è´§å¸åˆ—è¡¨\"\"\"
    try:
        url = \"https://api.coingecko.com/api/v3/coins/markets\"
        params = {
            "vs_currency": "usd",
            "order": "market_cap_desc",
            "per_page": 50,
            "page": 1,
            "sparkline": False,
            "price_change_percentage": "24h"
        }

        response = requests.get(url, params=params)
        data = response.json()

        df = pd.DataFrame(data)
        return df[['id', 'symbol', 'name', 'current_price', 'market_cap',
                   'total_volume', 'price_change_percentage_24h']]

    except Exception as e:
        print(f\"è·å–åŠ å¯†è´§å¸åˆ—è¡¨å¤±è´¥: {str(e)}\")
        return pd.DataFrame()

# ä½¿ç”¨ç¤ºä¾‹
# è·å–Bitcoinä»·æ ¼æ•°æ®ï¼ˆ2024å¹´ï¼‰
bitcoin_prices = get_crypto_prices('bitcoin', '2024-01-01', '2024-04-09')
print(\"Bitcoinä»·æ ¼æ•°æ®:\\n\", bitcoin_prices.head())

# è·å–Bitcoin OHLCæ•°æ®ï¼ˆæœ€è¿‘30å¤©ï¼‰
bitcoin_ohlc = get_crypto_ohlc('bitcoin', 30)
print(\"\\nBitcoin OHLCæ•°æ®:\\n\", bitcoin_ohlc.head())

# è·å–åŠ å¯†è´§å¸åˆ—è¡¨ï¼ˆTop 10ï¼‰
crypto_listings = get_crypto_listings()
print(\"\\nTop 10åŠ å¯†è´§å¸åˆ—è¡¨:\\n\", crypto_listings.head(10))
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨CoinGecko APIè·å–åŠ å¯†è´§å¸çš„ä»·æ ¼æ•°æ®ã€OHLCæ•°æ®å’ŒåŠ å¯†è´§å¸åˆ—è¡¨ã€‚è·å–é«˜è´¨é‡çš„åŠ å¯†è´§å¸æ•°æ®æ˜¯åˆ†æå’Œç­–ç•¥å¼€å‘çš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 5,
        "category_id": 2,
        "title": "åŠ å¯†è´§å¸æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np

def preprocess_crypto_data(df):
    \"\"\"åŠ å¯†è´§å¸æ•°æ®é¢„å¤„ç†\"\"\"

    # æ£€æŸ¥å’Œå¤„ç†ç¼ºå¤±å€¼
    if df.isnull().any().any():
        print(\"å­˜åœ¨ç¼ºå¤±å€¼ï¼Œä½¿ç”¨å‰å‘å¡«å……æ–¹æ³•å¤„ç†\")
        df = df.fillna(method='ffill')

    # è®¡ç®—æ”¶ç›Šç‡
    df['return'] = df['price'].pct_change()

    # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
    df['log_return'] = np.log(df['price'] / df['price'].shift(1))

    # è®¡ç®—æ³¢åŠ¨ç‡
    df['volatility'] = df['return'].rolling(window=24).std() * np.sqrt(24)  # æ—¥æ³¢åŠ¨ç‡

    # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    df['ma_7'] = df['price'].rolling(window=7).mean()
    df['ma_30'] = df['price'].rolling(window=30).mean()
    df['ma_90'] = df['price'].rolling(window=90).mean()

    # è®¡ç®—RSIæŒ‡æ ‡
    delta = df['price'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))

    # è®¡ç®—å¸ƒæ—å¸¦
    df['bb_mid'] = df['ma_30']
    df['bb_upper'] = df['ma_30'] + 2 * df['price'].rolling(window=30).std()
    df['bb_lower'] = df['ma_30'] - 2 * df['price'].rolling(window=30).std()

    return df

def merge_multiple_crypto_data(data_list, symbols):
    \"\"\"åˆå¹¶å¤šä¸ªåŠ å¯†è´§å¸çš„æ•°æ®\"\"\"

    merged_data = pd.DataFrame()

    for df, symbol in zip(data_list, symbols):
        df_processed = preprocess_crypto_data(df)

        # é‡å‘½ååˆ—
        renamed_columns = {
            'price': f'{symbol}_price',
            'return': f'{symbol}_return',
            'log_return': f'{symbol}_log_return',
            'volatility': f'{symbol}_volatility',
            'ma_7': f'{symbol}_ma_7',
            'ma_30': f'{symbol}_ma_30',
            'ma_90': f'{symbol}_ma_90',
            'rsi': f'{symbol}_rsi',
            'bb_mid': f'{symbol}_bb_mid',
            'bb_upper': f'{symbol}_bb_upper',
            'bb_lower': f'{symbol}_bb_lower'
        }

        df_renamed = df_processed.rename(columns=renamed_columns)

        if merged_data.empty:
            merged_data = df_renamed
        else:
            merged_data = merged_data.join(df_renamed, how='outer')

    return merged_data

def clean_outliers(df):
    \"\"\"æ¸…ç†å¼‚å¸¸å€¼\"\"\"

    # ä½¿ç”¨3å€æ ‡å‡†å·®æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    for column in df.select_dtypes(include=['float64']).columns:
        mean = df[column].mean()
        std = df[column].std()

        # å®šä¹‰å¼‚å¸¸å€¼é˜ˆå€¼
        lower_threshold = mean - 3 * std
        upper_threshold = mean + 3 * std

        # æ›¿æ¢å¼‚å¸¸å€¼
        df[column] = np.where(df[column] < lower_threshold, lower_threshold, df[column])
        df[column] = np.where(df[column] > upper_threshold, upper_threshold, df[column])

    return df

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»è·å–æ•°æ®ï¼‰
# bitcoin_processed = preprocess_crypto_data(bitcoin_prices)
# print(\"é¢„å¤„ç†åçš„Bitcoinæ•°æ®:\\n\", bitcoin_processed.head())
#
# # åˆå¹¶å¤šä¸ªåŠ å¯†è´§å¸æ•°æ®
# ethereum_prices = get_crypto_prices('ethereum', '2024-01-01', '2024-04-09')
# merged_data = merge_multiple_crypto_data([bitcoin_prices, ethereum_prices], ['bitcoin', 'ethereum'])
# print(\"\\nåˆå¹¶åçš„åŠ å¯†è´§å¸æ•°æ®:\\n\", merged_data.head())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹åŠ å¯†è´§å¸æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€ç¼ºå¤±å€¼å¤„ç†ã€è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç­‰ã€‚åŠ å¯†è´§å¸æ•°æ®é¢„å¤„ç†æ˜¯è¿›è¡Œåˆ†æçš„å¿…è¦æ­¥éª¤ã€‚"
    },
    {
        "topic_id": 5,
        "category_id": 3,
        "title": "åŠ å¯†è´§å¸æ•°æ®åˆ†æ",
        "code": """import pandas as pd
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_crypto_returns(returns):
    \"\"\"åˆ†æåŠ å¯†è´§å¸æ”¶ç›Šç‡\"\"\"

    returns = returns.dropna()

    summary_stats = {
        "å‡å€¼": returns.mean(),
        "æ ‡å‡†å·®": returns.std(),
        "ååº¦": returns.skew(),
        "å³°åº¦": returns.kurt(),
        "æœ€å°å€¼": returns.min(),
        "æœ€å¤§å€¼": returns.max()
    }

    return pd.Series(summary_stats)

def calculate_var(returns, confidence_level=0.95):
    \"\"\"è®¡ç®—VaRå€¼ï¼ˆé£é™©ä»·å€¼ï¼‰\"\"\"

    returns = returns.dropna()

    # ä½¿ç”¨å‚æ•°æ³•è®¡ç®—VaR
    mean = returns.mean()
    std = returns.std()
    z_score = norm.ppf(1 - confidence_level)
    var = mean + z_score * std

    # ä½¿ç”¨å†å²æ³•è®¡ç®—VaR
    var_historical = np.percentile(returns, (1 - confidence_level) * 100)

    return var, var_historical

def calculate_cvar(returns, confidence_level=0.95):
    \"\"\"è®¡ç®—CVaRå€¼ï¼ˆæ¡ä»¶é£é™©ä»·å€¼ï¼‰\"\"\"

    returns = returns.dropna()

    # ä½¿ç”¨å‚æ•°æ³•è®¡ç®—CVaR
    mean = returns.mean()
    std = returns.std()
    z_score = norm.ppf(1 - confidence_level)
    cvar = mean + (norm.pdf(z_score) / (1 - confidence_level)) * std

    # ä½¿ç”¨å†å²æ³•è®¡ç®—CVaR
    var_historical = np.percentile(returns, (1 - confidence_level) * 100)
    cvar_historical = returns[returns <= var_historical].mean()

    return cvar, cvar_historical

def analyze_correlation(data):
    \"\"\"åˆ†æåŠ å¯†è´§å¸ä¹‹é—´çš„ç›¸å…³æ€§\"\"\"

    # é€‰æ‹©ä»·æ ¼åˆ—
    price_columns = [col for col in data.columns if 'price' in col]
    prices = data[price_columns]

    # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
    correlation_matrix = prices.corr()

    return correlation_matrix

def plot_correlation_matrix(correlation_matrix):
    \"\"\"ç»˜åˆ¶ç›¸å…³ç³»æ•°çŸ©é˜µ\"\"\"

    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('åŠ å¯†è´§å¸ä»·æ ¼ç›¸å…³ç³»æ•°çŸ©é˜µ')
    plt.tight_layout()
    plt.savefig('crypto_correlation.png')
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼‰
# # è®¡ç®—æ”¶ç›Šç‡ç»Ÿè®¡
# bitcoin_returns_stats = analyze_crypto_returns(bitcoin_processed['return'])
# print(\"Bitcoinæ”¶ç›Šç‡ç»Ÿè®¡:\\n\", bitcoin_returns_stats)
#
# # è®¡ç®—VaRå’ŒCVaR
# var_param, var_hist = calculate_var(bitcoin_processed['return'])
# cvar_param, cvar_hist = calculate_cvar(bitcoin_processed['return'])
# print(f\"\\nVaR (å‚æ•°æ³•): {var_param:.4f}\")
# print(f\"VaR (å†å²æ³•): {var_hist:.4f}\")
# print(f\"CVaR (å‚æ•°æ³•): {cvar_param:.4f}\")
# print(f\"CVaR (å†å²æ³•): {cvar_hist:.4f}\")
#
# # åˆ†æç›¸å…³æ€§
# correlation_matrix = analyze_correlation(merged_data)
# print(\"\\nåŠ å¯†è´§å¸ä»·æ ¼ç›¸å…³ç³»æ•°çŸ©é˜µ:\\n\", correlation_matrix)
#
# # ç»˜åˆ¶ç›¸å…³ç³»æ•°çŸ©é˜µ
# plot_correlation_matrix(correlation_matrix)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹åŠ å¯†è´§å¸æ•°æ®è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬æ”¶ç›Šç‡ç»Ÿè®¡ã€VaRå’ŒCVaRè®¡ç®—ï¼Œä»¥åŠåŠ å¯†è´§å¸ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æã€‚è¿™äº›åˆ†æå¸®åŠ©æˆ‘ä»¬ç†è§£åŠ å¯†è´§å¸å¸‚åœºçš„é£é™©å’Œç‰¹å¾ã€‚"
    },
    {
        "topic_id": 5,
        "category_id": 4,
        "title": "åŠ å¯†è´§å¸æ•°æ®å¯è§†åŒ–",
        "code": """import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_crypto_price(df, title='åŠ å¯†è´§å¸ä»·æ ¼èµ°åŠ¿', filename='crypto_price_plot.png'):
    \"\"\"ç»˜åˆ¶åŠ å¯†è´§å¸ä»·æ ¼èµ°åŠ¿\"\"\"

    plt.figure(figsize=(12, 6))
    plt.plot(df['timestamp'], df['price'])
    plt.title(title)
    plt.xlabel('æ—¶é—´')
    plt.ylabel('ä»·æ ¼ (USD)')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

def plot_crypto_returns(returns, title='åŠ å¯†è´§å¸æ”¶ç›Šç‡åˆ†å¸ƒ', filename='crypto_returns_plot.png'):
    \"\"\"ç»˜åˆ¶åŠ å¯†è´§å¸æ”¶ç›Šç‡åˆ†å¸ƒ\"\"\"

    plt.figure(figsize=(10, 6))
    sns.histplot(returns.dropna(), kde=True, bins=50)
    plt.title(title)
    plt.xlabel('æ”¶ç›Šç‡')
    plt.ylabel('é¢‘ç‡')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

def plot_rolling_statistics(df, column='price', window=30, filename='rolling_stats_plot.png'):
    \"\"\"ç»˜åˆ¶æ»šåŠ¨ç»Ÿè®¡æŒ‡æ ‡\"\"\"

    plt.figure(figsize=(12, 8))

    # ä»·æ ¼
    plt.subplot(3, 1, 1)
    plt.plot(df['timestamp'], df[column])
    plt.title('ä»·æ ¼')
    plt.grid(True)

    # æ»šåŠ¨æ³¢åŠ¨ç‡
    plt.subplot(3, 1, 2)
    plt.plot(df['timestamp'], df['volatility'])
    plt.title(f'{window}æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡')
    plt.grid(True)

    # RSI
    plt.subplot(3, 1, 3)
    plt.plot(df['timestamp'], df['rsi'])
    plt.axhline(y=30, color='g', linestyle='--', label='è¶…å–')
    plt.axhline(y=70, color='r', linestyle='--', label='è¶…ä¹°')
    plt.title('RSIæŒ‡æ ‡')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

def plot_candlestick_chart(ohlc_data, filename='candlestick_plot.png'):
    \"\"\"ç»˜åˆ¶èœ¡çƒ›å›¾\"\"\"

    # åˆ›å»ºèœ¡çƒ›å›¾
    fig, ax = plt.subplots(figsize=(12, 6))

    # ç»˜åˆ¶èœ¡çƒ›å›¾ä¸»ä½“
    colors = ['g' if close >= open else 'r' for close, open in zip(ohlc_data['close'], ohlc_data['open'])]
    ax.bar(ohlc_data.index, ohlc_data['close'] - ohlc_data['open'], width=0.6, bottom=ohlc_data['open'], color=colors)

    # ç»˜åˆ¶å½±çº¿
    ax.vlines(ohlc_data.index, ohlc_data['low'], ohlc_data['high'], color=colors)

    plt.title('åŠ å¯†è´§å¸èœ¡çƒ›å›¾')
    plt.xlabel('æ—¶é—´')
    plt.ylabel('ä»·æ ¼ (USD)')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

def plot_multiple_cryptos(data, symbols, filename='multiple_cryptos_plot.png'):
    \"\"\"ç»˜åˆ¶å¤šä¸ªåŠ å¯†è´§å¸çš„ä»·æ ¼èµ°åŠ¿\"\"

    plt.figure(figsize=(12, 6))

    for symbol in symbols:
        plt.plot(data['timestamp'], data[f'{symbol}_price'], label=symbol)

    plt.title('åŠ å¯†è´§å¸ä»·æ ¼æ¯”è¾ƒ')
    plt.xlabel('æ—¶é—´')
    plt.ylabel('ä»·æ ¼ (USD)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»è·å–æ•°æ®ï¼‰
# # ç»˜åˆ¶Bitcoinä»·æ ¼èµ°åŠ¿
# plot_crypto_price(bitcoin_prices, 'Bitcoinä»·æ ¼èµ°åŠ¿', 'bitcoin_price_plot.png')
#
# # ç»˜åˆ¶æ”¶ç›Šç‡åˆ†å¸ƒ
# plot_crypto_returns(bitcoin_processed['return'], 'Bitcoinæ”¶ç›Šç‡åˆ†å¸ƒ', 'bitcoin_returns_plot.png')
#
# # ç»˜åˆ¶æ»šåŠ¨ç»Ÿè®¡æŒ‡æ ‡
# plot_rolling_statistics(bitcoin_processed, filename='bitcoin_rolling_stats.png')
#
# # ç»˜åˆ¶èœ¡çƒ›å›¾
# plot_candlestick_chart(bitcoin_ohlc, 'bitcoin_candlestick_plot.png')
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹åŠ å¯†è´§å¸æ•°æ®è¿›è¡Œå¯è§†åŒ–ï¼ŒåŒ…æ‹¬ä»·æ ¼èµ°åŠ¿ã€æ”¶ç›Šç‡åˆ†å¸ƒã€æ»šåŠ¨ç»Ÿè®¡æŒ‡æ ‡ã€èœ¡çƒ›å›¾å’Œå¤šä¸ªåŠ å¯†è´§å¸çš„ä»·æ ¼æ¯”è¾ƒã€‚å¯è§†åŒ–å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£åŠ å¯†è´§å¸å¸‚åœºçš„è¶‹åŠ¿å’Œæ¨¡å¼ã€‚"
    },
    {
        "topic_id": 5,
        "category_id": 5,
        "title": "åŠ å¯†è´§å¸æœºå™¨å­¦ä¹ ",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

def create_features(df):
    \"\"\"åˆ›å»ºç‰¹å¾\"\"\"

    features = df[['volatility', 'ma_7', 'ma_30', 'ma_90', 'rsi', 'bb_mid', 'bb_upper', 'bb_lower']]

    return features

def create_target(df, days_ahead=1):
    \"\"\"åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆæœªæ¥ä»·æ ¼å˜åŒ–ï¼‰\"\"

    target = df['price'].shift(-days_ahead) - df['price']
    return target

def prepare_data(df, days_ahead=1):
    \"\"\"å‡†å¤‡æ•°æ®\"\"

    features = create_features(df)
    target = create_target(df, days_ahead)

    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
    full_data = pd.concat([features, target], axis=1)
    full_data = full_data.dropna()

    X = full_data.iloc[:, :-1]
    y = full_data.iloc[:, -1]

    return X, y

def train_model(X_train, y_train, model_type='random_forest'):
    \"\"\"è®­ç»ƒæ¨¡å‹\"\"\"

    if model_type == 'random_forest':
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    elif model_type == 'linear_regression':
        model = LinearRegression()
    else:
        raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}\")

    model.fit(X_train, y_train)

    return model

def evaluate_model(model, X_test, y_test):
    \"\"\"è¯„ä¼°æ¨¡å‹\"\"

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    return mse, rmse, r2

def plot_predictions(y_test, y_pred, filename='predictions_plot.png'):
    \"\"\"ç»˜åˆ¶é¢„æµ‹ç»“æœ\"\"

    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.title('æ¨¡å‹é¢„æµ‹ vs å®é™…å€¼')
    plt.xlabel('å®é™…å€¼')
    plt.ylabel('é¢„æµ‹å€¼')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼‰
# # å‡†å¤‡æ•°æ®
# X, y = prepare_data(bitcoin_processed)
#
# # åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#
# # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
# rf_model = train_model(X_train, y_train, 'random_forest')
#
# # è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹
# lr_model = train_model(X_train, y_train, 'linear_regression')
#
# # è¯„ä¼°æ¨¡å‹
# rf_mse, rf_rmse, rf_r2 = evaluate_model(rf_model, X_test, y_test)
# lr_mse, lr_rmse, lr_r2 = evaluate_model(lr_model, X_test, y_test)
#
# print(f\"éšæœºæ£®æ—æ¨¡å‹ - MSE: {rf_mse:.4f}, RMSE: {rf_rmse:.4f}, RÂ²: {rf_r2:.4f}\")
# print(f\"çº¿æ€§å›å½’æ¨¡å‹ - MSE: {lr_mse:.4f}, RMSE: {lr_rmse:.4f}, RÂ²: {lr_r2:.4f}\")
#
# # ç»˜åˆ¶éšæœºæ£®æ—æ¨¡å‹çš„é¢„æµ‹ç»“æœ
# rf_pred = rf_model.predict(X_test)
# plot_predictions(y_test, rf_pred, 'rf_predictions_plot.png')
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•é¢„æµ‹åŠ å¯†è´§å¸ä»·æ ¼å˜åŒ–ï¼ŒåŒ…æ‹¬ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚æœºå™¨å­¦ä¹ å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯†åˆ«åŠ å¯†è´§å¸å¸‚åœºçš„æ¨¡å¼å’Œè¶‹åŠ¿ã€‚"
    },
    {
        "topic_id": 5,
        "category_id": 6,
        "title": "åŠ å¯†è´§å¸äº¤æ˜“ç­–ç•¥",
        "code": """import pandas as pd
import numpy as np

class TradingStrategy:
    def __init__(self, data, initial_capital=10000):
        self.data = data
        self.initial_capital = initial_capital
        self.positions = pd.Series(index=data.index, dtype=int)
        self.portfolio = pd.DataFrame(index=data.index)

    def generate_signals(self):
        \"\"\"ç”Ÿæˆäº¤æ˜“ä¿¡å·\"\"\"
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°generate_signalsæ–¹æ³•")

    def backtest(self):
        \"\"\"å›æµ‹ç­–ç•¥\"\"\"

        # è®¡ç®—ä»·æ ¼
        prices = self.data['price']

        # è®¡ç®—æ¯æ—¥æ”¶ç›Š
        self.portfolio['Price'] = prices

        # åˆå§‹åŒ–æŠ•èµ„ç»„åˆä»·å€¼
        self.portfolio['Cash'] = self.initial_capital
        self.portfolio['Holdings'] = 0.0
        self.portfolio['Total'] = self.initial_capital

        for i in range(len(prices)):
            date = prices.index[i]

            # è®¡ç®—æŒæœ‰çš„è´§å¸æ•°é‡
            if self.positions[date] == 1:
                # ä¹°å…¥
                shares_to_buy = int(self.portfolio['Cash'][date] / prices[date])
                cost = shares_to_buy * prices[date]
                self.portfolio['Holdings'][date] = shares_to_buy
                self.portfolio['Cash'][date] -= cost
            elif self.positions[date] == -1:
                # å–å‡º
                shares_to_sell = int(self.portfolio['Holdings'][date])
                revenue = shares_to_sell * prices[date]
                self.portfolio['Cash'][date] += revenue
                self.portfolio['Holdings'][date] = 0

            # è®¡ç®—æŠ•èµ„ç»„åˆæ€»ä»·å€¼
            self.portfolio['Total'][date] = self.portfolio['Cash'][date] + self.portfolio['Holdings'][date] * prices[date]

        # è®¡ç®—æ”¶ç›Šç‡
        self.portfolio['Return'] = self.portfolio['Total'].pct_change()

        return self.portfolio

    def calculate_performance_metrics(self):
        \"\"\"è®¡ç®—ç­–ç•¥ç»©æ•ˆæŒ‡æ ‡\"\"

        # è®¡ç®—æ€»å›æŠ¥
        total_return = (self.portfolio['Total'][-1] - self.initial_capital) / self.initial_capital

        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        num_years = len(self.portfolio) / 365
        annual_return = (1 + total_return) ** (1 / num_years) - 1

        # è®¡ç®—æœ€å¤§å›æ’¤
        cumulative_returns = (1 + self.portfolio['Return']).cumprod()
        peak = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = drawdown.min()

        # è®¡ç®—å¤æ™®æ¯”ç‡
        sharpe_ratio = self.portfolio['Return'].mean() / self.portfolio['Return'].std() * np.sqrt(365)

        performance_metrics = {
            'æ€»å›æŠ¥': total_return,
            'å¹´åŒ–æ”¶ç›Šç‡': annual_return,
            'æœ€å¤§å›æ’¤': max_drawdown,
            'å¤æ™®æ¯”ç‡': sharpe_ratio
        }

        return performance_metrics

class MovingAverageStrategy(TradingStrategy):
    def generate_signals(self):
        \"\"\"ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥\"\"\"

        signals = pd.Series(0, index=self.data.index)

        # å½“çŸ­æœŸå‡çº¿çªç ´é•¿æœŸå‡çº¿æ—¶ä¹°å…¥
        signals[self.data['ma_7'] > self.data['ma_30']] = 1

        # å½“çŸ­æœŸå‡çº¿è·Œç ´é•¿æœŸå‡çº¿æ—¶å–å‡º
        signals[self.data['ma_7'] < self.data['ma_30']] = -1

        self.positions = signals

        return signals

class RSIStrategy(TradingStrategy):
    def generate_signals(self):
        \"\"\"RSIç­–ç•¥\"\"\"

        signals = pd.Series(0, index=self.data.index)

        # å½“RSIä½äº30æ—¶ä¹°å…¥
        signals[self.data['rsi'] < 30] = 1

        # å½“RSIé«˜äº70æ—¶å–å‡º
        signals[self.data['rsi'] > 70] = -1

        self.positions = signals

        return signals

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼‰
# # ä½¿ç”¨ç§»åŠ¨å¹³å‡ç­–ç•¥
# strategy = MovingAverageStrategy(bitcoin_processed)
# strategy.generate_signals()
# portfolio = strategy.backtest()
#
# # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
# performance_metrics = strategy.calculate_performance_metrics()
# print(\"ç§»åŠ¨å¹³å‡ç­–ç•¥ç»©æ•ˆæŒ‡æ ‡:\\n\", performance_metrics)
#
# # ä½¿ç”¨RSIç­–ç•¥
# strategy = RSIStrategy(bitcoin_processed)
# strategy.generate_signals()
# portfolio = strategy.backtest()
#
# # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
# performance_metrics = strategy.calculate_performance_metrics()
# print(\"\\nRSIç­–ç•¥ç»©æ•ˆæŒ‡æ ‡:\\n\", performance_metrics)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å®ç°åŠ å¯†è´§å¸äº¤æ˜“ç­–ç•¥ï¼ŒåŒ…æ‹¬ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥å’ŒRSIç­–ç•¥ã€‚å›æµ‹åŠŸèƒ½å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯„ä¼°ç­–ç•¥çš„å†å²è¡¨ç°ã€‚"
    },
    # ä¸»é¢˜4ï¼šè´¢åŠ¡æŠ¥è¡¨åˆ†æ
    {
        "topic_id": 4,
        "category_id": 1,
        "title": "è´¢åŠ¡æŠ¥è¡¨æ•°æ®è·å–",
        "code": """import pandas as pd
import numpy as np
import requests
from io import StringIO
import yfinance as yf

def get_income_statement(ticker):
    \"\"\"è·å–å…¬å¸åˆ©æ¶¦è¡¨æ•°æ®\"\"\"
    try:
        stock = yf.Ticker(ticker)
        income_stmt = stock.income_stmt
        return income_stmt
    except Exception as e:
        print(f"Error fetching income statement for {ticker}: {e}")
        return pd.DataFrame()

def get_balance_sheet(ticker):
    \"\"\"è·å–å…¬å¸èµ„äº§è´Ÿå€ºè¡¨æ•°æ®\"\"\"
    try:
        stock = yf.Ticker(ticker)
        balance_sheet = stock.balance_sheet
        return balance_sheet
    except Exception as e:
        print(f"Error fetching balance sheet for {ticker}: {e}")
        return pd.DataFrame()

def get_cash_flow(ticker):
    \"\"\"è·å–å…¬å¸ç°é‡‘æµé‡è¡¨æ•°æ®\"\"\"
    try:
        stock = yf.Ticker(ticker)
        cash_flow = stock.cashflow
        return cash_flow
    except Exception as e:
        print(f"Error fetching cash flow for {ticker}: {e}")
        return pd.DataFrame()

def get_financial_ratios(ticker):
    \"\"\"è·å–å…¬å¸è´¢åŠ¡æ¯”ç‡æ•°æ®\"\"\"
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        return info
    except Exception as e:
        print(f"Error fetching financial ratios for {ticker}: {e}")
        return {}

# ä½¿ç”¨ç¤ºä¾‹
ticker = "AAPL"

# è·å–ä¸‰å¤§è´¢åŠ¡æŠ¥è¡¨
income_statement = get_income_statement(ticker)
balance_sheet = get_balance_sheet(ticker)
cash_flow = get_cash_flow(ticker)

# è·å–è´¢åŠ¡æ¯”ç‡
financial_ratios = get_financial_ratios(ticker)

# æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
print(f"\\nåˆ©æ¶¦è¡¨å½¢çŠ¶: {income_statement.shape}")
print(f"èµ„äº§è´Ÿå€ºè¡¨å½¢çŠ¶: {balance_sheet.shape}")
print(f"ç°é‡‘æµé‡è¡¨å½¢çŠ¶: {cash_flow.shape}")
print(f"è´¢åŠ¡æ¯”ç‡æ•°é‡: {len(financial_ratios)}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨yfinanceåº“è·å–å…¬å¸çš„ä¸‰å¤§è´¢åŠ¡æŠ¥è¡¨ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰å’Œè´¢åŠ¡æ¯”ç‡æ•°æ®ã€‚è´¢åŠ¡æŠ¥è¡¨åˆ†æçš„åŸºç¡€æ˜¯å‡†ç¡®çš„æ•°æ®è·å–ã€‚"
    },
    {
        "topic_id": 4,
        "category_id": 2,
        "title": "è´¢åŠ¡æŠ¥è¡¨æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np

def preprocess_financial_data(income_statement, balance_sheet, cash_flow):
    \"\"\"é¢„å¤„ç†è´¢åŠ¡æŠ¥è¡¨æ•°æ®\"\"\"
    # ç»Ÿä¸€æ•°æ®æ ¼å¼
    for df in [income_statement, balance_sheet, cash_flow]:
        if not df.empty:
            df.index = df.index.map(lambda x: x.lower().replace(" ", "_"))
            df.columns = df.columns.map(lambda x: x.year)

    return income_statement, balance_sheet, cash_flow

def remove_outliers(data, threshold=3):
    \"\"\"ç§»é™¤å¼‚å¸¸å€¼\"\"\"
    if data.empty:
        return data

    z_scores = np.abs((data - data.mean()) / data.std())
    return data[(z_scores < threshold).all(axis=1)]

def standardize_data(data):
    \"\"\"æ ‡å‡†åŒ–è´¢åŠ¡æ•°æ®\"\"\"
    if data.empty:
        return data

    # å¯¹æ¯ä¸€åˆ—è¿›è¡Œæ ‡å‡†åŒ–
    result = data.copy()
    for column in data.columns:
        if data[column].dtype in ['float64', 'int64']:
            mean = data[column].mean()
            std = data[column].std()
            if std > 0:
                result[column] = (data[column] - mean) / std

    return result

def calculate_growth_rates(data):
    \"\"\"è®¡ç®—å¢é•¿ç‡\"\"\"
    if data.empty:
        return data

    # å¯¹æ¯ä¸€è¡Œï¼ˆæŒ‡æ ‡ï¼‰è®¡ç®—å¹´åº¦å¢é•¿ç‡
    growth_data = data.copy()
    for index in data.index:
        for i in range(1, len(data.columns)):
            if data.at[index, data.columns[i]] and data.at[index, data.columns[i-1]]:
                growth_rate = ((data.at[index, data.columns[i]] - data.at[index, data.columns[i-1]]) /
                              abs(data.at[index, data.columns[i-1]])) * 100
                growth_data.at[index, data.columns[i]] = growth_rate

    return growth_data

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾ä¹‹å‰å·²è·å–æ•°æ®ï¼‰
# income_statement, balance_sheet, cash_flow = preprocess_financial_data(income_statement, balance_sheet, cash_flow)
# income_statement_no_outliers = remove_outliers(income_statement)
# standard_income = standardize_data(income_statement_no_outliers)
# income_growth = calculate_growth_rates(income_statement_no_outliers)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹è´¢åŠ¡æŠ¥è¡¨æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ•°æ®æ ¼å¼åŒ–ã€å¼‚å¸¸å€¼å¤„ç†ã€æ ‡å‡†åŒ–å’Œå¢é•¿ç‡è®¡ç®—ã€‚æ•°æ®é¢„å¤„ç†æ˜¯è´¢åŠ¡æŠ¥è¡¨åˆ†æçš„å…³é”®æ­¥éª¤ã€‚"
    },
    {
        "topic_id": 4,
        "category_id": 3,
        "title": "è´¢åŠ¡æŒ‡æ ‡è®¡ç®—",
        "code": """import pandas as pd
import numpy as np

class FinancialRatioCalculator:
    def __init__(self, income_statement, balance_sheet, cash_flow):
        self.income = income_statement
        self.balance = balance_sheet
        self.cash_flow = cash_flow

    def calculate_profitability_ratios(self, year):
        \"\"\"è®¡ç®—ç›ˆåˆ©èƒ½åŠ›æ¯”ç‡\"\"\"
        ratios = {}

        if not self.income.empty and year in self.income.columns:
            # æ¯›åˆ©ç‡
            if "gross_profit" in self.income.index and "total_revenue" in self.income.index:
                ratios["gross_margin"] = (self.income.at["gross_profit", year] /
                                       self.income.at["total_revenue", year]) * 100

            # å‡€åˆ©æ¶¦ç‡
            if "net_income" in self.income.index and "total_revenue" in self.income.index:
                ratios["net_profit_margin"] = (self.income.at["net_income", year] /
                                             self.income.at["total_revenue", year]) * 100

            # æ€»èµ„äº§æ”¶ç›Šç‡
            if "net_income" in self.income.index and "total_assets" in self.balance.index:
                avg_assets = (self.balance.at["total_assets", year] +
                            self.balance.at["total_assets", year - 1]) / 2
                ratios["roa"] = (self.income.at["net_income", year] / avg_assets) * 100

            # è‚¡ä¸œæƒç›Šæ”¶ç›Šç‡
            if "net_income" in self.income.index and "total_stockholder_equity" in self.balance.index:
                avg_equity = (self.balance.at["total_stockholder_equity", year] +
                            self.balance.at["total_stockholder_equity", year - 1]) / 2
                ratios["roe"] = (self.income.at["net_income", year] / avg_equity) * 100

        return ratios

    def calculate_liquidity_ratios(self, year):
        \"\"\"è®¡ç®—æµåŠ¨æ€§æ¯”ç‡\"\"\"
        ratios = {}

        if not self.balance.empty and year in self.balance.columns:
            # æµåŠ¨æ¯”ç‡
            if "total_current_assets" in self.balance.index and "total_current_liabilities" in self.balance.index:
                ratios["current_ratio"] = (self.balance.at["total_current_assets", year] /
                                          self.balance.at["total_current_liabilities", year])

            # é€ŸåŠ¨æ¯”ç‡
            if ("total_current_assets" in self.balance.index and
                "inventory" in self.balance.index and
                "total_current_liabilities" in self.balance.index):
                ratios["quick_ratio"] = ((self.balance.at["total_current_assets", year] -
                                       self.balance.at["inventory", year]) /
                                       self.balance.at["total_current_liabilities", year])

        return ratios

    def calculate_solvency_ratios(self, year):
        \"\"\"è®¡ç®—å¿ä»˜èƒ½åŠ›æ¯”ç‡\"\"\"
        ratios = {}

        if (not self.income.empty and year in self.income.columns and
            not self.balance.empty and year in self.balance.columns):
            # è´Ÿå€ºæƒç›Šæ¯”
            if ("total_liabilities" in self.balance.index and
                "total_stockholder_equity" in self.balance.index):
                ratios["debt_to_equity"] = (self.balance.at["total_liabilities", year] /
                                           self.balance.at["total_stockholder_equity", year])

            # åˆ©æ¯ä¿éšœå€æ•°
            if ("ebit" in self.income.index and "interest_expense" in self.income.index):
                ratios["interest_coverage"] = (self.income.at["ebit", year] /
                                             self.income.at["interest_expense", year])

        return ratios

    def calculate_all_ratios(self, year):
        \"\"\"è®¡ç®—æ‰€æœ‰è´¢åŠ¡æ¯”ç‡\"\"\"
        all_ratios = {}
        all_ratios.update(self.calculate_profitability_ratios(year))
        all_ratios.update(self.calculate_liquidity_ratios(year))
        all_ratios.update(self.calculate_solvency_ratios(year))
        return all_ratios

# ä½¿ç”¨ç¤ºä¾‹
# calculator = FinancialRatioCalculator(income_statement, balance_sheet, cash_flow)
# ratios = calculator.calculate_all_ratios(2024)
# print(ratios)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è®¡ç®—å„ç§è´¢åŠ¡æ¯”ç‡ï¼ŒåŒ…æ‹¬ç›ˆåˆ©èƒ½åŠ›ã€æµåŠ¨æ€§å’Œå¿ä»˜èƒ½åŠ›æ¯”ç‡ã€‚è¿™äº›æ¯”ç‡æ˜¯è´¢åŠ¡æŠ¥è¡¨åˆ†æçš„æ ¸å¿ƒæŒ‡æ ‡ï¼Œå¸®åŠ©è¯„ä¼°å…¬å¸çš„è´¢åŠ¡å¥åº·çŠ¶å†µã€‚"
    },
    {
        "topic_id": 4,
        "category_id": 4,
        "title": "è´¢åŠ¡æŠ¥è¡¨å¯è§†åŒ–",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False

def plot_income_statement_trends(income_statement, key_metrics):
    \"\"\"ç»˜åˆ¶åˆ©æ¶¦è¡¨è¶‹åŠ¿\"\"\"
    plt.figure(figsize=(15, 10))

    for i, metric in enumerate(key_metrics, 1):
        if metric in income_statement.index:
            plt.subplot(2, 2, i)
            plt.plot(income_statement.columns, income_statement.loc[metric], marker="o")
            plt.title(f"{metric.replace('_', ' ').title()}")
            plt.xlabel("å¹´ä»½")
            plt.ylabel("é‡‘é¢")
            plt.grid(True)

    plt.tight_layout()
    plt.savefig("income_statement_trends.png")
    plt.show()

def plot_balance_sheet_composition(balance_sheet, year):
    \"\"\"ç»˜åˆ¶èµ„äº§è´Ÿå€ºè¡¨ç»“æ„\"\"\"
    if year in balance_sheet.columns:
        assets = [item for item in balance_sheet.index if "asset" in item and "total" not in item]
        liabilities = [item for item in balance_sheet.index if "liability" in item and "total" not in item]
        equity = [item for item in balance_sheet.index if "equity" in item]

        # åˆ›å»ºå­å›¾
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))

        # é¥¼å›¾å±•ç¤ºèµ„äº§ç»“æ„
        asset_values = [balance_sheet.at[item, year] for item in assets]
        ax1.pie(asset_values, labels=assets, autopct='%1.1f%%', startangle=90)
        ax1.set_title("èµ„äº§ç»“æ„")

        # é¥¼å›¾å±•ç¤ºè´Ÿå€ºå’Œè‚¡ä¸œæƒç›Šç»“æ„
        liability_equity_values = []
        liability_equity_labels = []

        if liabilities:
            liability_equity_values.append(balance_sheet.at["total_current_liabilities", year])
            liability_equity_labels.append("æµåŠ¨è´Ÿå€º")
            liability_equity_values.append(balance_sheet.at["long_term_debt", year])
            liability_equity_labels.append("é•¿æœŸè´Ÿå€º")

        if equity:
            liability_equity_values.append(balance_sheet.at["total_stockholder_equity", year])
            liability_equity_labels.append("è‚¡ä¸œæƒç›Š")

        ax2.pie(liability_equity_values, labels=liability_equity_labels, autopct='%1.1f%%', startangle=90)
        ax2.set_title("è´Ÿå€ºå’Œè‚¡ä¸œæƒç›Šç»“æ„")

        plt.savefig("balance_sheet_composition.png")
        plt.show()

def plot_financial_ratios_comparison(ratios_data, ratio_types):
    \"\"\"ç»˜åˆ¶è´¢åŠ¡æ¯”ç‡å¯¹æ¯”\"\"\"
    years = list(ratios_data.keys())
    all_ratios = {}

    # æ”¶é›†æ‰€æœ‰è¦æ¯”è¾ƒçš„æ¯”ç‡
    for year, ratios in ratios_data.items():
        for ratio_type in ratio_types:
            if ratio_type not in all_ratios:
                all_ratios[ratio_type] = []
            all_ratios[ratio_type].append(ratios.get(ratio_type, 0))

    # ç»˜åˆ¶å¯¹æ¯”å›¾
    fig, axes = plt.subplots(len(all_ratios), 1, figsize=(12, 20))

    for i, (ratio, values) in enumerate(all_ratios.items()):
        axes[i].bar(years, values)
        axes[i].set_title(ratio.replace('_', ' ').title())
        axes[i].set_xlabel("å¹´ä»½")
        axes[i].set_ylabel("å€¼")

        # åœ¨æ¯ä¸ªæ¡å½¢ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for j, value in enumerate(values):
            axes[i].text(j, value + max(values)*0.05, f"{value:.2f}",
                        ha='center', va='bottom')

    plt.tight_layout()
    plt.savefig("financial_ratios_comparison.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾ä¹‹å‰å·²è®¡ç®—æ•°æ®ï¼‰
# key_metrics = ["gross_profit", "operating_income", "net_income"]
# plot_income_statement_trends(income_statement, key_metrics)
# plot_balance_sheet_composition(balance_sheet, 2024)
# ratios_2024 = calculator.calculate_all_ratios(2024)
# plot_financial_ratios_comparison({"2024": ratios_2024, "2023": ratios_2023}, ["gross_margin", "current_ratio"])
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹è´¢åŠ¡æŠ¥è¡¨æ•°æ®è¿›è¡Œå¯è§†åŒ–åˆ†æï¼ŒåŒ…æ‹¬è¶‹åŠ¿åˆ†æã€ç»“æ„åˆ†æå’Œå¯¹æ¯”åˆ†æã€‚å¯è§†åŒ–å¸®åŠ©æˆ‘ä»¬æ›´ç›´è§‚åœ°ç†è§£è´¢åŠ¡æ•°æ®çš„æ¨¡å¼å’Œå…³ç³»ã€‚"
    },
    {
        "topic_id": 4,
        "category_id": 5,
        "title": "è´¢åŠ¡æŠ¥è¡¨æœºå™¨å­¦ä¹ åˆ†æ",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

class FinancialStatementAnalyst:
    def __init__(self, financial_data):
        self.data = financial_data
        self.model = None
        self.scaler = StandardScaler()

    def prepare_features(self, features):
        \"\"\"å‡†å¤‡ç‰¹å¾æ•°æ®\"\"\"
        X = pd.DataFrame()

        for feature in features:
            # è®¡ç®—è´¢åŠ¡æ¯”ç‡
            if feature == "profitability":
                # ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
                X["gross_margin"] = (self.data["gross_profit"] / self.data["total_revenue"]) * 100
                X["net_margin"] = (self.data["net_income"] / self.data["total_revenue"]) * 100

            elif feature == "liquidity":
                # æµåŠ¨æ€§æŒ‡æ ‡
                X["current_ratio"] = (self.data["total_current_assets"] /
                                     self.data["total_current_liabilities"])
                X["quick_ratio"] = ((self.data["total_current_assets"] -
                                    self.data["inventory"]) /
                                    self.data["total_current_liabilities"])

            elif feature == "solvency":
                # å¿ä»˜èƒ½åŠ›æŒ‡æ ‡
                X["debt_to_equity"] = (self.data["total_liabilities"] /
                                      self.data["total_stockholder_equity"])

        # è®¡ç®—è¶‹åŠ¿ç‰¹å¾
        for column in X.columns:
            X[f"{column}_trend"] = X[column].rolling(window=3).mean().shift(1)

        return X.dropna()

    def prepare_labels(self, target_column="financial_health"):
        \"\"\"å‡†å¤‡æ ‡ç­¾æ•°æ®\"\"\"
        # ç®€å•çš„å¥åº·æ ‡ç­¾ï¼ˆéœ€è¦æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰
        labels = []

        for index, row in self.data.iterrows():
            # åŸºäºè´¢åŠ¡æ¯”ç‡é˜ˆå€¼åˆ¤æ–­å¥åº·çŠ¶å†µ
            if (row["net_margin"] > 10 and
                row["current_ratio"] > 1.5 and
                row["debt_to_equity"] < 2):
                labels.append("å¥åº·")
            elif (row["net_margin"] > 0 and
                  row["current_ratio"] > 1 and
                  row["debt_to_equity"] < 3):
                labels.append("æ­£å¸¸")
            else:
                labels.append("éœ€è¦å…³æ³¨")

        return pd.Series(labels, index=self.data.index)

    def train_classifier(self, features, test_size=0.2):
        \"\"\"è®­ç»ƒåˆ†ç±»å™¨\"\"\"
        X = self.prepare_features(features)
        y = self.prepare_labels()[X.index]

        # åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

        # æ ‡å‡†åŒ–ç‰¹å¾
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X_train_scaled, y_train)

        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = self.model.predict(X_test_scaled)

        # æ‰“å°è¯„ä¼°æŠ¥å‘Š
        print("åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred))
        print("\\næ··æ·†çŸ©é˜µ:")
        print(confusion_matrix(y_test, y_pred))

        return self.model

    def predict_financial_health(self, new_data):
        \"\"\"é¢„æµ‹è´¢åŠ¡å¥åº·çŠ¶å†µ\"\"\"
        if self.model:
            # å‡†å¤‡æ–°æ•°æ®çš„ç‰¹å¾
            features = ["profitability", "liquidity", "solvency"]
            X_new = self.prepare_features(features)

            if not X_new.empty:
                X_scaled = self.scaler.transform(X_new)
                predictions = self.model.predict(X_scaled)
                return pd.Series(predictions, index=X_new.index)

        return None

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆéœ€è¦å‡†å¤‡é€‚å½“çš„æ•°æ®é›†ï¼‰
# df = pd.read_csv("financial_data.csv", index_col="Year")
# analyst = FinancialStatementAnalyst(df)
# model = analyst.train_classifier(["profitability", "liquidity", "solvency"])
# predictions = analyst.predict_financial_health(df.tail(1))
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆéšæœºæ£®æ—åˆ†ç±»å™¨ï¼‰åˆ†æè´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼ŒåŒ…æ‹¬ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œè¯„ä¼°ã€‚æœºå™¨å­¦ä¹ å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯†åˆ«å¤æ‚çš„è´¢åŠ¡æ¨¡å¼ã€‚"
    },
    {
        "topic_id": 4,
        "category_id": 6,
        "title": "å®Œæ•´è´¢åŠ¡æŠ¥è¡¨åˆ†ææŠ¥å‘Š",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import StringIO

class FinancialReportGenerator:
    def __init__(self, company_name, financial_data):
        self.company_name = company_name
        self.financial_data = financial_data

    def generate_textual_report(self):
        \"\"\"ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š\"\"\"
        report = StringIO()

        report.write(f"# è´¢åŠ¡æŠ¥è¡¨åˆ†ææŠ¥å‘Š\\n")
        report.write(f"## {self.company_name}\\n")
        report.write(f"### æŠ¥å‘Šæ—¶é—´: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\\n\\n")

        # å…¬å¸æ¦‚è§ˆ
        report.write("## å…¬å¸æ¦‚è§ˆ\\n")
        report.write("- è¡Œä¸š: ç§‘æŠ€åˆ¶é€ ä¸š\\n")
        report.write("- ä¸»è¥ä¸šåŠ¡: ç”µå­äº§å“å’Œè½¯ä»¶æœåŠ¡\\n")
        report.write("- ä¸Šå¸‚æ—¶é—´: 1980å¹´\\n\\n")

        # è´¢åŠ¡å¥åº·çŠ¶å†µè¯„ä¼°
        report.write("## è´¢åŠ¡å¥åº·çŠ¶å†µè¯„ä¼°\\n")

        for year in self.financial_data["income"].columns[-3:]:
            report.write(f"### {year}å¹´è´¢åŠ¡æ¯”ç‡åˆ†æ\\n")

            # è·å–è¯¥å¹´ä»½çš„è´¢åŠ¡æ¯”ç‡ï¼ˆå‡è®¾ä¹‹å‰å·²è®¡ç®—ï¼‰
            # ratios = calculator.calculate_all_ratios(year)
            # for category, values in ratios.items():
            #     report.write(f"#### {category}\\n")
            #     for ratio, value in values.items():
            #         report.write(f"- {ratio}: {value:.2f}\\n")

            report.write("\\n")

        # è¶‹åŠ¿åˆ†æ
        report.write("## è´¢åŠ¡è¶‹åŠ¿åˆ†æ\\n")
        report.write("- è¥ä¸šæ”¶å…¥å¢é•¿ç‡: è¿‡å»ä¸‰å¹´å¹³å‡å¢é•¿15.2%\\n")
        report.write("- å‡€åˆ©æ¶¦å¢é•¿ç‡: è¿‡å»ä¸‰å¹´å¹³å‡å¢é•¿20.5%\\n")
        report.write("- èµ„äº§è´Ÿå€ºç‡: ä¿æŒåœ¨30%å·¦å³ï¼Œè´¢åŠ¡ç»“æ„ç¨³å¥\\n")
        report.write("- å‡€åˆ©ç‡: æŒç»­ä¸Šå‡ï¼Œä»2022å¹´çš„21.2%ä¸Šå‡åˆ°2024å¹´çš„25.8%\\n\\n")

        # é£é™©è¯„ä¼°
        report.write("## é£é™©è¯„ä¼°\\n")
        report.write("### ä¸»è¦é£é™©: å›½é™…å¸‚åœºé£é™©\\n")
        report.write("- æµ·å¤–å¸‚åœºå æ¯”é«˜ï¼Œå—æ±‡ç‡æ³¢åŠ¨å½±å“\\n")
        report.write("- ä¸­ç¾è´¸æ˜“æ‘©æ“¦å¯èƒ½å½±å“ä¾›åº”é“¾æˆæœ¬\\n")
        report.write("\\n")

        report.write("### é£é™©æ§åˆ¶å»ºè®®:\\n")
        report.write("- åŠ å¼ºå¤–æ±‡é£é™©ç®¡ç†\\n")
        report.write("- å¤šå…ƒåŒ–ä¾›åº”é“¾æ¥æº\\n")
        report.write("- åŠ å¼ºç ”å‘æŠ•å…¥ï¼Œä¿æŒäº§å“ç«äº‰åŠ›\\n")

        return report.getvalue()

    def generate_visual_report(self):
        \"\"\"ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š\"\"\"
        # åˆ›å»ºæŠ¥å‘Šæ ‡é¢˜é¡µ
        plt.figure(figsize=(12, 8))
        plt.text(0.5, 0.8, f"{self.company_name}\\nè´¢åŠ¡æŠ¥è¡¨åˆ†ææŠ¥å‘Š", fontsize=20, ha="center")
        plt.text(0.5, 0.5, "æŠ¥å‘Šæ—¶é—´: " + pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥'), fontsize=12, ha="center")
        plt.axis('off')
        plt.savefig("report_title.png", bbox_inches="tight")
        plt.close()

        # å…¶ä»–å›¾è¡¨ï¼ˆå‡è®¾ä¹‹å‰å·²ç”Ÿæˆï¼‰
        # income_statement_trends.png
        # balance_sheet_composition.png
        # financial_ratios_comparison.png
        return ["report_title.png", "income_statement_trends.png",
                "balance_sheet_composition.png", "financial_ratios_comparison.png"]

    def save_report(self, report_text, visual_report):
        \"\"\"ä¿å­˜æŠ¥å‘Š\"\"\"
        with open("financial_report.md", "w", encoding="utf-8") as f:
            f.write(report_text)

        print("è´¢åŠ¡æŠ¥è¡¨åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
        print(f"æ–‡æœ¬æŠ¥å‘Š: financial_report.md")
        print(f"å›¾è¡¨æ–‡ä»¶: {len(visual_report)}ä¸ª")

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆéœ€è¦å‡†å¤‡å®Œæ•´çš„è´¢åŠ¡æ•°æ®ï¼‰
# income_statement, balance_sheet, cash_flow = get_financial_data()
# data_dict = {"income": income_statement, "balance": balance_sheet, "cash_flow": cash_flow}
# report_generator = FinancialReportGenerator("è‹¹æœå…¬å¸", data_dict)
# text_report = report_generator.generate_textual_report()
# visual_report = report_generator.generate_visual_report()
# report_generator.save_report(text_report, visual_report)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ç”Ÿæˆå®Œæ•´çš„è´¢åŠ¡æŠ¥è¡¨åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬æ–‡æœ¬æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨ã€‚æŠ¥å‘Šåº”ç»¼åˆè´¢åŠ¡æ¯”ç‡åˆ†æã€è¶‹åŠ¿åˆ†æå’Œé£é™©è¯„ä¼°ï¼Œä¸ºå†³ç­–è€…æä¾›å…¨é¢çš„è´¢åŠ¡çŠ¶å†µæ¦‚è§ˆã€‚"
    },
    # ä¸»é¢˜3ï¼šé£é™©ç®¡ç†ç³»ç»Ÿ
    {
        "topic_id": 3,
        "category_id": 1,
        "title": "é£é™©æ•°æ®è·å–",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import yfinance as yf

def fetch_stock_data(symbols, start_date, end_date):
    \"\"\"è·å–è‚¡ç¥¨æ•°æ®\"\"\"
    data = {}
    for symbol in symbols:
        try:
            df = yf.download(symbol, start=start_date, end=end_date)
            data[symbol] = df
            print(f"æˆåŠŸè·å–{symbol}æ•°æ®ï¼Œå…±{len(df)}æ¡")
        except Exception as e:
            print(f"è·å–{symbol}æ•°æ®å¤±è´¥: {e}")
    return data

def fetch_index_data(symbol, start_date, end_date):
    \"\"\"è·å–æŒ‡æ•°æ•°æ®\"\"\"
    try:
        df = yf.download(symbol, start=start_date, end=end_date)
        print(f"æˆåŠŸè·å–{symbol}æŒ‡æ•°æ•°æ®ï¼Œå…±{len(df)}æ¡")
        return df
    except Exception as e:
        print(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def fetch_macro_data():
    \"\"\"è·å–å®è§‚ç»æµæ•°æ®ï¼ˆç¤ºä¾‹ï¼‰\"\"\"
    dates = pd.date_range(start="2015-01-01", end=datetime.now(), freq="D")
    inflation = np.random.normal(0.02/365, 0.01/365, len(dates))
    interest_rate = np.random.normal(0.03/365, 0.005/365, len(dates))

    data = pd.DataFrame({
        "Date": dates,
        "Inflation": inflation,
        "InterestRate": interest_rate
    }).set_index("Date")

    print(f"ç”Ÿæˆå®è§‚ç»æµæ•°æ®ï¼Œå…±{len(data)}æ¡")
    return data

# ä½¿ç”¨ç¤ºä¾‹
symbols = ["AAPL", "GOOGL", "MSFT", "AMZN"]
start_date = "2015-01-01"
end_date = "2025-01-01"

stock_data = fetch_stock_data(symbols, start_date, end_date)
index_data = fetch_index_data("^GSPC", start_date, end_date)
macro_data = fetch_macro_data()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è·å–é£é™©ç®¡ç†æ‰€éœ€çš„å„ç±»æ•°æ®ï¼ŒåŒ…æ‹¬è‚¡ç¥¨æ•°æ®ã€æŒ‡æ•°æ•°æ®å’Œå®è§‚ç»æµæ•°æ®ã€‚é£é™©ç®¡ç†çš„åŸºç¡€æ˜¯å‡†ç¡®ã€å…¨é¢çš„æ•°æ®è·å–ã€‚"
    },
    {
        "topic_id": 3,
        "category_id": 2,
        "title": "é£é™©æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np

def preprocess_stock_data(stock_data):
    \"\"\"é¢„å¤„ç†è‚¡ç¥¨æ•°æ®\"\"\"
    processed_data = {}

    for symbol, df in stock_data.items():
        # æ£€æŸ¥å¹¶å¡«å……ç¼ºå¤±å€¼
        df = df.fillna(method="ffill")

        # è®¡ç®—æ”¶ç›Šç‡
        df["Return"] = df["Close"].pct_change()

        # è®¡ç®—æ³¢åŠ¨ç‡
        df["Volatility"] = df["Return"].rolling(window=30).std() * np.sqrt(252)

        # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
        df["LogReturn"] = np.log(df["Close"] / df["Close"].shift(1))

        processed_data[symbol] = df
        print(f"{symbol}æ•°æ®é¢„å¤„ç†å®Œæˆ")

    return processed_data

def preprocess_index_data(index_data):
    \"\"\"é¢„å¤„ç†æŒ‡æ•°æ•°æ®\"\"\"
    # æ£€æŸ¥å¹¶å¡«å……ç¼ºå¤±å€¼
    index_data = index_data.fillna(method="ffill")

    # è®¡ç®—æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡
    index_data["Return"] = index_data["Close"].pct_change()
    index_data["Volatility"] = index_data["Return"].rolling(window=30).std() * np.sqrt(252)

    print("æŒ‡æ•°æ•°æ®é¢„å¤„ç†å®Œæˆ")
    return index_data

def merge_data(processed_stock, processed_index, macro_data):
    \"\"\"åˆå¹¶å„ç±»æ•°æ®\"\"\"
    # åˆå¹¶è‚¡ç¥¨æ•°æ®
    merged_data = pd.DataFrame()
    for symbol, df in processed_stock.items():
        temp = df[["Close", "Return", "Volatility"]].copy()
        temp.columns = [f"{symbol}_{col}" for col in temp.columns]
        if merged_data.empty:
            merged_data = temp
        else:
            merged_data = merged_data.join(temp, how="outer")

    # åˆå¹¶æŒ‡æ•°æ•°æ®
    merged_data = merged_data.join(
        processed_index[["Return", "Volatility"]].rename(
            columns={"Return": "SP500_Return", "Volatility": "SP500_Volatility"}
        ),
        how="outer"
    )

    # åˆå¹¶å®è§‚ç»æµæ•°æ®
    merged_data = merged_data.join(macro_data, how="outer")

    # å¡«å……æœ€ç»ˆç¼ºå¤±å€¼
    merged_data = merged_data.fillna(method="ffill").fillna(method="bfill")

    print(f"æ•°æ®åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆå½¢çŠ¶: {merged_data.shape}")
    return merged_data

# ä½¿ç”¨ç¤ºä¾‹
# processed_stock = preprocess_stock_data(stock_data)
# processed_index = preprocess_index_data(index_data)
# final_data = merge_data(processed_stock, processed_index, macro_data)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•é¢„å¤„ç†é£é™©ç®¡ç†æ•°æ®ï¼ŒåŒ…æ‹¬è‚¡ç¥¨å’ŒæŒ‡æ•°æ•°æ®çš„æ¸…æ´—ã€æ”¶ç›Šç‡è®¡ç®—ã€æ³¢åŠ¨ç‡è®¡ç®—ï¼Œä»¥åŠå„ç±»æ•°æ®çš„åˆå¹¶ã€‚æ•°æ®é¢„å¤„ç†æ˜¯é£é™©ç®¡ç†çš„å…³é”®æ­¥éª¤ã€‚"
    },
    {
        "topic_id": 3,
        "category_id": 3,
        "title": "é£é™©åˆ†ææ–¹æ³•",
        "code": """import pandas as pd
import numpy as np
from scipy.stats import norm, t

class RiskAnalyst:
    def __init__(self, data):
        self.data = data

    def calculate_var(self, returns, method="parametric", confidence=0.95, period=1):
        \"\"\"è®¡ç®—é£é™©ä»·å€¼(VaR)\"\"\"
        if method == "parametric":
            mu = returns.mean()
            sigma = returns.std()
            VaR = mu * period - sigma * norm.ppf(confidence) * np.sqrt(period)
        elif method == "historical":
            VaR = -returns.quantile(1 - confidence)
        elif method == "monte_carlo":
            np.random.seed(42)
            sim_returns = np.random.normal(returns.mean(), returns.std(), 10000)
            VaR = -np.percentile(sim_returns, 100 * (1 - confidence))
        else:
            raise ValueError("æ— æ•ˆçš„VaRè®¡ç®—æ–¹æ³•")

        return VaR

    def calculate_cvar(self, returns, method="parametric", confidence=0.95):
        \"\"\"è®¡ç®—æ¡ä»¶é£é™©ä»·å€¼(CVaR)\"\"\"
        if method == "parametric":
            mu = returns.mean()
            sigma = returns.std()
            cvar = mu - sigma * norm.pdf(norm.ppf(1 - confidence)) / (1 - confidence)
        elif method == "historical":
            var = -returns.quantile(1 - confidence)
            cvar = -returns[returns <= -var].mean()
        else:
            raise ValueError("æ— æ•ˆçš„CVaRè®¡ç®—æ–¹æ³•")

        return cvar

    def analyze_portfolio_risk(self, weights, symbols, period=1):
        \"\"\"åˆ†ææŠ•èµ„ç»„åˆé£é™©\"\"\"
        returns = np.array([self.data[f"{symbol}_Return"] for symbol in symbols]).T
        cov_matrix = np.cov(returns.T)

        # è®¡ç®—æŠ•èµ„ç»„åˆæ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡
        portfolio_return = np.dot(weights, np.array([self.data[f"{symbol}_Return"].mean() for symbol in symbols]))
        portfolio_volatility = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights))) * np.sqrt(period)

        # è®¡ç®—VaRå’ŒCVaR
        portfolio_returns = np.dot(returns, weights)
        portfolio_VaR = self.calculate_var(portfolio_returns, method="parametric")
        portfolio_CVaR = self.calculate_cvar(portfolio_returns, method="parametric")

        risk_report = {
            "Return": portfolio_return,
            "Volatility": portfolio_volatility,
            "VaR": portfolio_VaR,
            "CVaR": portfolio_CVaR
        }

        return risk_report

# ä½¿ç”¨ç¤ºä¾‹
# analyst = RiskAnalyst(final_data)
# weights = [0.25, 0.25, 0.25, 0.25]
# risk_report = analyst.analyze_portfolio_risk(weights, symbols)
# print("æŠ•èµ„ç»„åˆé£é™©åˆ†ææŠ¥å‘Š:")
# for metric, value in risk_report.items():
#     print(f"{metric}: {value:.4f}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¤šç§æ–¹æ³•è®¡ç®—é£é™©ç®¡ç†ä¸­çš„å…³é”®æŒ‡æ ‡ï¼ŒåŒ…æ‹¬VaRï¼ˆé£é™©ä»·å€¼ï¼‰å’ŒCVaRï¼ˆæ¡ä»¶é£é™©ä»·å€¼ï¼‰ï¼Œå¹¶æä¾›æŠ•èµ„ç»„åˆé£é™©åˆ†æåŠŸèƒ½ã€‚"
    },
    {
        "topic_id": 3,
        "category_id": 4,
        "title": "é£é™©å¯è§†åŒ–",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def plot_volatility_evolution(processed_data, symbols):
    \"\"\"ç»˜åˆ¶æ³¢åŠ¨ç‡æ¼”å˜\"\"\"
    plt.figure(figsize=(12, 6))
    for symbol in symbols:
        plt.plot(processed_data[symbol].index, processed_data[symbol]["Volatility"], label=f"{symbol}")

    plt.title("æ³¢åŠ¨ç‡æ¼”å˜")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("å¹´æ³¢åŠ¨ç‡")
    plt.legend()
    plt.grid(True)
    plt.savefig("volatility_evolution.png")
    plt.show()

def plot_correlation_matrix(final_data, symbols):
    \"\"\"ç»˜åˆ¶ç›¸å…³ç³»æ•°çŸ©é˜µ\"\"\"
    returns = [final_data[f"{symbol}_Return"] for symbol in symbols]
    returns.append(final_data["SP500_Return"])
    return_df = pd.DataFrame(returns).T
    return_df.columns = symbols + ["SP500"]

    corr_matrix = return_df.corr()

    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1, center=0)
    plt.title("æ”¶ç›Šç‡ç›¸å…³ç³»æ•°çŸ©é˜µ")
    plt.savefig("correlation_matrix.png")
    plt.show()

def plot_return_distribution(final_data, symbols):
    \"\"\"ç»˜åˆ¶æ”¶ç›Šç‡åˆ†å¸ƒ\"\"\"
    plt.figure(figsize=(12, 8))
    for i, symbol in enumerate(symbols, 1):
        plt.subplot(2, 2, i)
        sns.histplot(final_data[f"{symbol}_Return"].dropna(), kde=True)
        plt.title(f"{symbol}æ”¶ç›Šç‡åˆ†å¸ƒ")
        plt.xlabel("æ”¶ç›Šç‡")
        plt.ylabel("é¢‘ç‡")

    plt.tight_layout()
    plt.savefig("return_distribution.png")
    plt.show()

def plot_risk_metrics_comparison(risk_reports):
    \"\"\"ç»˜åˆ¶é£é™©æŒ‡æ ‡æ¯”è¾ƒ\"\"\"
    methods = list(risk_reports.keys())
    VaRs = [report["VaR"] for report in risk_reports.values()]
    CVaRs = [report["CVaR"] for report in risk_reports.values()]

    x = np.arange(len(methods))
    width = 0.35

    plt.figure(figsize=(10, 6))
    plt.bar(x - width/2, VaRs, width, label="VaR")
    plt.bar(x + width/2, CVaRs, width, label="CVaR")

    plt.title("ä¸åŒè®¡ç®—æ–¹æ³•çš„VaRå’ŒCVaRæ¯”è¾ƒ")
    plt.xlabel("è®¡ç®—æ–¹æ³•")
    plt.ylabel("é£é™©ä»·å€¼")
    plt.xticks(x, methods)
    plt.legend()
    plt.grid(axis="y")
    plt.savefig("risk_metrics_comparison.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# plot_volatility_evolution(processed_stock, symbols)
# plot_correlation_matrix(final_data, symbols)
# plot_return_distribution(final_data, symbols)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯è§†åŒ–é£é™©ç®¡ç†è¿‡ç¨‹ä¸­çš„å„ç±»æ•°æ®å’ŒæŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ³¢åŠ¨ç‡æ¼”å˜ã€ç›¸å…³ç³»æ•°çŸ©é˜µã€æ”¶ç›Šç‡åˆ†å¸ƒå’Œé£é™©æŒ‡æ ‡æ¯”è¾ƒå›¾è¡¨ã€‚å¯è§†åŒ–å¸®åŠ©åˆ†æå¸ˆç›´è§‚ç†è§£é£é™©ç‰¹å¾ã€‚"
    },
    {
        "topic_id": 3,
        "category_id": 5,
        "title": "æœºå™¨å­¦ä¹ åœ¨é£é™©ç®¡ç†ä¸­çš„åº”ç”¨",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

class RiskPredictor:
    def __init__(self, data, threshold=0.02):
        self.data = data
        self.threshold = threshold
        self.scaler = StandardScaler()

    def create_features(self, symbol):
        \"\"\"åˆ›å»ºç‰¹å¾æ•°æ®\"\"\"
        features = pd.DataFrame()
        features["Return"] = self.data[f"{symbol}_Return"]
        features["Volatility"] = self.data[f"{symbol}_Volatility"]
        features["SP500_Return"] = self.data["SP500_Return"]
        features["SP500_Volatility"] = self.data["SP500_Volatility"]
        features["Inflation"] = self.data["Inflation"]
        features["InterestRate"] = self.data["InterestRate"]

        # åˆ›å»ºæ»åç‰¹å¾
        for i in range(1, 6):
            features[f"Return_Lag{i}"] = self.data[f"{symbol}_Return"].shift(i)

        # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        features = features.dropna()
        return features

    def create_labels(self, symbol):
        \"\"\"åˆ›å»ºæ ‡ç­¾æ•°æ®\"\"\"
        returns = self.data[f"{symbol}_Return"]
        labels = (returns < -self.threshold).astype(int)
        return labels

    def train_model(self, symbol):
        \"\"\"è®­ç»ƒé£é™©é¢„æµ‹æ¨¡å‹\"\"\"
        X = self.create_features(symbol)
        y = self.create_labels(symbol)[X.index]

        # åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # æ ‡å‡†åŒ–æ•°æ®
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train_scaled, y_train)

        # é¢„æµ‹
        y_pred = model.predict(X_test_scaled)

        # è¯„ä¼°æ¨¡å‹
        report = classification_report(y_test, y_pred)
        matrix = confusion_matrix(y_test, y_pred)

        return model, report, matrix

    def predict_risk(self, model, symbol, future_dates):
        \"\"\"é¢„æµ‹æœªæ¥é£é™©\"\"\"
        features = self.create_features(symbol)
        last_features = features.tail(1)
        last_features_scaled = self.scaler.transform(last_features)

        risk_prediction = model.predict(last_features_scaled)
        risk_probability = model.predict_proba(last_features_scaled)[0][1]

        return risk_prediction, risk_probability

# ä½¿ç”¨ç¤ºä¾‹
# predictor = RiskPredictor(final_data, threshold=0.02)
# model, report, matrix = predictor.train_model("AAPL")
# print("æ¨¡å‹åˆ†ç±»æŠ¥å‘Š:")
# print(report)
# print("æ··æ·†çŸ©é˜µ:")
# print(matrix)

# risk_pred, risk_prob = predictor.predict_risk(model, "AAPL", [pd.Timestamp("2025-01-02")])
# print(f"é¢„æµ‹é£é™©å‘ç”Ÿ: {risk_pred}")
# print(f"é£é™©æ¦‚ç‡: {risk_prob:.4f}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•é¢„æµ‹é‡‘èé£é™©äº‹ä»¶ï¼ŒåŒ…æ‹¬ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œè¯„ä¼°ã€‚é€šè¿‡æœºå™¨å­¦ä¹ ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å‡†ç¡®åœ°è¯†åˆ«æ½œåœ¨çš„é£é™©ä¿¡å·ã€‚"
    },
    {
        "topic_id": 3,
        "category_id": 6,
        "title": "å®Œæ•´é£é™©ç®¡ç†ç³»ç»Ÿ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

class RiskManagementSystem:
    def __init__(self):
        self.data = None
        self.stock_data = None
        self.index_data = None
        self.macro_data = None
        self.processed_data = None
        self.risk_analyst = None

    def load_and_prepare_data(self, symbols, start_date, end_date):
        \"\"\"åŠ è½½å’Œå‡†å¤‡æ•°æ®\"\"\"
        from data_fetcher import fetch_stock_data, fetch_index_data, fetch_macro_data
        from data_preprocessor import preprocess_stock_data, preprocess_index_data, merge_data

        print("å¼€å§‹åŠ è½½æ•°æ®...")
        self.stock_data = fetch_stock_data(symbols, start_date, end_date)
        self.index_data = fetch_index_data("^GSPC", start_date, end_date)
        self.macro_data = fetch_macro_data()

        print("å¼€å§‹é¢„å¤„ç†æ•°æ®...")
        processed_stock = preprocess_stock_data(self.stock_data)
        processed_index = preprocess_index_data(self.index_data)

        print("å¼€å§‹åˆå¹¶æ•°æ®...")
        self.processed_data = merge_data(processed_stock, processed_index, self.macro_data)

        return self.processed_data

    def initialize_risk_analyst(self):
        \"\"\"åˆå§‹åŒ–é£é™©åˆ†æå¸ˆ\"\"\"
        from risk_analyst import RiskAnalyst

        self.risk_analyst = RiskAnalyst(self.processed_data)
        return self.risk_analyst

    def run_portfolio_risk_analysis(self, weights, symbols):
        \"\"\"è¿è¡ŒæŠ•èµ„ç»„åˆé£é™©åˆ†æ\"\"\"
        if self.risk_analyst is None:
            self.initialize_risk_analyst()

        print("å¼€å§‹æŠ•èµ„ç»„åˆé£é™©åˆ†æ...")
        return self.risk_analyst.analyze_portfolio_risk(weights, symbols)

    def run_stress_testing(self, scenario, symbols):
        \"\"\"è¿è¡Œå‹åŠ›æµ‹è¯•\"\"\"
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸åŒçš„å‹åŠ›æµ‹è¯•åœºæ™¯
        # æ¯”å¦‚ï¼šé‡‘èå±æœºã€ç»æµè¡°é€€ã€å¸‚åœºå´©æºƒç­‰
        print(f"è¿è¡Œå‹åŠ›æµ‹è¯•åœºæ™¯: {scenario}")

        if scenario == "severe_recession":
            # æ¨¡æ‹Ÿä¸¥é‡è¡°é€€åœºæ™¯ï¼šå¸‚åœºä¸‹è·Œ20%ï¼Œæ³¢åŠ¨ç‡å¢åŠ 3å€
            stress_data = self.processed_data.copy()
            for symbol in symbols:
                stress_data[f"{symbol}_Return"] = stress_data[f"{symbol}_Return"] * 0.8
                stress_data[f"{symbol}_Volatility"] = stress_data[f"{symbol}_Volatility"] * 3
            stress_data["SP500_Return"] = stress_data["SP500_Return"] * 0.8
            stress_data["SP500_Volatility"] = stress_data["SP500_Volatility"] * 3
            stress_data["InterestRate"] = stress_data["InterestRate"] * 1.5

            # åœ¨å‹åŠ›åœºæ™¯ä¸‹é‡æ–°è¯„ä¼°é£é™©
            stress_analyst = RiskAnalyst(stress_data)
            stress_report = stress_analyst.analyze_portfolio_risk([0.25, 0.25, 0.25, 0.25], symbols)

            return stress_report
        else:
            return {"Error": "æœªçŸ¥å‹åŠ›æµ‹è¯•åœºæ™¯"}

    def generate_risk_report(self, portfolio_report, stress_report=None):
        \"\"\"ç”Ÿæˆé£é™©æŠ¥å‘Š\"\"\"
        print("\\n=== é£é™©ç®¡ç†æŠ¥å‘Š ===")
        print("\\næŠ•èµ„ç»„åˆåŸºç¡€é£é™©:")
        for key, value in portfolio_report.items():
            if key in ["Return", "Volatility"]:
                print(f"{key}: {value:.4f}")
            else:
                print(f"{key}: {value:.2%}")

        if stress_report and "Error" not in stress_report:
            print("\\nå‹åŠ›æµ‹è¯•ç»“æœ:")
            for key, value in stress_report.items():
                if key in ["Return", "Volatility"]:
                    print(f"{key}: {value:.4f}")
                else:
                    print(f"{key}: {value:.2%}")

        return "Risk report generated successfully"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    system = RiskManagementSystem()
    symbols = ["AAPL", "GOOGL", "MSFT", "AMZN"]
    start_date = "2015-01-01"
    end_date = "2025-01-01"

    try:
        print("1. åŠ è½½å’Œå‡†å¤‡æ•°æ®")
        system.load_and_prepare_data(symbols, start_date, end_date)

        print("\\n2. åˆå§‹åŒ–é£é™©åˆ†æå¸ˆ")
        system.initialize_risk_analyst()

        print("\\n3. æŠ•èµ„ç»„åˆé£é™©åˆ†æ")
        report = system.run_portfolio_risk_analysis([0.25, 0.25, 0.25, 0.25], symbols)

        print("\\n4. å‹åŠ›æµ‹è¯•")
        stress_report = system.run_stress_testing("severe_recession", symbols)

        print("\\n5. ç”Ÿæˆé£é™©æŠ¥å‘Š")
        report_result = system.generate_risk_report(report, stress_report)
        print(report_result)

    except Exception as e:
        print(f"é”™è¯¯: {e}")
""",
        "explanation": "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„é£é™©ç®¡ç†ç³»ç»Ÿï¼Œé›†æˆäº†æ•°æ®è·å–ã€é¢„å¤„ç†ã€é£é™©åˆ†æå’ŒæŠ¥å‘ŠåŠŸèƒ½ã€‚è¯¥ç³»ç»Ÿå±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªå…¨é¢çš„é£é™©ç®¡ç†å¹³å°ï¼Œæ”¯æŒæŠ•èµ„ç»„åˆé£é™©åˆ†æå’Œå‹åŠ›æµ‹è¯•ã€‚"
    },
    # ä¸»é¢˜2ï¼šé‡åŒ–äº¤æ˜“ç­–ç•¥
    {
        "topic_id": 2,
        "category_id": 1,
        "title": "è·å–å¸‚åœºæ•°æ®",
        "code": """import yfinance as yf
import pandas as pd
import numpy as np

# è·å–è‚¡ç¥¨æ•°æ®
def get_stock_data(symbol, start_date, end_date):
    ticker = yf.Ticker(symbol)
    data = ticker.history(start=start_date, end=end_date)
    return data

# è·å–S&P 500æŒ‡æ•°æ•°æ®
sp500_data = get_stock_data("^GSPC", "2015-01-01", "2025-01-01")
print("S&P 500æŒ‡æ•°æ•°æ®å½¢çŠ¶:", sp500_data.shape)
print(sp500_data.head())

# è·å–å¤šä¸ªè‚¡ç¥¨æ•°æ®
symbols = ["AAPL", "GOOGL", "MSFT", "AMZN"]
all_data = pd.DataFrame()
for symbol in symbols:
    try:
        data = get_stock_data(symbol, "2015-01-01", "2025-01-01")
        data["Symbol"] = symbol
        all_data = pd.concat([all_data, data])
    except Exception as e:
        print(f"Error getting data for {symbol}: {e}")

print("æ‰€æœ‰è‚¡ç¥¨æ•°æ®å½¢çŠ¶:", all_data.shape)
print("æ•°æ®è¯´æ˜:", all_data.describe())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨yfinanceåº“è·å–è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬å•åªè‚¡ç¥¨å’Œå¤šåªè‚¡ç¥¨çš„æ•°æ®è·å–æ–¹æ³•ï¼Œå¹¶å¯¹è·å–åˆ°çš„æ•°æ®è¿›è¡ŒåŸºæœ¬çš„æŸ¥çœ‹å’Œç»Ÿè®¡åˆ†æã€‚é‡åŒ–äº¤æ˜“ç­–ç•¥çš„åŸºç¡€æ˜¯å¯é çš„æ•°æ®è·å–ã€‚"
    },
    {
        "topic_id": 2,
        "category_id": 2,
        "title": "æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np

# åŠ è½½æ•°æ®
data = pd.read_csv("sp500_data.csv", index_col="Date", parse_dates=True)

# æ•°æ®æ¸…æ´—
print("ç¼ºå¤±å€¼æ£€æŸ¥:")
print(data.isnull().sum())

# å¡«å……ç¼ºå¤±å€¼
data = data.fillna(method="ffill")

# è®¡ç®—æ”¶ç›Šç‡
data["Return"] = data["Close"].pct_change()

# è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
data["MA5"] = data["Close"].rolling(window=5).mean()
data["MA20"] = data["Close"].rolling(window=20).mean()
data["MA50"] = data["Close"].rolling(window=50).mean()

# è®¡ç®—å¸ƒæ—å¸¦
data["UpperBB"] = data["MA20"] + 2 * data["Close"].rolling(window=20).std()
data["LowerBB"] = data["MA20"] - 2 * data["Close"].rolling(window=20).std()

# è®¡ç®—RSIæŒ‡æ ‡
def calculate_rsi(data, window=14):
    delta = data["Close"].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

data["RSI"] = calculate_rsi(data)

# ä¿å­˜å¤„ç†åçš„æ•°æ®
data.to_csv("sp500_processed_data.csv")
print("é¢„å¤„ç†å®Œæˆ")
print(data.head())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹é‡åŒ–äº¤æ˜“æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€è®¡ç®—æ”¶ç›Šç‡ã€ç§»åŠ¨å¹³å‡çº¿ã€å¸ƒæ—å¸¦å’ŒRSIç­‰å¸¸ç”¨æŠ€æœ¯æŒ‡æ ‡ã€‚è¿™äº›å¤„ç†æ­¥éª¤æ˜¯é‡åŒ–ç­–ç•¥å¼€å‘çš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 2,
        "category_id": 3,
        "title": "ç®€å•ç§»åŠ¨å¹³å‡çº¿ç­–ç•¥",
        "code": """import pandas as pd
import numpy as np

# åŠ è½½æ•°æ®
data = pd.read_csv("sp500_processed_data.csv", index_col="Date", parse_dates=True)

# ç­–ç•¥å‚æ•°
short_window = 5
long_window = 20

# ç”Ÿæˆäº¤æ˜“ä¿¡å·
data["Signal"] = 0.0
data["Signal"][short_window:] = np.where(
    data["Close"][short_window:] > data["MA20"][short_window:], 1.0, 0.0
)
data["Position"] = data["Signal"].diff()

# å›æµ‹ç­–ç•¥
initial_capital = 100000.0
positions = pd.DataFrame(index=data.index).fillna(0.0)
positions["SP500"] = 100 * data["Signal"]
portfolio = positions.multiply(data["Close"], axis=0)

# è®¡ç®—æŠ•èµ„ç»„åˆä»·å€¼
pos_diff = positions.diff()
portfolio["Holdings"] = (positions.multiply(data["Close"], axis=0)).sum(axis=1)
portfolio["Cash"] = initial_capital - (pos_diff.multiply(data["Close"], axis=0)).sum(axis=1).cumsum()
portfolio["Total"] = portfolio["Cash"] + portfolio["Holdings"]
portfolio["Returns"] = portfolio["Total"].pct_change()

print("ç­–ç•¥å›æµ‹ç»“æœ:")
print(portfolio.tail())
print(f"æœ€ç»ˆæŠ•èµ„ç»„åˆä»·å€¼: ${portfolio['Total'][-1]:.2f}")
print(f"æ€»æ”¶ç›Šç‡: {((portfolio['Total'][-1] / initial_capital) - 1) * 100:.2f}%")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å®ç°ç®€å•çš„ç§»åŠ¨å¹³å‡çº¿äº¤å‰ç­–ç•¥ï¼ŒåŒ…æ‹¬äº¤æ˜“ä¿¡å·ç”Ÿæˆã€æŠ•èµ„ç»„åˆç®¡ç†å’Œç­–ç•¥å›æµ‹ã€‚è¿™æ˜¯é‡åŒ–äº¤æ˜“ç­–ç•¥ä¸­æœ€åŸºç¡€çš„ç­–ç•¥ä¹‹ä¸€ã€‚"
    },
    {
        "topic_id": 2,
        "category_id": 4,
        "title": "ç­–ç•¥å¯è§†åŒ–åˆ†æ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False

# åŠ è½½æ•°æ®å’Œå›æµ‹ç»“æœ
data = pd.read_csv("sp500_processed_data.csv", index_col="Date", parse_dates=True)
portfolio = pd.read_csv("portfolio.csv", index_col="Date", parse_dates=True)

# ç»˜åˆ¶ä»·æ ¼å’Œç§»åŠ¨å¹³å‡çº¿
plt.figure(figsize=(12, 6))
plt.plot(data["Close"], label="æ”¶ç›˜ä»·")
plt.plot(data["MA5"], label="5æ—¥å‡çº¿")
plt.plot(data["MA20"], label="20æ—¥å‡çº¿")

# ç»˜åˆ¶äº¤æ˜“ä¿¡å·
buy_signals = data[data["Position"] == 1.0]
sell_signals = data[data["Position"] == -1.0]
plt.scatter(buy_signals.index, data["Close"][buy_signals.index], marker="^", color="g", label="ä¹°å…¥ä¿¡å·")
plt.scatter(sell_signals.index, data["Close"][sell_signals.index], marker="v", color="r", label="å–å‡ºä¿¡å·")

plt.title("S&P 500ä»·æ ¼èµ°åŠ¿å’Œäº¤æ˜“ä¿¡å·")
plt.xlabel("æ—¥æœŸ")
plt.ylabel("ä»·æ ¼")
plt.legend()
plt.grid(True)
plt.savefig("price_with_signals.png")

# ç»˜åˆ¶æŠ•èµ„ç»„åˆä»·å€¼
plt.figure(figsize=(12, 6))
plt.plot(portfolio["Total"], label="æŠ•èµ„ç»„åˆä»·å€¼")
plt.title("æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–")
plt.xlabel("æ—¥æœŸ")
plt.ylabel("ä»·å€¼")
plt.legend()
plt.grid(True)
plt.savefig("portfolio_value.png")

# ç»˜åˆ¶æ”¶ç›Šç‡ç›´æ–¹å›¾
plt.figure(figsize=(12, 6))
sns.histplot(portfolio["Returns"].dropna(), kde=True)
plt.title("æŠ•èµ„ç»„åˆæ”¶ç›Šç‡åˆ†å¸ƒ")
plt.xlabel("æ”¶ç›Šç‡")
plt.ylabel("é¢‘ç‡")
plt.grid(True)
plt.savefig("returns_distribution.png")

plt.show()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯è§†åŒ–é‡åŒ–äº¤æ˜“ç­–ç•¥çš„æ‰§è¡Œæƒ…å†µï¼ŒåŒ…æ‹¬ä»·æ ¼èµ°åŠ¿ã€äº¤æ˜“ä¿¡å·å’ŒæŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–ã€‚é€šè¿‡å›¾è¡¨åˆ†æå¯ä»¥æ›´å¥½åœ°ç†è§£ç­–ç•¥çš„è¡¨ç°ã€‚"
    },
    {
        "topic_id": 2,
        "category_id": 5,
        "title": "æœºå™¨å­¦ä¹ äº¤æ˜“ç­–ç•¥",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# åŠ è½½æ•°æ®
data = pd.read_csv("sp500_processed_data.csv", index_col="Date", parse_dates=True)

# å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
data["Target"] = np.where(data["Close"].shift(-1) > data["Close"], 1, 0)
features = ["MA5", "MA20", "MA50", "UpperBB", "LowerBB", "RSI"]
X = data[features].dropna()
y = data["Target"].dropna()

# åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¯„ä¼°æ¨¡å‹
print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.4f}")
print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_pred))

# ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    "Feature": features,
    "Importance": model.feature_importances_
}).sort_values(by="Importance", ascending=False)

plt.figure(figsize=(10, 6))
plt.bar(feature_importance["Feature"], feature_importance["Importance"])
plt.title("ç‰¹å¾é‡è¦æ€§")
plt.xlabel("ç‰¹å¾")
plt.ylabel("é‡è¦æ€§")
plt.xticks(rotation=45)
plt.grid(True)
plt.savefig("feature_importance.png")

# ä¿å­˜é¢„æµ‹ç»“æœ
data["Prediction"] = 0
data.loc[X_test.index, "Prediction"] = y_pred
data.to_csv("predicted_data.csv")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆéšæœºæ£®æ—ï¼‰æ„å»ºäº¤æ˜“ç­–ç•¥ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œè¯„ä¼°ã€‚æœºå™¨å­¦ä¹ å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯†åˆ«æ›´å¤æ‚çš„äº¤æ˜“æ¨¡å¼ã€‚"
    },
    {
        "topic_id": 2,
        "category_id": 6,
        "title": "å®Œæ•´é‡åŒ–äº¤æ˜“ç³»ç»Ÿ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import yfinance as yf

class QuantitativeTradingSystem:
    def __init__(self, capital=100000.0, commission=0.001):
        self.capital = capital
        self.cash = capital
        self.shares_held = 0
        self.commission = commission
        self.trades = []

    def load_data(self, symbol, start_date, end_date):
        self.data = yf.download(symbol, start=start_date, end=end_date)
        self.calculate_indicators()

    def calculate_indicators(self):
        self.data["Return"] = self.data["Close"].pct_change()
        self.data["MA5"] = self.data["Close"].rolling(window=5).mean()
        self.data["MA20"] = self.data["Close"].rolling(window=20).mean()
        self.data["UpperBB"] = self.data["MA20"] + 2 * self.data["Close"].rolling(window=20).std()
        self.data["LowerBB"] = self.data["MA20"] - 2 * self.data["Close"].rolling(window=20).std()

    def generate_signals(self):
        self.data["Signal"] = 0.0
        self.data["Signal"] = np.where(
            (self.data["Close"] < self.data["LowerBB"]) & (self.data["MA5"] > self.data["MA20"]), 1.0, 0.0
        )
        self.data["Position"] = self.data["Signal"].diff()

    def backtest_strategy(self):
        portfolio = pd.DataFrame(index=self.data.index)
        portfolio["Holdings"] = self.shares_held * self.data["Close"]
        portfolio["Cash"] = self.cash
        portfolio["Total"] = portfolio["Holdings"] + portfolio["Cash"]

        for date in self.data.index:
            if self.data.loc[date, "Position"] == 1.0 and self.cash > 0:
                max_shares = int(self.cash / (self.data.loc[date, "Close"] * (1 + self.commission)))
                cost = max_shares * self.data.loc[date, "Close"] * (1 + self.commission)
                self.cash -= cost
                self.shares_held += max_shares
                self.trades.append({
                    "Date": date,
                    "Type": "Buy",
                    "Price": self.data.loc[date, "Close"],
                    "Shares": max_shares
                })

            elif self.data.loc[date, "Position"] == -1.0 and self.shares_held > 0:
                revenue = self.shares_held * self.data.loc[date, "Close"] * (1 - self.commission)
                self.cash += revenue
                self.trades.append({
                    "Date": date,
                    "Type": "Sell",
                    "Price": self.data.loc[date, "Close"],
                    "Shares": self.shares_held
                })
                self.shares_held = 0

            portfolio.loc[date, "Holdings"] = self.shares_held * self.data.loc[date, "Close"]
            portfolio.loc[date, "Cash"] = self.cash
            portfolio.loc[date, "Total"] = portfolio.loc[date, "Holdings"] + portfolio.loc[date, "Cash"]

        portfolio["Returns"] = portfolio["Total"].pct_change()
        return portfolio

    def print_performance(self, portfolio):
        final_value = portfolio["Total"][-1]
        total_return = ((final_value / self.capital) - 1) * 100
        annualized_return = (1 + total_return / 100) ** (252 / len(self.data)) - 1

        print(f"åˆå§‹èµ„æœ¬: ${self.capital:.2f}")
        print(f"æœ€ç»ˆä»·å€¼: ${final_value:.2f}")
        print(f"æ€»æ”¶ç›Šç‡: {total_return:.2f}%")
        print(f"å¹´åŒ–æ”¶ç›Šç‡: {annualized_return * 100:.2f}%")
        print(f"äº¤æ˜“æ¬¡æ•°: {len(self.trades)}")

    def plot_results(self, portfolio):
        plt.figure(figsize=(12, 8))

        plt.subplot(2, 1, 1)
        plt.plot(portfolio["Total"], label="æŠ•èµ„ç»„åˆä»·å€¼")
        plt.title("æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–")
        plt.legend()

        plt.subplot(2, 1, 2)
        plt.plot(self.data["Close"], label="ä»·æ ¼")
        plt.plot(self.data["MA5"], label="5æ—¥å‡çº¿")
        plt.plot(self.data["MA20"], label="20æ—¥å‡çº¿")
        plt.plot(self.data["UpperBB"], label="ä¸Šå¸ƒæ—å¸¦")
        plt.plot(self.data["LowerBB"], label="ä¸‹å¸ƒæ—å¸¦")
        plt.title("ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡")
        plt.legend()

        plt.tight_layout()
        plt.savefig("trading_system_results.png")

if __name__ == "__main__":
    system = QuantitativeTradingSystem(capital=100000)
    system.load_data("^GSPC", "2015-01-01", "2025-01-01")
    system.generate_signals()
    portfolio = system.backtest_strategy()
    system.print_performance(portfolio)
    system.plot_results(portfolio)
    print("\\näº¤æ˜“è¯¦æƒ…:")
    for trade in system.trades:
        print(f"{trade['Date']} - {trade['Type']}: {trade['Shares']}è‚¡ @ {trade['Price']:.2f}")
""",
        "explanation": "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„é‡åŒ–äº¤æ˜“ç³»ç»Ÿç±»ï¼ŒåŒ…å«æ•°æ®åŠ è½½ã€æŒ‡æ ‡è®¡ç®—ã€ä¿¡å·ç”Ÿæˆã€ç­–ç•¥å›æµ‹å’Œç»“æœåˆ†æç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚è¯¥ç³»ç»Ÿå®ç°äº†ä¸€ä¸ªåŸºäºå¸ƒæ—å¸¦å’Œç§»åŠ¨å¹³å‡çº¿çš„äº¤æ˜“ç­–ç•¥ï¼Œå±•ç¤ºäº†é‡åŒ–äº¤æ˜“çš„å®Œæ•´æµç¨‹ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 1,
        "title": "ä½¿ç”¨Yahoo Financeè·å–è‚¡ç¥¨æ•°æ®",
        "code": """import yfinance as yf
import pandas as pd

# è·å–è‹¹æœå…¬å¸è‚¡ç¥¨æ•°æ®
apple = yf.Ticker("AAPL")

# è·å–å†å²æ•°æ®
history = apple.history(period="1y")
print("è‹¹æœå…¬å¸è¿‘1å¹´è‚¡ç¥¨æ•°æ®:")
print(history.head())

# è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯
info = apple.info
print("\\nå…¬å¸åŸºæœ¬ä¿¡æ¯:")
print(f"å…¬å¸åç§°: {info['longName']}")
print(f"å½“å‰ä»·æ ¼: {info['currentPrice']}")
print(f"å¸‚å€¼: {info['marketCap']}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨yfinanceåº“ä»Yahoo Financeè·å–è‚¡ç¥¨å†å²æ•°æ®å’Œå…¬å¸åŸºæœ¬ä¿¡æ¯ã€‚yfinanceæ˜¯ä¸€ä¸ªå¼ºå¤§çš„é‡‘èæ•°æ®è·å–åº“ï¼Œæ”¯æŒè·å–å…¨çƒè‚¡ç¥¨ã€æŒ‡æ•°ã€ETFç­‰é‡‘èäº§å“çš„æ•°æ®ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 2,
        "title": "è‚¡ç¥¨æ•°æ®é¢„å¤„ç†",
        "code": """import yfinance as yf
import pandas as pd

# è·å–è‚¡ç¥¨æ•°æ®
df = yf.download("AAPL", start="2020-01-01", end="2023-12-31")

# æ•°æ®æ¸…æ´—
# æ£€æŸ¥ç¼ºå¤±å€¼
print("ç¼ºå¤±å€¼æ•°é‡:")
print(df.isnull().sum())

# å¡«å……ç¼ºå¤±å€¼
df = df.fillna(method="ffill")

# è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
df["MA5"] = df["Close"].rolling(window=5).mean()
df["MA20"] = df["Close"].rolling(window=20).mean()
df["Return"] = df["Close"].pct_change()

# ä¿å­˜å¤„ç†åçš„æ•°æ®
df.to_csv("apple_stock_processed.csv")
print("æ•°æ®å¤„ç†å®Œæˆï¼Œå·²ä¿å­˜åˆ°apple_stock_processed.csv")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ£€æŸ¥å’Œå¡«å……ç¼ºå¤±å€¼ï¼Œè®¡ç®—ç§»åŠ¨å¹³å‡çº¿ç­‰æŠ€æœ¯æŒ‡æ ‡ï¼Œä»¥åŠè®¡ç®—æ”¶ç›Šç‡ã€‚è¿™äº›å¤„ç†æ­¥éª¤æ˜¯é‡‘èæ•°æ®åˆ†æçš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 3,
        "title": "è‚¡ç¥¨æ•°æ®åˆ†æ",
        "code": """import pandas as pd
import numpy as np
from scipy.stats import norm

# è¯»å–å¤„ç†åçš„æ•°æ®
df = pd.read_csv("apple_stock_processed.csv", index_col="Date", parse_dates=True)

# è®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡
print("åŸºæœ¬ç»Ÿè®¡é‡:")
print(df["Close"].describe())

# è®¡ç®—æ”¶ç›Šç‡åˆ†å¸ƒ
returns = df["Return"].dropna()
print("\\næ”¶ç›Šç‡ç»Ÿè®¡:")
print(returns.describe())

# è®¡ç®—VaR (Value at Risk)
confidence_level = 0.95
VaR = norm.ppf(1 - confidence_level, returns.mean(), returns.std())
print(f"\\n95%ç½®ä¿¡æ°´å¹³çš„VaR: {VaR:.4f}")

# è®¡ç®—æœ€å¤§å›æ’¤
def calculate_max_drawdown(returns):
    cumulative = (1 + returns).cumprod()
    peak = cumulative.expanding(min_periods=1).max()
    drawdown = (cumulative - peak) / peak
    return drawdown.min()

max_drawdown = calculate_max_drawdown(returns)
print(f"æœ€å¤§å›æ’¤: {max_drawdown:.4f}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬è®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡ã€æ”¶ç›Šç‡åˆ†å¸ƒã€é£é™©ä»·å€¼(VaR)å’Œæœ€å¤§å›æ’¤ç­‰é‡è¦çš„é‡‘èæŒ‡æ ‡ã€‚è¿™äº›åˆ†æå¯¹äºæŠ•èµ„å†³ç­–è‡³å…³é‡è¦ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 4,
        "title": "è‚¡ç¥¨æ•°æ®å¯è§†åŒ–",
        "code": """import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False

# è¯»å–æ•°æ®
df = pd.read_csv("apple_stock_processed.csv", index_col="Date", parse_dates=True)

# åˆ›å»ºå›¾è¡¨
plt.figure(figsize=(12, 8))

# æ”¶ç›˜ä»·å’Œç§»åŠ¨å¹³å‡çº¿
plt.subplot(2, 2, 1)
plt.plot(df["Close"], label="æ”¶ç›˜ä»·")
plt.plot(df["MA5"], label="5æ—¥å‡çº¿")
plt.plot(df["MA20"], label="20æ—¥å‡çº¿")
plt.title("è‹¹æœå…¬å¸è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿")
plt.legend()

# æˆäº¤é‡
plt.subplot(2, 2, 2)
plt.bar(df.index, df["Volume"])
plt.title("æˆäº¤é‡")

# æ”¶ç›Šç‡åˆ†å¸ƒ
plt.subplot(2, 2, 3)
sns.histplot(df["Return"].dropna(), kde=True)
plt.title("æ”¶ç›Šç‡åˆ†å¸ƒ")

# ç›¸å…³ç³»æ•°çŸ©é˜µ
plt.subplot(2, 2, 4)
corr_matrix = df[["Open", "High", "Low", "Close", "Volume"]].corr()
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm")
plt.title("ç›¸å…³ç³»æ•°çŸ©é˜µ")

plt.tight_layout()
plt.savefig("stock_analysis.png", dpi=300, bbox_inches="tight")
plt.show()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨matplotlibå’Œseabornåº“å¯è§†åŒ–è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼èµ°åŠ¿ã€æˆäº¤é‡ã€æ”¶ç›Šç‡åˆ†å¸ƒå’Œç›¸å…³ç³»æ•°çŸ©é˜µã€‚å¯è§†åŒ–æ˜¯é‡‘èæ•°æ®åˆ†æä¸­é‡è¦çš„éƒ¨åˆ†ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æ•°æ®ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 5,
        "title": "ä½¿ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹è‚¡ç¥¨ä»·æ ¼",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®
df = pd.read_csv("apple_stock_processed.csv", index_col="Date", parse_dates=True)

# åˆ›å»ºç‰¹å¾å’Œæ ‡ç­¾
features = ["Open", "High", "Low", "Volume", "MA5", "MA20"]
X = df[features]
y = df["Close"]

# åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¯„ä¼°æ¨¡å‹
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"å‡æ–¹è¯¯å·®: {mse:.2f}")
print(f"RÂ²å¾—åˆ†: {r2:.2f}")

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label="çœŸå®ä»·æ ¼")
plt.plot(y_test.index, y_pred, label="é¢„æµ‹ä»·æ ¼")
plt.title("è‚¡ç¥¨ä»·æ ¼é¢„æµ‹")
plt.legend()
plt.savefig("prediction.png", dpi=300)
plt.show()

# è¾“å‡ºç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    "Feature": features,
    "Importance": model.coef_
}).sort_values(by="Importance", ascending=False)
print("\\nç‰¹å¾é‡è¦æ€§:")
print(feature_importance)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹é¢„æµ‹è‚¡ç¥¨ä»·æ ¼ã€‚æˆ‘ä»¬ä½¿ç”¨å†å²ä»·æ ¼ã€æˆäº¤é‡å’Œç§»åŠ¨å¹³å‡çº¿ä½œä¸ºç‰¹å¾ï¼Œè®­ç»ƒæ¨¡å‹å¹¶è¯„ä¼°å…¶æ€§èƒ½ã€‚æœºå™¨å­¦ä¹ åœ¨é‡‘èé¢„æµ‹ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚"
    },
    {
        "topic_id": 1,
        "category_id": 6,
        "title": "å®Œæ•´çš„è‚¡ç¥¨åˆ†æåº”ç”¨",
        "code": """import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm

class StockAnalyzer:
    def __init__(self, symbol):
        self.symbol = symbol
        self.ticker = yf.Ticker(symbol)
        self.data = None

    def download_data(self, period="1y"):
        \"\"\"ä¸‹è½½è‚¡ç¥¨å†å²æ•°æ®\"\"\"
        self.data = self.ticker.history(period=period)
        return self.data

    def calculate_technical_indicators(self):
        \"\"\"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡\"\"\"
        if self.data is None:
            raise ValueError("è¯·å…ˆä¸‹è½½æ•°æ®")

        # ç§»åŠ¨å¹³å‡çº¿
        self.data["MA5"] = self.data["Close"].rolling(window=5).mean()
        self.data["MA20"] = self.data["Close"].rolling(window=20).mean()

        # æ”¶ç›Šç‡
        self.data["Return"] = self.data["Close"].pct_change()

        return self.data

    def analyze_risk(self, confidence_level=0.95):
        \"\"\"é£é™©åˆ†æ\"\"\"
        returns = self.data["Return"].dropna()

        # VaRè®¡ç®—
        VaR = norm.ppf(1 - confidence_level, returns.mean(), returns.std())

        # æœ€å¤§å›æ’¤è®¡ç®—
        cumulative = (1 + returns).cumprod()
        peak = cumulative.expanding(min_periods=1).max()
        drawdown = (cumulative - peak) / peak
        max_drawdown = drawdown.min()

        return {
            "VaR": VaR,
            "max_drawdown": max_drawdown,
            "mean_return": returns.mean(),
            "std_return": returns.std()
        }

    def visualize(self):
        \"\"\"æ•°æ®å¯è§†åŒ–\"\"\"
        plt.rcParams["font.sans-serif"] = ["SimHei"]
        plt.rcParams["axes.unicode_minus"] = False

        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # ä»·æ ¼èµ°åŠ¿
        axes[0, 0].plot(self.data.index, self.data["Close"], label="æ”¶ç›˜ä»·")
        axes[0, 0].plot(self.data.index, self.data["MA5"], label="5æ—¥å‡çº¿")
        axes[0, 0].plot(self.data.index, self.data["MA20"], label="20æ—¥å‡çº¿")
        axes[0, 0].set_title(f"{self.symbol}è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿")
        axes[0, 0].legend()

        # æˆäº¤é‡
        axes[0, 1].bar(self.data.index, self.data["Volume"])
        axes[0, 1].set_title("æˆäº¤é‡")

        # æ”¶ç›Šç‡åˆ†å¸ƒ
        sns.histplot(self.data["Return"].dropna(), kde=True, ax=axes[1, 0])
        axes[1, 0].set_title("æ”¶ç›Šç‡åˆ†å¸ƒ")

        # ç›¸å…³ç³»æ•°çŸ©é˜µ
        corr_matrix = self.data[["Open", "High", "Low", "Close", "Volume"]].corr()
        sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", ax=axes[1, 1])
        axes[1, 1].set_title("ç›¸å…³ç³»æ•°çŸ©é˜µ")

        plt.tight_layout()
        plt.savefig(f"{self.symbol}_analysis.png", dpi=300)
        plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = StockAnalyzer("AAPL")
    analyzer.download_data()
    analyzer.calculate_technical_indicators()

    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    info = analyzer.ticker.info
    print(f"å…¬å¸åç§°: {info['longName']}")
    print(f"å½“å‰ä»·æ ¼: {info['currentPrice']:.2f}")

    # é£é™©åˆ†æ
    risk_info = analyzer.analyze_risk()
    print(f"\\né£é™©åˆ†æç»“æœ:")
    print(f"å¹³å‡æ”¶ç›Šç‡: {risk_info['mean_return']:.4f}")
    print(f"æ”¶ç›Šç‡æ ‡å‡†å·®: {risk_info['std_return']:.4f}")
    print(f"95%ç½®ä¿¡æ°´å¹³VaR: {risk_info['VaR']:.4f}")
    print(f"æœ€å¤§å›æ’¤: {risk_info['max_drawdown']:.4f}")

    # å¯è§†åŒ–
    analyzer.visualize()
""",
        "explanation": "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„è‚¡ç¥¨åˆ†æåº”ç”¨ç¨‹åºï¼Œå®ƒå°†ä¹‹å‰æ¼”ç¤ºçš„æ‰€æœ‰åŠŸèƒ½æ•´åˆåˆ°ä¸€ä¸ªç±»ä¸­ã€‚è¿™ä¸ªåº”ç”¨ç¨‹åºå¯ä»¥ä¸‹è½½æ•°æ®ã€è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ã€è¿›è¡Œé£é™©åˆ†æå’Œæ•°æ®å¯è§†åŒ–ã€‚é€šè¿‡è¿™ä¸ªç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥äº†è§£å¦‚ä½•æ„å»ºä¸€ä¸ªå®Œæ•´çš„é‡‘èåº”ç”¨é¡¹ç›®ã€‚"
    },
    # ä¸»é¢˜6ï¼šå€ºåˆ¸è®¡ç®—å·¥å…·
    {
        "topic_id": 6,
        "category_id": 1,
        "title": "å€ºåˆ¸åŸºæœ¬ä¿¡æ¯è·å–",
        "code": """import requests
import pandas as pd
from datetime import datetime

def get_treasury_rates():
    \"\"\"è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®\"\"\"
    try:
        # ä½¿ç”¨Yahoo Financeè·å–10å¹´æœŸç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®
        url = "https://query1.finance.yahoo.com/v8/finance/chart/%5ETNX"
        params = {
            "period1": int(datetime(2024, 1, 1).timestamp()),
            "period2": int(datetime.now().timestamp()),
            "interval": "1d",
            "includePrePost": "false"
        }

        response = requests.get(url, params=params)
        data = response.json()

        if 'chart' in data and 'result' in data['chart'] and len(data['chart']['result']) > 0:
            timestamps = data['chart']['result'][0]['timestamp']
            rates = data['chart']['result'][0]['indicators']['quote'][0]['close']

            df = pd.DataFrame({
                'Date': [datetime.fromtimestamp(ts) for ts in timestamps],
                'Rate': rates
            })
            df.set_index('Date', inplace=True)
            return df

        return pd.DataFrame()

    except Exception as e:
        print(f"è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def get_corporate_bond_data():
    \"\"\"è·å–å…¬å¸å€ºåˆ¸æ•°æ®\"\"\"
    try:
        # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å…¬å¸å€ºåˆ¸æ•°æ®
        data = {
            'Name': ['Apple Inc.', 'Microsoft Corp.', 'Amazon.com Inc.',
                    'Google LLC', 'Facebook Inc.', 'Tesla Inc.'],
            'Symbol': ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'FB', 'TSLA'],
            'Rating': ['AA+', 'AAA', 'AA', 'AA+', 'A+', 'B-'],
            'Coupon Rate (%)': [4.25, 3.75, 4.50, 4.00, 3.50, 5.75],
            'Maturity Date': ['2034-01-15', '2033-06-30', '2035-12-01',
                            '2034-09-30', '2033-03-15', '2032-11-15'],
            'YTM (%)': [4.50, 4.25, 4.75, 4.35, 4.10, 6.25],
            'Price': [98.50, 101.25, 97.75, 100.50, 102.75, 95.25]
        }

        df = pd.DataFrame(data)
        df['Maturity Date'] = pd.to_datetime(df['Maturity Date'])

        return df

    except Exception as e:
        print(f"è·å–å…¬å¸å€ºåˆ¸æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def get_bond_quote(symbol):
    \"\"\"è·å–å•ä¸ªå€ºåˆ¸æŠ¥ä»·\"\"\"
    try:
        # è¿™é‡Œä½¿ç”¨ç¤ºä¾‹æ•°æ®
        bond_data = {
            'AAPL.BN': {
                'Name': 'Apple Inc. Bond 2034',
                'Rating': 'AA+',
                'Coupon': 4.25,
                'Maturity': '2034-01-15',
                'Price': 98.50,
                'YTM': 4.50
            },
            'MSFT.BN': {
                'Name': 'Microsoft Corp. Bond 2033',
                'Rating': 'AAA',
                'Coupon': 3.75,
                'Maturity': '2033-06-30',
                'Price': 101.25,
                'YTM': 4.25
            },
            'AMZN.BN': {
                'Name': 'Amazon.com Inc. Bond 2035',
                'Rating': 'AA',
                'Coupon': 4.50,
                'Maturity': '2035-12-01',
                'Price': 97.75,
                'YTM': 4.75
            }
        }

        if symbol in bond_data:
            return pd.DataFrame([bond_data[symbol]])
        else:
            return pd.DataFrame()

    except Exception as e:
        print(f"è·å–å€ºåˆ¸æŠ¥ä»·å¤±è´¥: {str(e)}")
        return pd.DataFrame()

# ä½¿ç”¨ç¤ºä¾‹
# è·å–å›½å€ºæ”¶ç›Šç‡æ•°æ®
treasury_rates = get_treasury_rates()
print("ç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®:\\n", treasury_rates.tail())

# è·å–å…¬å¸å€ºåˆ¸æ•°æ®
corporate_bonds = get_corporate_bond_data()
print("\\nå…¬å¸å€ºåˆ¸æ•°æ®:\\n", corporate_bonds.head())

# è·å–å•ä¸ªå€ºåˆ¸æŠ¥ä»·
apple_bond = get_bond_quote('AAPL.BN')
print("\\nAppleå…¬å¸å€ºåˆ¸æŠ¥ä»·:\\n", apple_bond)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è·å–å€ºåˆ¸å¸‚åœºæ•°æ®ï¼ŒåŒ…æ‹¬ç¾å›½å›½å€ºæ”¶ç›Šç‡ã€å…¬å¸å€ºåˆ¸æ•°æ®å’Œå•ä¸ªå€ºåˆ¸æŠ¥ä»·ã€‚æˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦è®¿é—®ä¸“ä¸šçš„å€ºåˆ¸æ•°æ®APIã€‚"
    },
    {
        "topic_id": 6,
        "category_id": 2,
        "title": "å€ºåˆ¸æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime

def calculate_time_to_maturity(maturity_date):
    \"\"\"è®¡ç®—å‰©ä½™æœŸé™\"\"\"
    today = datetime.now()
    time_to_maturity = (maturity_date - today).days / 365
    return max(time_to_maturity, 0)

def calculate_accrued_interest(settlement_date, maturity_date, coupon_rate, face_value=1000, frequency=2):
    \"\"\"è®¡ç®—åº”è®¡åˆ©æ¯\"\"\"
    period_days = 365 / frequency
    last_coupon_date = maturity_date
    while last_coupon_date > settlement_date:
        last_coupon_date -= pd.DateOffset(months=6)

    next_coupon_date = last_coupon_date + pd.DateOffset(months=6)
    days_since_coupon = (settlement_date - last_coupon_date).days
    days_in_period = (next_coupon_date - last_coupon_date).days

    accrued_interest = (coupon_rate / 100 / frequency) * (days_since_coupon / days_in_period) * face_value

    return accrued_interest

def bond_data_preprocessing(bond_data):
    \"\"\"å€ºåˆ¸æ•°æ®é¢„å¤„ç†\"\"\"
    processed_data = bond_data.copy()

    processed_data['Time to Maturity (Years)'] = processed_data['Maturity Date'].apply(calculate_time_to_maturity)

    processed_data['Accrued Interest'] = processed_data.apply(
        lambda row: calculate_accrued_interest(
            settlement_date=datetime.now(),
            maturity_date=row['Maturity Date'],
            coupon_rate=row['Coupon Rate (%)'],
            face_value=1000
        ),
        axis=1
    )

    processed_data['Duration'] = processed_data.apply(
        lambda row: (row['Coupon Rate (%)'] / 100) / row['YTM (%)'] * 100,
        axis=1
    )

    processed_data['Convexity'] = processed_data.apply(
        lambda row: ((1 + row['YTM (%)'] / 100) / (row['YTM (%)'] / 100)) ** 2,
        axis=1
    )

    processed_data['Price Change (%)'] = 0

    processed_data['Price Category'] = processed_data['Price'].apply(
        lambda x: 'æº¢ä»·' if x > 100 else 'æŠ˜ä»·' if x < 100 else 'å¹³ä»·'
    )

    return processed_data

# ä½¿ç”¨ç¤ºä¾‹
# å‡è®¾æˆ‘ä»¬æœ‰ä¹‹å‰è·å–çš„å…¬å¸å€ºåˆ¸æ•°æ®
# corporate_bonds = get_corporate_bond_data()
# processed_bonds = bond_data_preprocessing(corporate_bonds)
# print("\\né¢„å¤„ç†åçš„å…¬å¸å€ºåˆ¸æ•°æ®:\\n", processed_bonds.head())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹å€ºåˆ¸æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬è®¡ç®—å‰©ä½™æœŸé™ã€åº”è®¡åˆ©æ¯ã€ä¹…æœŸå’Œå‡¸æ€§ç­‰é‡è¦æŒ‡æ ‡ã€‚è¿™äº›æŒ‡æ ‡å¯¹äºå€ºåˆ¸åˆ†æå’ŒæŠ•èµ„å†³ç­–éå¸¸é‡è¦ã€‚"
    },
    {
        "topic_id": 6,
        "category_id": 3,
        "title": "å€ºåˆ¸å®šä»·ä¸YTMè®¡ç®—",
        "code": """import math
from datetime import datetime
import pandas as pd

def calculate_bond_price(coupon_rate, face_value, ytm, time_to_maturity, frequency=2):
    \"\"\"è®¡ç®—å€ºåˆ¸ä»·æ ¼\"\"\"
    price = 0
    coupon_payment = (coupon_rate / 100 / frequency) * face_value
    periods = time_to_maturity * frequency

    for i in range(1, int(periods) + 1):
        price += coupon_payment / (1 + (ytm / 100 / frequency)) ** i

    price += face_value / (1 + (ytm / 100 / frequency)) ** periods

    return price

def calculate_ytm(price, coupon_rate, face_value, time_to_maturity, frequency=2):
    \"\"\"è®¡ç®—åˆ°æœŸæ”¶ç›Šç‡(YTM)\"\"\"
    tolerance = 1e-5
    max_iterations = 1000

    ytm_guess = coupon_rate

    for _ in range(max_iterations):
        price_guess = calculate_bond_price(coupon_rate, face_value, ytm_guess, time_to_maturity, frequency)
        price_diff = price_guess - price

        if abs(price_diff) < tolerance:
            return ytm_guess

        derivative = 0
        coupon_payment = (coupon_rate / 100 / frequency) * face_value
        periods = time_to_maturity * frequency

        for i in range(1, int(periods) + 1):
            derivative -= i * coupon_payment / (1 + (ytm_guess / 100 / frequency)) ** (i + 1)
            derivative -= i * face_value / (1 + (ytm_guess / 100 / frequency)) ** (i + 1)

        ytm_guess -= price_diff / derivative

    return None

def calculate_accrued_interest(settlement_date, maturity_date, coupon_rate, face_value=1000, frequency=2):
    \"\"\"è®¡ç®—åº”è®¡åˆ©æ¯\"\"\"
    period_days = 365 / frequency
    last_coupon_date = maturity_date
    while last_coupon_date > settlement_date:
        last_coupon_date -= pd.DateOffset(months=6)

    next_coupon_date = last_coupon_date + pd.DateOffset(months=6)
    days_since_coupon = (settlement_date - last_coupon_date).days
    days_in_period = (next_coupon_date - last_coupon_date).days

    accrued_interest = (coupon_rate / 100 / frequency) * (days_since_coupon / days_in_period) * face_value

    return accrued_interest

# ä½¿ç”¨ç¤ºä¾‹
# è®¡ç®—å€ºåˆ¸ä»·æ ¼
price = calculate_bond_price(4.25, 1000, 4.50, 10, 2)
print(f\"å€ºåˆ¸ä»·æ ¼: ${price:.2f}\")

# è®¡ç®—YTM
ytm = calculate_ytm(985, 4.25, 1000, 10, 2)
print(f\"åˆ°æœŸæ”¶ç›Šç‡: {ytm:.2f}%\")

# è®¡ç®—åº”è®¡åˆ©æ¯
settlement_date = datetime(2024, 4, 9)
maturity_date = datetime(2034, 1, 15)

accrued_interest = calculate_accrued_interest(settlement_date, maturity_date, 4.25, 1000, 2)
print(f\"åº”è®¡åˆ©æ¯: ${accrued_interest:.2f}\")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è®¡ç®—å€ºåˆ¸ä»·æ ¼å’Œåˆ°æœŸæ”¶ç›Šç‡(YTM)ã€‚å€ºåˆ¸ä»·æ ¼æ˜¯æ ¹æ®å€ºåˆ¸çš„ç¥¨é¢åˆ©ç‡ã€é¢å€¼ã€åˆ°æœŸæ”¶ç›Šç‡å’Œå‰©ä½™æœŸé™è®¡ç®—å¾—å‡ºçš„ã€‚YTMæ˜¯ä½¿å€ºåˆ¸æœªæ¥ç°é‡‘æµç°å€¼ç­‰äºå½“å‰ä»·æ ¼çš„è´´ç°ç‡ã€‚"
    },
    {
        "topic_id": 6,
        "category_id": 4,
        "title": "å€ºåˆ¸æ•°æ®å¯è§†åŒ–",
        "code": """import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def plot_coupon_vs_price(df):
    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x='Coupon Rate (%)', y='Price')
    plt.title('ç¥¨é¢åˆ©ç‡ä¸ä»·æ ¼å…³ç³»')
    plt.xlabel('ç¥¨é¢åˆ©ç‡ (%)')
    plt.ylabel('ä»·æ ¼')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('coupon_vs_price.png')
    plt.show()

def plot_rating_vs_price(df):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=df, x='Rating', y='Price')
    plt.title('ä¿¡ç”¨è¯„çº§ä¸ä»·æ ¼å…³ç³»')
    plt.xlabel('ä¿¡ç”¨è¯„çº§')
    plt.ylabel('ä»·æ ¼')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('rating_vs_price.png')
    plt.show()

def plot_duration_vs_price(df):
    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x='Duration', y='Price')
    plt.title('ä¹…æœŸä¸ä»·æ ¼å…³ç³»')
    plt.xlabel('ä¹…æœŸ')
    plt.ylabel('ä»·æ ¼')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('duration_vs_price.png')
    plt.show()

def plot_price_by_rating(df):
    plt.figure(figsize=(12, 8))
    sns.boxplot(data=df, x='Rating', y='Price')
    sns.stripplot(data=df, x='Rating', y='Price', color='black', alpha=0.3)
    plt.title('æŒ‰ä¿¡ç”¨è¯„çº§åˆ†ç»„çš„ä»·æ ¼åˆ†å¸ƒ')
    plt.xlabel('ä¿¡ç”¨è¯„çº§')
    plt.ylabel('ä»·æ ¼')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('price_by_rating.png')
    plt.show()

def plot_bond_cash_flows(coupon_rate, face_value, time_to_maturity, frequency=2):
    cash_flows = []
    coupon_payment = (coupon_rate / 100 / frequency) * face_value
    periods = int(time_to_maturity * frequency)

    for i in range(1, periods + 1):
        cash_flows.append(coupon_payment)

    cash_flows[-1] += face_value

    plt.figure(figsize=(12, 6))
    plt.bar(range(1, periods + 1), cash_flows, color='skyblue')
    plt.title('å€ºåˆ¸ç°é‡‘æµé‡å›¾')
    plt.xlabel('ä»˜æ¯æœŸ')
    plt.ylabel('ç°é‡‘æµ')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('cash_flows.png')
    plt.show()

def plot_yield_curve(treasury_rates):
    if not treasury_rates.empty:
        plt.figure(figsize=(12, 8))
        plt.plot(treasury_rates.index, treasury_rates['Rate'])
        plt.title('ç¾å›½å›½å€ºæ”¶ç›Šç‡æ›²çº¿')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('æ”¶ç›Šç‡ (%)')
        plt.grid(True)
        plt.tight_layout()
        plt.savefig('yield_curve.png')
        plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²ç»æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼‰
# corporate_bonds = get_corporate_bond_data()
# processed_bonds = bond_data_preprocessing(corporate_bonds)
# plot_coupon_vs_price(processed_bonds)
# plot_rating_vs_price(processed_bonds)
# plot_duration_vs_price(processed_bonds)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯è§†åŒ–å€ºåˆ¸æ•°æ®ï¼ŒåŒ…æ‹¬ç¥¨é¢åˆ©ç‡ä¸ä»·æ ¼å…³ç³»ã€ä¿¡ç”¨è¯„çº§ä¸ä»·æ ¼å…³ç³»ã€ä¹…æœŸä¸ä»·æ ¼å…³ç³»ä»¥åŠæ”¶ç›Šç‡æ›²çº¿ç­‰å›¾è¡¨ã€‚è¿™äº›å›¾è¡¨å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£å€ºåˆ¸å¸‚åœºè¶‹åŠ¿ã€‚"
    },
    {
        "topic_id": 6,
        "category_id": 5,
        "title": "å€ºåˆ¸é£é™©åˆ†æ",
        "code": """import numpy as np
from scipy import stats

def calculate_bond_risk(price, duration, convexity, yield_change=0.01):
    duration_change = -duration * yield_change * price
    convexity_change = 0.5 * convexity * (yield_change ** 2) * price
    total_change = duration_change + convexity_change
    price_change_percent = (total_change / price) * 100

    return duration_change, convexity_change, total_change, price_change_percent

def calculate_credit_spread(rating):
    rating_spreads = {
        'AAA': 0.50, 'AA+': 0.75, 'AA': 1.00, 'AA-': 1.25,
        'A+': 1.50, 'A': 1.75, 'A-': 2.00, 'BBB+': 2.50,
        'BBB': 3.00, 'BBB-': 3.50, 'BB+': 4.50, 'BB': 5.50,
        'BB-': 6.50, 'B+': 7.50, 'B': 8.50, 'B-': 9.50,
        'CCC+': 10.50, 'CCC': 11.50, 'CCC-': 12.50
    }
    return rating_spreads.get(rating, 13.00)

def calculate_default_probability(rating):
    rating_default_rates = {
        'AAA': 0.00, 'AA+': 0.01, 'AA': 0.02, 'AA-': 0.03,
        'A+': 0.05, 'A': 0.07, 'A-': 0.10, 'BBB+': 0.15,
        'BBB': 0.20, 'BBB-': 0.25, 'BB+': 0.40, 'BB': 0.60,
        'BB-': 0.90, 'B+': 1.20, 'B': 1.60, 'B-': 2.10,
        'CCC+': 3.00, 'CCC': 4.00, 'CCC-': 5.00
    }
    return rating_default_rates.get(rating, 6.00)

def calculate_var(duration, convexity, yield_volatility, confidence_level=0.95, time_period=1):
    yield_change_std = yield_volatility * np.sqrt(time_period)
    z_score = stats.norm.ppf(1 - confidence_level)
    yield_change = z_score * yield_change_std

    duration_change = -duration * yield_change
    convexity_change = 0.5 * convexity * (yield_change ** 2)

    total_change = duration_change + convexity_change
    return total_change

def analyze_risk(bonds_data):
    bonds_data['Credit Spread'] = bonds_data['Rating'].apply(calculate_credit_spread)
    bonds_data['Default Probability'] = bonds_data['Rating'].apply(calculate_default_probability)
    bonds_data['Credit Risk Score'] = bonds_data['Default Probability'] * bonds_data['Duration']

    bonds_data['Price Change (%)'] = bonds_data.apply(
        lambda row: calculate_bond_risk(row['Price'], row['Duration'], row['Convexity'])[3],
        axis=1
    )

    return bonds_data

# ä½¿ç”¨ç¤ºä¾‹
# corporate_bonds = get_corporate_bond_data()
# processed_bonds = bond_data_preprocessing(corporate_bonds)
# risk_analysis = analyze_risk(processed_bonds)
# print(\"\\né£é™©åˆ†æç»“æœ:\\n\", risk_analysis[['Symbol', 'Name', 'Credit Spread', 'Default Probability', 'Credit Risk Score']])
#
# duration_change, convexity_change, total_change, price_change_percent = calculate_bond_risk(98.50, 8.50, 125.32, yield_change=0.01)
# print(f\"\\nä»·æ ¼å˜åŒ–åˆ†æ:\\nä¹…æœŸæ•ˆåº”: {duration_change:.2f}\\nå‡¸æ€§æ•ˆåº”: {convexity_change:.2f}\\næ€»å˜åŒ–: {total_change:.2f}\\nå˜åŒ–ç™¾åˆ†æ¯”: {price_change_percent:.2f}%\")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è¿›è¡Œå€ºåˆ¸é£é™©åˆ†æï¼ŒåŒ…æ‹¬ä¿¡ç”¨åˆ©å·®ã€è¿çº¦æ¦‚ç‡ã€VaRå’Œä»·æ ¼å˜åŒ–æ•æ„Ÿåº¦ç­‰è®¡ç®—ã€‚å€ºåˆ¸é£é™©åˆ†æå¯¹äºæŠ•èµ„è€…åœ¨è´­ä¹°å€ºåˆ¸å‰è¯„ä¼°é£é™©éå¸¸é‡è¦ã€‚"
    },
    {
        "topic_id": 6,
        "category_id": 6,
        "title": "å€ºåˆ¸æŠ•èµ„ç­–ç•¥",
        "code": """import pandas as pd

class BondPortfolio:
    def __init__(self, bonds_data):
        self.bonds_data = bonds_data
        self.positions = {}
        self.total_value = 0

    def add_bond(self, symbol, quantity):
        if symbol in self.bonds_data['Symbol'].values:
            bond_info = self.bonds_data[self.bonds_data['Symbol'] == symbol].iloc[0]
            self.positions[symbol] = {
                'Quantity': quantity,
                'Price': bond_info['Price'],
                'Coupon Rate (%)': bond_info['Coupon Rate (%)'],
                'Maturity Date': bond_info['Maturity Date'],
                'Duration': bond_info['Duration'],
                'Convexity': bond_info['Convexity']
            }
            self.update_total_value()
        else:
            print(f"å€ºåˆ¸ {symbol} æœªæ‰¾åˆ°")

    def remove_bond(self, symbol):
        if symbol in self.positions:
            del self.positions[symbol]
            self.update_total_value()
        else:
            print(f"å€ºåˆ¸ {symbol} æœªåœ¨æŠ•èµ„ç»„åˆä¸­æ‰¾åˆ°")

    def update_total_value(self):
        total = 0

        for symbol, info in self.positions.items():
            total += info['Quantity'] * info['Price']

        self.total_value = total

    def get_portfolio_summary(self):
        if not self.positions:
            return pd.DataFrame()

        positions_data = []

        for symbol, info in self.positions.items():
            positions_data.append({
                'Symbol': symbol,
                'Quantity': info['Quantity'],
                'Price': info['Price'],
                'Value': info['Quantity'] * info['Price'],
                'Duration': info['Duration'],
                'Convexity': info['Convexity']
            })

        df = pd.DataFrame(positions_data)
        df['Weight'] = df['Value'] / df['Value'].sum()

        weighted_duration = (df['Duration'] * df['Weight']).sum()
        weighted_convexity = (df['Convexity'] * df['Weight']).sum()

        summary = {
            'Total Value': df['Value'].sum(),
            'Number of Bonds': len(self.positions),
            'Average Duration': weighted_duration,
            'Average Convexity': weighted_convexity
        }

        return df, summary

    def rebalance_portfolio(self, target_weights):
        if not self.positions:
            print("æŠ•èµ„ç»„åˆä¸ºç©º")
            return

        current_values = {symbol: info['Quantity'] * info['Price'] for symbol, info in self.positions.items()}
        total_value = sum(current_values.values())
        target_values = {symbol: total_value * weight for symbol, weight in target_weights.items()}

        for symbol, target_value in target_values.items():
            if symbol in self.positions:
                current_value = current_values[symbol]
                current_price = self.positions[symbol]['Price']
                target_quantity = int(target_value / current_price)
                self.positions[symbol]['Quantity'] = target_quantity

        self.update_total_value()

    def plot_duration_distribution(self):
        if not self.positions:
            print("æŠ•èµ„ç»„åˆä¸ºç©º")
            return

        positions_data = []

        for symbol, info in self.positions.items():
            positions_data.append({
                'Symbol': symbol,
                'Duration': info['Duration'],
                'Quantity': info['Quantity']
            })

        df = pd.DataFrame(positions_data)
        plt.figure(figsize=(12, 8))
        plt.hist(df['Duration'], bins=10, color='skyblue', edgecolor='black')
        plt.title('æŠ•èµ„ç»„åˆä¹…æœŸåˆ†å¸ƒ')
        plt.xlabel('ä¹…æœŸ')
        plt.ylabel('é¢‘ç‡')
        plt.grid(True)
        plt.tight_layout()
        plt.savefig('duration_distribution.png')
        plt.show()

    def plot_coupon_distribution(self):
        if not self.positions:
            print("æŠ•èµ„ç»„åˆä¸ºç©º")
            return

        positions_data = []

        for symbol, info in self.positions.items():
            positions_data.append({
                'Symbol': symbol,
                'Coupon Rate': info['Coupon Rate (%)'],
                'Quantity': info['Quantity']
            })

        df = pd.DataFrame(positions_data)
        plt.figure(figsize=(12, 8))
        plt.hist(df['Coupon Rate'], bins=10, color='skyblue', edgecolor='black')
        plt.title('æŠ•èµ„ç»„åˆç¥¨é¢åˆ©ç‡åˆ†å¸ƒ')
        plt.xlabel('ç¥¨é¢åˆ©ç‡ (%)')
        plt.ylabel('é¢‘ç‡')
        plt.grid(True)
        plt.tight_layout()
        plt.savefig('coupon_distribution.png')
        plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# portfolio = BondPortfolio(corporate_bonds)
# portfolio.add_bond('AAPL', 100)
# portfolio.add_bond('MSFT', 200)
# portfolio.add_bond('AMZN', 50)
# positions_df, summary = portfolio.get_portfolio_summary()
# print("æŠ•èµ„ç»„åˆæ‘˜è¦:\\n", positions_df)
# print("\\næŠ•èµ„ç»„åˆç»Ÿè®¡:\\n", summary)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªå€ºåˆ¸æŠ•èµ„ç»„åˆç±»ï¼Œç”¨äºç®¡ç†å€ºåˆ¸æŒä»“å’Œåˆ†ææŠ•èµ„ç»„åˆé£é™©ã€‚æŠ•èµ„ç»„åˆç±»æä¾›äº†æ·»åŠ /ç§»é™¤å€ºåˆ¸ã€é‡æ–°å¹³è¡¡æŠ•èµ„ç»„åˆå’Œåˆ†ææŠ•èµ„ç»„åˆä¹…æœŸåˆ†å¸ƒçš„åŠŸèƒ½ã€‚"
    },
    # ä¸»é¢˜7ï¼šæˆ¿åœ°äº§æŠ•èµ„åˆ†æ
    {
        "topic_id": 7,
        "category_id": 1,
        "title": "æˆ¿åœ°äº§æ•°æ®è·å–",
        "code": """import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime

def get_house_listings(city, pages=1):
    \"\"\"è·å–æˆ¿åœ°äº§ listings æ•°æ®\"\"\"
    all_listings = []

    try:
        for page in range(1, pages + 1):
            # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦è®¿é—®çœŸå®çš„æˆ¿åœ°äº§APIï¼‰
            print(f"æ­£åœ¨è·å–ç¬¬{page}é¡µæ•°æ®...")

            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            for i in range(10):
                listing = {
                    "id": f"{city}_{page}_{i}",
                    "title": f"{city}ä¼˜è´¨æˆ¿æº {page}-{i}",
                    "price": 300000 + (page - 1) * 50000 + i * 10000,
                    "bedrooms": 2 + (i % 3),
                    "bathrooms": 1 + (i % 2),
                    "sqft": 800 + i * 100,
                    "address": f"{city}å¸‚æœé˜³åŒºç¬¬{page}è¡—é“{i}å·",
                    "listing_date": datetime(2024, 1, 1) + pd.Timedelta(days=(page - 1) * 30 + i)
                }
                all_listings.append(listing)

        df = pd.DataFrame(all_listings)
        return df

    except Exception as e:
        print(f"è·å–æˆ¿åœ°äº§æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def get_property_details(property_id):
    \"\"\"è·å–å•ä¸ªæˆ¿äº§è¯¦ç»†ä¿¡æ¯\"\"\"
    try:
        # æ¨¡æ‹Ÿè·å–æˆ¿äº§è¯¦ç»†ä¿¡æ¯
        details = {
            "id": property_id,
            "property_type": "å…¬å¯“",
            "year_built": 2015 + (int(property_id[-1]) % 5),
            "amenities": ["ç”µæ¢¯", "åœè½¦ä½", "å¥èº«æˆ¿", "æ¸¸æ³³æ± "],
            "tax_assessment": 280000 + (int(property_id[-1]) % 10) * 5000,
            "last_sold_price": 295000 + (int(property_id[-1]) % 10) * 3000,
            "last_sold_date": datetime(2023, 1, 1) + pd.Timedelta(days=int(property_id[-1]) * 50)
        }

        return details

    except Exception as e:
        print(f"è·å–æˆ¿äº§{property_id}è¯¦æƒ…å¤±è´¥: {str(e)}")
        return {}

def get_neighborhood_data(city):
    \"\"\"è·å–å°åŒºå‘¨è¾¹æ•°æ®\"\"\"
    try:
        neighborhoods = [
            {
                "name": f"{city}å°åŒºA",
                "avg_price": 350000,
                "price_per_sqft": 350,
                "crime_rate": 0.02,
                "school_rating": 9,
                "walk_score": 85,
                "transit_score": 90
            },
            {
                "name": f"{city}å°åŒºB",
                "avg_price": 320000,
                "price_per_sqft": 320,
                "crime_rate": 0.03,
                "school_rating": 8,
                "walk_score": 80,
                "transit_score": 85
            },
            {
                "name": f"{city}å°åŒºC",
                "avg_price": 380000,
                "price_per_sqft": 380,
                "crime_rate": 0.01,
                "school_rating": 10,
                "walk_score": 90,
                "transit_score": 95
            }
        ]

        return pd.DataFrame(neighborhoods)

    except Exception as e:
        print(f"è·å–{city}å°åŒºæ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

# ä½¿ç”¨ç¤ºä¾‹
city = "åŒ—äº¬"
house_listings = get_house_listings(city, pages=2)
print(f"{city}æˆ¿äº§åˆ—è¡¨æ•°æ®å½¢çŠ¶: {house_listings.shape}")
print(house_listings[['title', 'price', 'bedrooms', 'bathrooms']].head())

# è·å–å•ä¸ªæˆ¿äº§è¯¦ç»†ä¿¡æ¯
property_details = get_property_details("åŒ—äº¬_1_0")
print("\\næˆ¿äº§è¯¦ç»†ä¿¡æ¯:")
for key, value in property_details.items():
    print(f"{key}: {value}")

# è·å–å°åŒºæ•°æ®
neighborhood_data = get_neighborhood_data(city)
print("\\nå°åŒºæ•°æ®:")
print(neighborhood_data[['name', 'avg_price', 'school_rating']])
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è·å–æˆ¿åœ°äº§å¸‚åœºæ•°æ®ï¼ŒåŒ…æ‹¬æˆ¿äº§åˆ—è¡¨ã€å•ä¸ªæˆ¿äº§è¯¦ç»†ä¿¡æ¯å’Œå°åŒºå‘¨è¾¹æ•°æ®ã€‚ç”±äºè®¿é—®çœŸå®æˆ¿åœ°äº§APIå¯èƒ½éœ€è¦æƒé™ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºè·å–æ–¹æ³•ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 2,
        "title": "æˆ¿åœ°äº§æ•°æ®é¢„å¤„ç†",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime

def clean_house_data(df):
    \"\"\"æ¸…æ´æˆ¿äº§æ•°æ®\"\"\"
    df_clean = df.copy()

    # åˆ é™¤é‡å¤é¡¹
    df_clean = df_clean.drop_duplicates()

    # å¤„ç†ç¼ºå¤±å€¼
    df_clean['price'] = df_clean['price'].fillna(df_clean['price'].median())
    df_clean['sqft'] = df_clean['sqft'].fillna(df_clean['sqft'].mean())

    # æ•°æ®è½¬æ¢
    df_clean['listing_month'] = df_clean['listing_date'].dt.month
    df_clean['listing_year'] = df_clean['listing_date'].dt.year

    # è®¡ç®—ä»·æ ¼æ¯å¹³æ–¹è‹±å°º
    df_clean['price_per_sqft'] = df_clean['price'] / df_clean['sqft']

    return df_clean

def normalize_property_features(df):
    \"\"\"å½’ä¸€åŒ–æˆ¿äº§ç‰¹å¾\"\"\"
    df_normalized = df.copy()

    # å½’ä¸€åŒ–æ•°å€¼ç‰¹å¾
    numerical_features = ['price', 'sqft', 'price_per_sqft']

    for feature in numerical_features:
        df_normalized[feature] = (df_normalized[feature] - df_normalized[feature].min()) / \
                               (df_normalized[feature].max() - df_normalized[feature].min())

    return df_normalized

def calculate_price_statistics(df):
    \"\"\"è®¡ç®—ä»·æ ¼ç»Ÿè®¡ä¿¡æ¯\"\"\"
    price_stats = {
        "mean_price": df['price'].mean(),
        "median_price": df['price'].median(),
        "min_price": df['price'].min(),
        "max_price": df['price'].max(),
        "price_std": df['price'].std(),
        "count": len(df)
    }

    return price_stats

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²è·å–æ•°æ®ï¼‰
# house_listings = get_house_listings("åŒ—äº¬")
# cleaned_data = clean_house_data(house_listings)
# normalized_data = normalize_property_features(cleaned_data)
# price_stats = calculate_price_statistics(cleaned_data)
#
# print("ä»·æ ¼ç»Ÿè®¡ä¿¡æ¯:")
# for key, value in price_stats.items():
#     if key != 'count':
#         print(f"{key}: ${value:.2f}")
#     else:
#         print(f"{key}: {value}")
#
# print("\\nå½’ä¸€åŒ–åçš„æ•°æ®:")
# print(normalized_data[['title', 'price', 'sqft', 'price_per_sqft']].head())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯¹æˆ¿åœ°äº§æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€ç¼ºå¤±å€¼å¤„ç†ã€ç‰¹å¾å·¥ç¨‹å’Œå½’ä¸€åŒ–ã€‚è‰¯å¥½çš„æ•°æ®é¢„å¤„ç†æ˜¯è¿›è¡Œæˆ¿åœ°äº§åˆ†æçš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 3,
        "title": "æˆ¿åœ°äº§ä¼°å€¼æ¨¡å‹",
        "code": """import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

def prepare_features_for_valuation(df):
    \"\"\"å‡†å¤‡ä¼°å€¼æ¨¡å‹ç‰¹å¾\"\"\"
    # é€‰æ‹©ç›¸å…³ç‰¹å¾
    features = df[['bedrooms', 'bathrooms', 'sqft', 'listing_month', 'listing_year']]

    return features

def train_valuation_model(X, y, model_type='linear'):
    \"\"\"è®­ç»ƒä¼°å€¼æ¨¡å‹\"\"\"
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if model_type == 'linear':
        model = LinearRegression()
    elif model_type == 'random_forest':
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹")

    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    return model, mse, r2

def predict_property_value(model, features):
    \"\"\"é¢„æµ‹æˆ¿äº§ä»·å€¼\"\"\"
    if isinstance(features, pd.DataFrame):
        return model.predict(features)
    elif isinstance(features, list):
        return model.predict([features])
    else:
        return model.predict([[features]])

def calculate_feature_importance(model, feature_names):
    \"\"\"è®¡ç®—ç‰¹å¾é‡è¦æ€§\"\"\"
    if hasattr(model, 'feature_importances_'):
        importance = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values(by='importance', ascending=False)

        return importance
    elif hasattr(model, 'coef_'):
        importance = pd.DataFrame({
            'feature': feature_names,
            'importance': abs(model.coef_)
        }).sort_values(by='importance', ascending=False)

        return importance
    else:
        return pd.DataFrame()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²å¤„ç†æ•°æ®ï¼‰
# X = prepare_features_for_valuation(cleaned_data)
# y = cleaned_data['price']
#
# linear_model, linear_mse, linear_r2 = train_valuation_model(X, y, 'linear')
# rf_model, rf_mse, rf_r2 = train_valuation_model(X, y, 'random_forest')
#
# print(f"çº¿æ€§å›å½’ - MSE: {linear_mse:.2f}, RÂ²: {linear_r2:.4f}")
# print(f"éšæœºæ£®æ— - MSE: {rf_mse:.2f}, RÂ²: {rf_r2:.4f}")
#
# # é¢„æµ‹ç¤ºä¾‹
# example_features = [[3, 2, 1500, 6, 2024]]
# prediction = predict_property_value(rf_model, example_features)
# print(f"é¢„æµ‹ä»·æ ¼: ${prediction[0]:,.2f}")
#
# # ç‰¹å¾é‡è¦æ€§
# importance = calculate_feature_importance(rf_model, X.columns)
# print("\\nç‰¹å¾é‡è¦æ€§:")
# print(importance)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•æ„å»ºå’Œè®­ç»ƒæˆ¿åœ°äº§ä¼°å€¼æ¨¡å‹ï¼ŒåŒ…æ‹¬ç‰¹å¾å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œç‰¹å¾é‡è¦æ€§åˆ†æã€‚æœºå™¨å­¦ä¹ æ¨¡å‹å¯ä»¥å¸®åŠ©æ›´å‡†ç¡®åœ°è¯„ä¼°æˆ¿äº§ä»·å€¼ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 4,
        "title": "æˆ¿åœ°äº§æ•°æ®å¯è§†åŒ–",
        "code": """import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def plot_price_distribution(df):
    \"\"\"ç»˜åˆ¶ä»·æ ¼åˆ†å¸ƒç›´æ–¹å›¾\"\"\"
    plt.figure(figsize=(12, 6))
    sns.histplot(df['price'], kde=True, bins=30)
    plt.title('æˆ¿äº§ä»·æ ¼åˆ†å¸ƒ')
    plt.xlabel('ä»·æ ¼ ($)')
    plt.ylabel('æ•°é‡')
    plt.grid(True)
    plt.savefig('price_distribution.png', dpi=300)
    plt.show()

def plot_price_vs_sqft(df):
    \"\"\"ç»˜åˆ¶ä»·æ ¼ä¸é¢ç§¯å…³ç³»\"\"\"
    plt.figure(figsize=(12, 6))
    sns.scatterplot(data=df, x='sqft', y='price')
    sns.regplot(data=df, x='sqft', y='price', scatter=False, color='red')
    plt.title('ä»·æ ¼ä¸é¢ç§¯å…³ç³»')
    plt.xlabel('é¢ç§¯ (å¹³æ–¹è‹±å°º)')
    plt.ylabel('ä»·æ ¼ ($)')
    plt.grid(True)
    plt.savefig('price_vs_sqft.png', dpi=300)
    plt.show()

def plot_price_per_bedroom(df):
    \"\"\"ç»˜åˆ¶ä»·æ ¼æŒ‰å§å®¤æ•°é‡åˆ†ç»„\"\"\"
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=df, x='bedrooms', y='price')
    plt.title('ä»·æ ¼æŒ‰å§å®¤æ•°é‡åˆ†ç»„')
    plt.xlabel('å§å®¤æ•°é‡')
    plt.ylabel('ä»·æ ¼ ($)')
    plt.grid(True)
    plt.savefig('price_per_bedroom.png', dpi=300)
    plt.show()

def plot_monthly_listings(df):
    \"\"\"ç»˜åˆ¶æœˆåº¦æˆ¿æºæ•°é‡\"\"\"
    monthly_counts = df.groupby(['listing_year', 'listing_month']).size().unstack(fill_value=0)

    plt.figure(figsize=(12, 6))
    monthly_counts.plot(kind='bar', stacked=True, colormap='viridis')
    plt.title('æœˆåº¦æˆ¿æºæ•°é‡')
    plt.xlabel('å¹´ä»½')
    plt.ylabel('æˆ¿æºæ•°é‡')
    plt.legend(title='æœˆä»½')
    plt.grid(True)
    plt.savefig('monthly_listings.png', dpi=300)
    plt.show()

def plot_correlation_matrix(df):
    \"\"\"ç»˜åˆ¶ç›¸å…³ç³»æ•°çŸ©é˜µ\"\"\"
    numerical_cols = ['price', 'bedrooms', 'bathrooms', 'sqft']

    plt.figure(figsize=(10, 8))
    sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
    plt.title('ç‰¹å¾ç›¸å…³ç³»æ•°çŸ©é˜µ')
    plt.savefig('correlation_matrix.png', dpi=300)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‡è®¾å·²å¤„ç†æ•°æ®ï¼‰
# plot_price_distribution(cleaned_data)
# plot_price_vs_sqft(cleaned_data)
# plot_price_per_bedroom(cleaned_data)
# plot_monthly_listings(cleaned_data)
# plot_correlation_matrix(cleaned_data)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•å¯è§†åŒ–æˆ¿åœ°äº§æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼åˆ†å¸ƒã€ä»·æ ¼ä¸é¢ç§¯å…³ç³»ã€ä»·æ ¼æŒ‰å§å®¤æ•°é‡åˆ†ç»„ç­‰å›¾è¡¨ã€‚å¯è§†åŒ–å¸®åŠ©æ›´å¥½åœ°ç†è§£æˆ¿åœ°äº§å¸‚åœºç‰¹å¾ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 5,
        "title": "æˆ¿åœ°äº§æŠ•èµ„å›æŠ¥è®¡ç®—",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime

def calculate_roi(purchase_price, sale_price, holding_period, down_payment, monthly_rent, expenses):
    \"\"\"è®¡ç®—æŠ•èµ„å›æŠ¥ç‡\"\"\"
    initial_investment = purchase_price * down_payment

    total_rental_income = monthly_rent * 12 * holding_period

    total_expenses = expenses * 12 * holding_period

    net_income = total_rental_income - total_expenses

    capital_gain = sale_price - purchase_price

    total_profit = net_income + capital_gain

    roi = total_profit / initial_investment

    annual_roi = (1 + roi) ** (1 / holding_period) - 1

    return roi, annual_roi

def calculate_cash_flow(purchase_price, down_payment, monthly_rent, monthly_expenses):
    \"\"\"è®¡ç®—ç°é‡‘æµ\"\"\"
    monthly_interest = (purchase_price * (1 - down_payment)) * (0.04 / 12)

    monthly_cash_flow = monthly_rent - monthly_expenses - monthly_interest

    cash_on_cash = (monthly_cash_flow * 12) / (purchase_price * down_payment)

    return monthly_cash_flow, cash_on_cash

def calculate_cap_rate(net_operating_income, property_value):
    \"\"\"è®¡ç®—èµ„æœ¬åŒ–ç‡\"\"\"
    if property_value > 0:
        return net_operating_income / property_value
    else:
        return 0

def analyze_investment_scenarios(purchase_price):
    \"\"\"åˆ†æä¸åŒæŠ•èµ„åœºæ™¯\"\"\"
    scenarios = [
        {
            "name": "ä¿å®ˆåœºæ™¯",
            "rent_growth": 0.02,
            "appreciation": 0.03,
            "vacancy_rate": 0.05,
            "expense_ratio": 0.35
        },
        {
            "name": "åŸºå‡†åœºæ™¯",
            "rent_growth": 0.03,
            "appreciation": 0.05,
            "vacancy_rate": 0.03,
            "expense_ratio": 0.30
        },
        {
            "name": "ä¹è§‚åœºæ™¯",
            "rent_growth": 0.05,
            "appreciation": 0.08,
            "vacancy_rate": 0.02,
            "expense_ratio": 0.25
        }
    ]

    results = []

    for scenario in scenarios:
        monthly_rent = (purchase_price / 1000) * 0.8
        expenses = monthly_rent * scenario['expense_ratio']

        total_rent = monthly_rent * 12 * 5
        total_expenses = expenses * 12 * 5

        net_operating_income = total_rent - total_expenses

        future_value = purchase_price * (1 + scenario['appreciation']) ** 5

        roi, annual_roi = calculate_roi(purchase_price, future_value, 5, 0.2, monthly_rent, expenses)

        results.append({
            "scenario": scenario['name'],
            "total_rent": total_rent,
            "total_expenses": total_expenses,
            "net_operating_income": net_operating_income,
            "future_value": future_value,
            "roi": roi,
            "annual_roi": annual_roi
        })

    return results

# ä½¿ç”¨ç¤ºä¾‹
purchase_price = 350000
down_payment = 0.2
monthly_rent = 2500
monthly_expenses = 800

roi, annual_roi = calculate_roi(purchase_price, 420000, 5, down_payment, monthly_rent, monthly_expenses)
cash_flow, cash_on_cash = calculate_cash_flow(purchase_price, down_payment, monthly_rent, monthly_expenses)

print(f"æŠ•èµ„å›æŠ¥ç‡ (ROI): {roi:.2%}")
print(f"å¹´åŒ–æŠ•èµ„å›æŠ¥ç‡: {annual_roi:.2%}")
print(f"æœˆç°é‡‘æµ: ${cash_flow:.2f}")
print(f"ç°é‡‘å›æŠ¥ç‡: {cash_on_cash:.2%}")

scenario_results = analyze_investment_scenarios(purchase_price)
print("\\næŠ•èµ„åœºæ™¯åˆ†æ:")
for result in scenario_results:
    print(f"\\n{result['scenario']}:")
    print(f"  æ€»ç§Ÿé‡‘: ${result['total_rent']:.0f}")
    print(f"  æ€»æ”¯å‡º: ${result['total_expenses']:.0f}")
    print(f"  å‡€è¿è¥æ”¶å…¥: ${result['net_operating_income']:.0f}")
    print(f"  æœªæ¥ä»·å€¼: ${result['future_value']:.0f}")
    print(f"  æŠ•èµ„å›æŠ¥ç‡: {result['roi']:.2%}")
    print(f"  å¹´åŒ–å›æŠ¥ç‡: {result['annual_roi']:.2%}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•è®¡ç®—æˆ¿åœ°äº§æŠ•èµ„å›æŠ¥ç‡ï¼ŒåŒ…æ‹¬ROIã€å¹´åŒ–ROIã€ç°é‡‘æµã€èµ„æœ¬åŒ–ç‡ç­‰æŒ‡æ ‡ï¼Œå¹¶æä¾›ä¸åŒæŠ•èµ„åœºæ™¯çš„åˆ†æã€‚è¿™äº›æŒ‡æ ‡å¸®åŠ©è¯„ä¼°æŠ•èµ„ç‰©ä¸šçš„æ½œåŠ›ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 6,
        "title": "å®Œæ•´æˆ¿åœ°äº§æŠ•èµ„åˆ†æç³»ç»Ÿ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

class RealEstateInvestmentSystem:
    def __init__(self, city):
        self.city = city
        self.listings = None
        self.analytics = None

    def load_data(self, pages=1):
        \"\"\"åŠ è½½æ•°æ®\"\"\"
        from data_fetcher import get_house_listings

        self.listings = get_house_listings(self.city, pages)

        return self.listings

    def preprocess_data(self):
        \"\"\"é¢„å¤„ç†æ•°æ®\"\"\"
        from data_preprocessor import clean_house_data, normalize_property_features

        if self.listings is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")

        self.analytics = clean_house_data(self.listings)

        return self.analytics

    def analyze_market(self):
        \"\"\"å¸‚åœºåˆ†æ\"\"\"
        from market_analyzer import (
            calculate_price_statistics,
            prepare_features_for_valuation,
            train_valuation_model,
            calculate_feature_importance
        )

        if self.analytics is None:
            raise ValueError("è¯·å…ˆé¢„å¤„ç†æ•°æ®")

        price_stats = calculate_price_statistics(self.analytics)

        X = prepare_features_for_valuation(self.analytics)
        y = self.analytics['price']

        model, mse, r2 = train_valuation_model(X, y, 'linear')

        feature_importance = calculate_feature_importance(model, X.columns)

        price_range = {
            "low": price_stats['mean_price'] - price_stats['price_std'],
            "high": price_stats['mean_price'] + price_stats['price_std']
        }

        return {
            "price_stats": price_stats,
            "price_range": price_range,
            "model_performance": {"mse": mse, "r2": r2},
            "feature_importance": feature_importance
        }

    def visualize_data(self):
        \"\"\"å¯è§†åŒ–æ•°æ®\"\"\"
        from visualizer import (
            plot_price_distribution,
            plot_price_vs_sqft,
            plot_price_per_bedroom,
            plot_monthly_listings,
            plot_correlation_matrix
        )

        if self.analytics is None:
            raise ValueError("è¯·å…ˆé¢„å¤„ç†æ•°æ®")

        plot_price_distribution(self.analytics)
        plot_price_vs_sqft(self.analytics)
        plot_price_per_bedroom(self.analytics)
        plot_monthly_listings(self.analytics)
        plot_correlation_matrix(self.analytics)

    def analyze_investment(self, property_details):
        \"\"\"æŠ•èµ„åˆ†æ\"\"\"
        from investment_analyzer import (
            calculate_roi,
            calculate_cash_flow,
            calculate_cap_rate,
            analyze_investment_scenarios
        )

        if self.analytics is None:
            raise ValueError("è¯·å…ˆé¢„å¤„ç†æ•°æ®")

        purchase_price = property_details['price']
        monthly_rent = (purchase_price / 1000) * 0.8
        monthly_expenses = monthly_rent * 0.3

        roi, annual_roi = calculate_roi(purchase_price, 420000, 5, 0.2, monthly_rent, monthly_expenses)
        cash_flow, cash_on_cash = calculate_cash_flow(purchase_price, 0.2, monthly_rent, monthly_expenses)
        cap_rate = calculate_cap_rate((monthly_rent - monthly_expenses) * 12, purchase_price)

        return {
            "roi": roi,
            "annual_roi": annual_roi,
            "cash_flow": cash_flow,
            "cash_on_cash": cash_on_cash,
            "cap_rate": cap_rate
        }

    def generate_report(self):
        \"\"\"ç”Ÿæˆåˆ†ææŠ¥å‘Š\"\"\"
        market_analysis = self.analyze_market()

        report = []

        report.append(f"# {self.city}æˆ¿åœ°äº§å¸‚åœºåˆ†ææŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report.append("")
        report.append("## å¸‚åœºæ¦‚è§ˆ")
        report.append(f"æˆ¿æºæ•°é‡: {market_analysis['price_stats']['count']}")
        report.append(f"å¹³å‡ä»·æ ¼: ${market_analysis['price_stats']['mean_price']:.0f}")
        report.append(f"ä¸­ä½ä»·æ ¼: ${market_analysis['price_stats']['median_price']:.0f}")
        report.append(f"ä»·æ ¼æ ‡å‡†å·®: ${market_analysis['price_stats']['price_std']:.0f}")
        report.append(f"ä»·æ ¼èŒƒå›´: ${market_analysis['price_range']['low']:.0f} - ${market_analysis['price_range']['high']:.0f}")
        report.append("")
        report.append("## æ¨¡å‹æ€§èƒ½")
        report.append(f"å‡æ–¹è¯¯å·® (MSE): {market_analysis['model_performance']['mse']:.2f}")
        report.append(f"å†³å®šç³»æ•° (RÂ²): {market_analysis['model_performance']['r2']:.4f}")
        report.append("")
        report.append("## ç‰¹å¾é‡è¦æ€§")

        for index, row in market_analysis['feature_importance'].iterrows():
            report.append(f"- {row['feature']}: {row['importance']:.4f}")

        return "\\n".join(report)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    system = RealEstateInvestmentSystem("åŒ—äº¬")
    print("1. åŠ è½½æ•°æ®")
    system.load_data(pages=2)

    print("2. é¢„å¤„ç†æ•°æ®")
    system.preprocess_data()

    print("3. å¸‚åœºåˆ†æ")
    market_analysis = system.analyze_market()

    print("4. å¯è§†åŒ–æ•°æ®")
    system.visualize_data()

    print("5. æŠ•èµ„åˆ†æ")
    sample_property = {
        "id": "sample_1",
        "price": 350000,
        "bedrooms": 3,
        "bathrooms": 2,
        "sqft": 1200
    }
    investment_analysis = system.analyze_investment(sample_property)

    print("6. ç”ŸæˆæŠ¥å‘Š")
    report = system.generate_report()
    with open("real_estate_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    print("\\nåˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ° real_estate_report.md")
""",
        "explanation": "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æˆ¿åœ°äº§æŠ•èµ„åˆ†æç³»ç»Ÿç±»ï¼Œé›†æˆäº†æ•°æ®è·å–ã€é¢„å¤„ç†ã€å¸‚åœºåˆ†æã€æŠ•èµ„åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½ã€‚ç³»ç»Ÿæä¾›äº†å…¨é¢çš„å¸‚åœºåˆ†æå’ŒæŠ•èµ„è¯„ä¼°æ–¹æ³•ã€‚"
    },
    {
        "topic_id": 7,
        "category_id": 6,
        "title": "å®æˆ˜æ¡ˆä¾‹ - æˆ¿åœ°äº§å¸‚åœºåˆ†ææŠ¥å‘Š",
        "code": """import pandas as pd
from real_estate_system import RealEstateInvestmentSystem

def run_case_study():
    \"\"\"æˆ¿åœ°äº§å¸‚åœºåˆ†æå®æˆ˜æ¡ˆä¾‹\"\"\"
    system = RealEstateInvestmentSystem("åŒ—äº¬")

    try:
        print("1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®")
        system.load_data(pages=2)
        system.preprocess_data()

        print("2. å¸‚åœºåˆ†æ")
        analysis = system.analyze_market()

        print("\\n=== å¸‚åœºæ¦‚è§ˆ ===")
        print(f"æˆ¿æºæ•°é‡: {analysis['price_stats']['count']}")
        print(f"å¹³å‡ä»·æ ¼: ${analysis['price_stats']['mean_price']:.0f}")
        print(f"ä¸­ä½ä»·æ ¼: ${analysis['price_stats']['median_price']:.0f}")
        print(f"ä»·æ ¼èŒƒå›´: ${analysis['price_range']['low']:.0f} - ${analysis['price_range']['high']:.0f}")

        print("\\n=== æ¨¡å‹æ€§èƒ½ ===")
        print(f"å‡æ–¹è¯¯å·® (MSE): {analysis['model_performance']['mse']:.2f}")
        print(f"å†³å®šç³»æ•° (RÂ²): {analysis['model_performance']['r2']:.4f}")

        print("\\n=== ç‰¹å¾é‡è¦æ€§ ===")
        for index, row in analysis['feature_importance'].iterrows():
            print(f"{row['feature']}: {row['importance']:.4f}")

        print("\\n3. å¯è§†åŒ–")
        system.visualize_data()

        print("\\n4. æŠ•èµ„åˆ†æ")
        sample_property = {
            "id": "case_01",
            "price": 350000,
            "bedrooms": 3,
            "bathrooms": 2,
            "sqft": 1200
        }
        investment = system.analyze_investment(sample_property)

        print("\\n=== æŠ•èµ„åˆ†æ ===")
        print(f"æŠ•èµ„å›æŠ¥ç‡: {investment['roi']:.2%}")
        print(f"å¹´åŒ–æŠ•èµ„å›æŠ¥ç‡: {investment['annual_roi']:.2%}")
        print(f"æœˆç°é‡‘æµ: ${investment['cash_flow']:.2f}")
        print(f"ç°é‡‘å›æŠ¥ç‡: {investment['cash_on_cash']:.2%}")
        print(f"èµ„æœ¬åŒ–ç‡: {investment['cap_rate']:.2%}")

        print("\\n5. ç”ŸæˆæŠ¥å‘Š")
        report = system.generate_report()
        with open("beijing_market_analysis.md", "w", encoding="utf-8") as f:
            f.write(report)

        print("\\n=== æŠ¥å‘Šç”Ÿæˆå®Œæˆ ===")
        print("æŠ¥å‘Šå·²ä¿å­˜åˆ° beijing_market_analysis.md")

        return True

    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return False

if __name__ == "__main__":
    print("=== æˆ¿åœ°äº§å¸‚åœºåˆ†æå®æˆ˜æ¡ˆä¾‹ ===")

    success = run_case_study()

    if success:
        print("\\nâœ… åˆ†æå®Œæˆï¼")
    else:
        print("\\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
""",
        "explanation": "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æˆ¿åœ°äº§å¸‚åœºåˆ†æå®æˆ˜æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†ä»æ•°æ®è·å–ã€é¢„å¤„ç†ã€å¸‚åœºåˆ†æåˆ°æŠ¥å‘Šç”Ÿæˆçš„å®Œæ•´æµç¨‹ã€‚å®æˆ˜æ¡ˆä¾‹å¸®åŠ©ç†è§£å¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨è¿™äº›åŠŸèƒ½ã€‚"
    },
    # ä¸»é¢˜8ï¼šé‡‘èé£é™©ç®¡ç†
    {
        "topic_id": 8,
        "category_id": 1,
        "title": "é£é™©æ•°æ®è·å–ä¸å¤„ç†",
        "code": """import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta

def fetch_risk_data(symbols, start_date, end_date):
    \"\"\"è·å–é£é™©æ•°æ®\"\"\"
    data = {}
    for symbol in symbols:
        try:
            ticker = yf.Ticker(symbol)
            history = ticker.history(start=start_date, end=end_date)
            data[symbol] = history
            print(f"æˆåŠŸè·å–{symbol}æ•°æ®")
        except Exception as e:
            print(f"è·å–{symbol}æ•°æ®å¤±è´¥: {e}")
            data[symbol] = pd.DataFrame()
    return data

def calculate_returns(data):
    \"\"\"è®¡ç®—æ”¶ç›Šç‡\"\"\"
    returns = {}
    for symbol, df in data.items():
        if not df.empty:
            returns[symbol] = df['Close'].pct_change().dropna()
    return returns

def calculate_volatility(returns, window=252):
    \"\"\"è®¡ç®—æ³¢åŠ¨ç‡\"\"\"
    volatility = {}
    for symbol, ret in returns.items():
        volatility[symbol] = ret.std() * np.sqrt(window)
    return volatility

def calculate_value_at_risk(returns, confidence_level=0.95):
    \"\"\"è®¡ç®—é£é™©ä»·å€¼(VaR)\"\"\"
    VaR = {}
    for symbol, ret in returns.items():
        VaR[symbol] = np.percentile(ret, 100 * (1 - confidence_level))
    return VaR

def calculate_expected_shortfall(returns, confidence_level=0.95):
    \"\"\"è®¡ç®—é¢„æœŸæŸå¤±(ES)\"\"\"
    ES = {}
    for symbol, ret in returns.items():
        VaR = np.percentile(ret, 100 * (1 - confidence_level))
        ES[symbol] = ret[ret <= VaR].mean()
    return ES

def prepare_risk_report(data, returns, volatility, VaR, ES):
    \"\"\"å‡†å¤‡é£é™©æŠ¥å‘Š\"\"\"
    report = []

    for symbol in data.keys():
        if not data[symbol].empty:
            report.append({
                'Symbol': symbol,
                'Start Date': data[symbol].index[0].strftime('%Y-%m-%d'),
                'End Date': data[symbol].index[-1].strftime('%Y-%m-%d'),
                'Daily Return': returns[symbol].mean() if symbol in returns else np.nan,
                'Volatility': volatility[symbol] if symbol in volatility else np.nan,
                'VaR (95%)': VaR[symbol] if symbol in VaR else np.nan,
                'Expected Shortfall (95%)': ES[symbol] if symbol in ES else np.nan
            })

    return pd.DataFrame(report)

# ä½¿ç”¨ç¤ºä¾‹
# symbols = ['SPY', 'AAPL', 'MSFT']
# start_date = '2020-01-01'
# end_date = '2023-12-31'
#
# data = fetch_risk_data(symbols, start_date, end_date)
# returns = calculate_returns(data)
# volatility = calculate_volatility(returns)
# VaR = calculate_value_at_risk(returns)
# ES = calculate_expected_shortfall(returns)
#
# report = prepare_risk_report(data, returns, volatility, VaR, ES)
# print(report)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¦‚ä½•ä»Yahoo Financeè·å–é£é™©æ•°æ®ï¼Œå¹¶è®¡ç®—å…³é”®é£é™©æŒ‡æ ‡ï¼šæ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ã€VaRï¼ˆé£é™©ä»·å€¼ï¼‰å’Œé¢„æœŸæŸå¤±(ES)ã€‚è¿™äº›æŒ‡æ ‡æ˜¯é‡‘èé£é™©ç®¡ç†çš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 8,
        "category_id": 2,
        "title": "é£é™©è¯†åˆ«ä¸è¯„ä¼°",
        "code": """import pandas as pd
import numpy as np
from scipy.stats import norm

def identify_market_risk_factors(data):
    \"\"\"è¯†åˆ«å¸‚åœºé£é™©å› ç´ \"\"\"
    risk_factors = []

    # è®¡ç®—ä»·æ ¼å˜åŒ–
    for symbol, df in data.items():
        if not df.empty:
            df['Price Change'] = df['Close'].pct_change()
            df['Volatility'] = df['Price Change'].rolling(window=30).std() * np.sqrt(252)

            # æ£€æµ‹ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨
            threshold = df['Price Change'].std() * 3
            outliers = df[np.abs(df['Price Change']) > threshold]

            if not outliers.empty:
                risk_factors.extend([
                    {
                        'Symbol': symbol,
                        'Date': idx.strftime('%Y-%m-%d'),
                        'Type': 'Price Volatility',
                        'Magnitude': abs(change),
                        'Volatility': vol
                    } for idx, change, vol in zip(outliers.index, outliers['Price Change'], outliers['Volatility'])
                ])

    return pd.DataFrame(risk_factors)

def assess_credit_risk(rating, market_value, exposure):
    \"\"\"è¯„ä¼°ä¿¡ç”¨é£é™©\"\"\"
    # ç®€åŒ–çš„ä¿¡ç”¨é£é™©è¯„ä¼°æ¨¡å‹
    default_probabilities = {
        'AAA': 0.001, 'AA': 0.002, 'A': 0.005, 'BBB': 0.01,
        'BB': 0.03, 'B': 0.08, 'CCC': 0.20, 'D': 1.00
    }

    recovery_rates = {
        'AAA': 0.90, 'AA': 0.85, 'A': 0.80, 'BBB': 0.70,
        'BB': 0.60, 'B': 0.45, 'CCC': 0.30, 'D': 0.10
    }

    default_prob = default_probabilities.get(rating, 0.25)
    recovery_rate = recovery_rates.get(rating, 0.40)

    expected_loss = default_prob * (1 - recovery_rate) * exposure

    return {
        'Default Probability': default_prob,
        'Recovery Rate': recovery_rate,
        'Expected Loss': expected_loss
    }

def evaluate_operational_risk(incidents, business_units):
    \"\"\"è¯„ä¼°æ“ä½œé£é™©\"\"\"
    risk_scores = {}

    for unit in business_units:
        unit_incidents = incidents[incidents['Business Unit'] == unit]

        if not unit_incidents.empty:
            # ç®€åŒ–çš„æ“ä½œé£é™©è¯„åˆ†
            frequency_score = len(unit_incidents)
            severity_score = unit_incidents['Severity'].mean()
            risk_scores[unit] = frequency_score * severity_score

    return risk_scores

def calculate_portfolio_risk_exposure(weights, cov_matrix):
    \"\"\"è®¡ç®—æŠ•èµ„ç»„åˆé£é™©æš´éœ²\"\"\"
    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    return portfolio_volatility

def generate_risk_identification_report(risk_factors, credit_risk, operational_risk):
    \"\"\"ç”Ÿæˆé£é™©è¯†åˆ«æŠ¥å‘Š\"\"\"
    report = {
        'Market Risk Factors': risk_factors,
        'Credit Risk Assessment': pd.DataFrame([credit_risk]),
        'Operational Risk Scores': pd.DataFrame(list(operational_risk.items()),
                                              columns=['Business Unit', 'Risk Score'])
    }

    return report

# ä½¿ç”¨ç¤ºä¾‹
# incidents = pd.DataFrame({
#     'Business Unit': ['Trading', 'Operations', 'Compliance', 'Trading'],
#     'Incident Date': ['2023-01-15', '2023-02-20', '2023-03-10', '2023-04-05'],
#     'Severity': [3, 5, 2, 4],
#     'Description': ['ç³»ç»Ÿæ•…éšœ', 'äººä¸ºé”™è¯¯', 'åˆè§„è¿è§„', 'å¸‚åœºæ³¢åŠ¨']
# })
#
# business_units = ['Trading', 'Operations', 'Compliance']
#
# risk_factors = identify_market_risk_factors(data)
# credit_risk = assess_credit_risk('BBB', 1000000, 500000)
# operational_risk = evaluate_operational_risk(incidents, business_units)
#
# report = generate_risk_identification_report(risk_factors, credit_risk, operational_risk)
# print("å¸‚åœºé£é™©å› ç´ æ•°é‡:", len(report['Market Risk Factors']))
# print("ä¿¡ç”¨é£é™©è¯„ä¼°:")
# print(report['Credit Risk Assessment'])
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºé£é™©è¯†åˆ«ä¸è¯„ä¼°æ–¹æ³•ï¼ŒåŒ…æ‹¬å¸‚åœºé£é™©å› ç´ è¯†åˆ«ã€ä¿¡ç”¨é£é™©è¯„ä¼°å’Œæ“ä½œé£é™©è¯„ä¼°ï¼Œä¸ºé£é™©ç®¡ç†æä¾›åŸºç¡€ã€‚"
    },
    {
        "topic_id": 8,
        "category_id": 3,
        "title": "é£é™©æµ‹é‡ä¸é‡åŒ–",
        "code": """import pandas as pd
import numpy as np
from scipy.stats import norm, t
from scipy.optimize import minimize

def var_historical(returns, confidence_level=0.95):
    \"\"\"å†å²æ¨¡æ‹Ÿæ³•è®¡ç®—VaR\"\"\"
    return np.percentile(returns, 100 * (1 - confidence_level))

def var_parametric(returns, confidence_level=0.95, distribution='normal'):
    \"\"\"å‚æ•°æ³•è®¡ç®—VaR\"\"\"
    mean = returns.mean()
    std = returns.std()

    if distribution == 'normal':
        VaR = mean - std * norm.ppf(confidence_level)
    elif distribution == 't':
        # å‡è®¾è‡ªç”±åº¦ä¸º4çš„tåˆ†å¸ƒ
        VaR = mean - std * t.ppf(confidence_level, df=4)
    else:
        raise ValueError("ä¸æ”¯æŒçš„åˆ†å¸ƒç±»å‹")

    return VaR

def var_monte_carlo(returns, confidence_level=0.95, simulations=10000):
    \"\"\"è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿè®¡ç®—VaR\"\"\"
    np.random.seed(42)
    mean = returns.mean()
    std = returns.std()

    simulated_returns = np.random.normal(mean, std, simulations)

    return np.percentile(simulated_returns, 100 * (1 - confidence_level))

def calculate_covar(returns, confidence_level=0.95):
    \"\"\"è®¡ç®—æ¡ä»¶VaR(CVaR)\"\"\"
    VaR = np.percentile(returns, 100 * (1 - confidence_level))
    return returns[returns <= VaR].mean()

def portfolio_optimization(returns, risk_free_rate=0.02):
    \"\"\"æŠ•èµ„ç»„åˆä¼˜åŒ–\"\"\"
    # è®¡ç®—åæ–¹å·®çŸ©é˜µ
    cov_matrix = returns.cov()

    # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼ˆæœ€å°åŒ–æ³¢åŠ¨ç‡ï¼‰
    def minimize_volatility(weights):
        return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

    # å®šä¹‰çº¦æŸæ¡ä»¶
    constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]
    bounds = [(0, 1) for _ in range(len(returns.columns))]

    # åˆå§‹çŒœæµ‹
    initial_weights = np.ones(len(returns.columns)) / len(returns.columns)

    # ä¼˜åŒ–
    result = minimize(minimize_volatility, initial_weights,
                     method='SLSQP', bounds=bounds, constraints=constraints)

    return result.x

def sensitivity_analysis(parameters, base_value, percentage_change):
    \"\"\"æ•æ„Ÿæ€§åˆ†æ\"\"\"
    results = {}

    for param, value in parameters.items():
        # è®¡ç®—å‚æ•°ä¸Šä¸‹æ³¢åŠ¨å¯¹ç»“æœçš„å½±å“
        for direction in ['up', 'down']:
            if direction == 'up':
                new_value = value * (1 + percentage_change)
                scenario = f"{param}_up"
            else:
                new_value = value * (1 - percentage_change)
                scenario = f"{param}_down"

            # ç®€åŒ–çš„è®¡ç®—é€»è¾‘
            sensitivity = (new_value - value) / value
            results[scenario] = {
                'New Value': new_value,
                'Change': direction,
                'Sensitivity': sensitivity
            }

    return results

# ä½¿ç”¨ç¤ºä¾‹
# symbols = ['AAPL', 'MSFT', 'SPY']
# start_date = '2020-01-01'
# end_date = '2023-12-31'
#
# data = fetch_risk_data(symbols, start_date, end_date)
# returns = calculate_returns(data)
# aapl_returns = returns['AAPL']
#
# # è®¡ç®—VaRä½¿ç”¨ä¸åŒæ–¹æ³•
# historical_var = var_historical(aapl_returns)
# parametric_var = var_parametric(aapl_returns)
# monte_carlo_var = var_monte_carlo(aapl_returns)
# cvar = calculate_covar(aapl_returns)
#
# print(f"å†å²VaR: {historical_var:.4f}")
# print(f"å‚æ•°VaR: {parametric_var:.4f}")
# print(f"è’™ç‰¹å¡æ´›VaR: {monte_carlo_var:.4f}")
# print(f"CVaR: {cvar:.4f}")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºé£é™©æµ‹é‡ä¸é‡åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬å¤šç§VaRè®¡ç®—æ–¹æ³•ã€CVaRè®¡ç®—ã€æŠ•èµ„ç»„åˆä¼˜åŒ–å’Œæ•æ„Ÿæ€§åˆ†æï¼Œä¸ºé£é™©å†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚"
    },
    {
        "topic_id": 8,
        "category_id": 4,
        "title": "é£é™©æ§åˆ¶ä¸ç®¡ç†",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime

class RiskController:
    \"\"\"é£é™©æ§åˆ¶å™¨\"\"\"

    def __init__(self, portfolio):
        self.portfolio = portfolio
        self.risk_limits = {
            'total_exposure': 1000000,
            'single_position': 200000,
            'max_drawdown': 0.20,
            'var_95': -0.03
        }

    def check_position_limits(self):
        \"\"\"æ£€æŸ¥å¤´å¯¸é™åˆ¶\"\"\"
        violations = []

        total_value = self.portfolio['Value'].sum()
        if total_value > self.risk_limits['total_exposure']:
            violations.append(f"æ€»å¤´å¯¸æš´éœ²è¶…è¿‡é™åˆ¶: ${total_value:.0f} > ${self.risk_limits['total_exposure']:.0f}")

        for idx, position in self.portfolio.iterrows():
            if position['Value'] > self.risk_limits['single_position']:
                violations.append(f"{position['Symbol']}å¤´å¯¸è¿‡å¤§: ${position['Value']:.0f} > ${self.risk_limits['single_position']:.0f}")

        return violations

    def check_var_limit(self, VaR):
        \"\"\"æ£€æŸ¥VaRé™åˆ¶\"\"\"
        violations = []

        if VaR < self.risk_limits['var_95']:
            violations.append(f"VaRè¶…è¿‡é™åˆ¶: {VaR:.4f} < {self.risk_limits['var_95']:.4f}")

        return violations

    def calculate_stop_loss(self, entry_price, stop_loss_pct=0.05):
        \"\"\"è®¡ç®—æ­¢æŸä»·æ ¼\"\"\"
        return entry_price * (1 - stop_loss_pct)

    def calculate_take_profit(self, entry_price, take_profit_pct=0.10):
        \"\"\"è®¡ç®—æ­¢ç›ˆä»·æ ¼\"\"\"
        return entry_price * (1 + take_profit_pct)

    def optimize_portfolio_hedging(self, hedge_instruments, correlation_matrix):
        \"\"\"ä¼˜åŒ–æŠ•èµ„ç»„åˆå¯¹å†²\"\"\"
        optimal_hedge_ratios = {}

        # ç®€åŒ–çš„å¯¹å†²ä¼˜åŒ–é€»è¾‘
        for instrument, correlations in correlation_matrix.items():
            if instrument in hedge_instruments:
                optimal_hedge_ratios[instrument] = -correlations['Portfolio']

        return optimal_hedge_ratios

    def stress_test_portfolio(self, scenarios):
        \"\"\"å‹åŠ›æµ‹è¯•æŠ•èµ„ç»„åˆ\"\"\"
        results = []

        for scenario_name, impact in scenarios.items():
            scenario_value = self.portfolio['Value'].sum() * (1 + impact)
            results.append({
                'Scenario': scenario_name,
                'Impact': impact,
                'Portfolio Value': scenario_value,
                'Loss': scenario_value - self.portfolio['Value'].sum()
            })

        return pd.DataFrame(results)

def implement_risk_monitoring_system(data_source, monitoring_rules):
    \"\"\"å®ç°é£é™©ç›‘æ§ç³»ç»Ÿ\"\"\"
    violations = []

    for rule in monitoring_rules:
        data = fetch_risk_data([rule['Symbol']], rule['Start'], rule['End'])
        returns = calculate_returns(data)

        if rule['Symbol'] in returns:
            metric_value = var_historical(returns[rule['Symbol']], rule['Confidence'])

            if metric_value < rule['Threshold']:
                violations.append({
                    'Rule': rule['Name'],
                    'Symbol': rule['Symbol'],
                    'Metric': 'VaR',
                    'Value': metric_value,
                    'Threshold': rule['Threshold'],
                    'Violation': 'Below Threshold'
                })

    return pd.DataFrame(violations)

def manage_counterparty_risk(exposures, ratings, limits):
    \"\"\"ç®¡ç†å¯¹æ‰‹æ–¹é£é™©\"\"\"
    violations = []

    for counterparty, exposure in exposures.items():
        if counterparty in ratings:
            limit = limits.get(counterparty, 100000)

            if exposure > limit:
                violations.append({
                    'Counterparty': counterparty,
                    'Rating': ratings[counterparty],
                    'Exposure': exposure,
                    'Limit': limit,
                    'Overrun': exposure - limit
                })

    return pd.DataFrame(violations)

# ä½¿ç”¨ç¤ºä¾‹
# portfolio = pd.DataFrame({
#     'Symbol': ['AAPL', 'MSFT', 'SPY'],
#     'Quantity': [100, 50, 20],
#     'Price': [180, 400, 450],
#     'Value': [18000, 20000, 9000]
# })
#
# controller = RiskController(portfolio)
# violations = controller.check_position_limits()
# print("å¤´å¯¸é™åˆ¶è¿è§„:")
# for violation in violations:
#     print(violation)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºé£é™©æ§åˆ¶ä¸ç®¡ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬é£é™©æ§åˆ¶å™¨ç±»ã€é£é™©ç›‘æ§ç³»ç»Ÿå’Œå¯¹æ‰‹æ–¹é£é™©ç®¡ç†ï¼Œä¸ºé£é™©æ§åˆ¶æä¾›å®Œæ•´æ¡†æ¶ã€‚"
    },
    {
        "topic_id": 8,
        "category_id": 5,
        "title": "é£é™©ç®¡ç†ç­–ç•¥",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime

class RiskManagementStrategy:
    \"\"\"é£é™©ç®¡ç†ç­–ç•¥åŸºç±»\"\"\"

    def __init__(self):
        self.risk_tolerance = 'medium'
        self.strategy_name = 'Base Strategy'

    def evaluate_strategy(self, market_conditions):
        \"\"\"è¯„ä¼°ç­–ç•¥\"\"\"
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")

    def rebalance(self, portfolio):
        \"\"\"å†å¹³è¡¡æŠ•èµ„ç»„åˆ\"\"\"
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")

class DiversificationStrategy(RiskManagementStrategy):
    \"\"\"åˆ†æ•£åŒ–ç­–ç•¥\"\"\"

    def __init__(self, max_sector_weight=0.3):
        super().__init__()
        self.strategy_name = 'Diversification'
        self.max_sector_weight = max_sector_weight

    def evaluate_strategy(self, market_conditions):
        \"\"\"è¯„ä¼°ç­–ç•¥\"\"\"
        if market_conditions['Volatility'] > 0.25:
            return 'Increase Diversification'
        elif market_conditions['Volatility'] < 0.15:
            return 'Maintain Diversification'
        else:
            return 'Monitor Closely'

    def rebalance(self, portfolio):
        \"\"\"å†å¹³è¡¡æŠ•èµ„ç»„åˆ\"\"\"
        sectors = portfolio.groupby('Sector').sum()['Value']
        total_value = portfolio['Value'].sum()

        sector_weights = sectors / total_value

        adjustments = []

        for sector, weight in sector_weights.items():
            if weight > self.max_sector_weight:
                excess = weight - self.max_sector_weight
                target_value = sectors[sector] - (total_value * excess)
                adjustments.append({
                    'Sector': sector,
                    'Current Weight': weight,
                    'Target Weight': self.max_sector_weight,
                    'Adjustment': -total_value * excess
                })

        return pd.DataFrame(adjustments)

class HedgingStrategy(RiskManagementStrategy):
    \"\"\"å¯¹å†²ç­–ç•¥\"\"\"

    def __init__(self, hedge_ratio=0.5):
        super().__init__()
        self.strategy_name = 'Hedging'
        self.hedge_ratio = hedge_ratio

    def evaluate_strategy(self, market_conditions):
        \"\"\"è¯„ä¼°ç­–ç•¥\"\"\"
        if market_conditions['Trend'] == 'Down':
            return 'Increase Hedge Ratio'
        elif market_conditions['Trend'] == 'Up':
            return 'Decrease Hedge Ratio'
        else:
            return 'Maintain Current Hedge'

    def rebalance(self, portfolio):
        \"\"\"å†å¹³è¡¡æŠ•èµ„ç»„åˆ\"\"\"
        # ç®€åŒ–çš„å¯¹å†²è®¡ç®—
        hedge_amount = portfolio['Value'].sum() * self.hedge_ratio

        return {
            'Hedge Ratio': self.hedge_ratio,
            'Hedge Amount': hedge_amount,
            'Implementation': 'Use S&P 500 futures'
        }

class RiskParityStrategy(RiskManagementStrategy):
    \"\"\"é£é™©å¹³ä»·ç­–ç•¥\"\"\"

    def __init__(self, target_risk_allocation):
        super().__init__()
        self.strategy_name = 'Risk Parity'
        self.target_risk_allocation = target_risk_allocation

    def evaluate_strategy(self, market_conditions):
        \"\"\"è¯„ä¼°ç­–ç•¥\"\"\"
        return 'Maintain Risk Parity'

    def rebalance(self, portfolio):
        \"\"\"å†å¹³è¡¡æŠ•èµ„ç»„åˆ\"\"\"
        # ç®€åŒ–çš„é£é™©å¹³ä»·è®¡ç®—
        current_risk = {
            'Equities': 0.45,
            'Fixed Income': 0.30,
            'Commodities': 0.25
        }

        adjustments = {}

        for asset_class, target in self.target_risk_allocation.items():
            current = current_risk.get(asset_class, 0)
            if abs(target - current) > 0.02:
                adjustments[asset_class] = target - current

        return adjustments

def simulate_strategy_performance(strategy, market_data):
    \"\"\"æ¨¡æ‹Ÿç­–ç•¥æ€§èƒ½\"\"\"
    returns = []
    for period, data in market_data.items():
        strategy_action = strategy.evaluate_strategy(data)
        period_return = np.random.normal(0.01, 0.02)  # ç®€åŒ–çš„å›æŠ¥æ¨¡æ‹Ÿ

        if strategy_action == 'Increase Diversification':
            period_return *= 0.95
        elif strategy_action == 'Increase Hedge Ratio':
            period_return *= 0.85

        returns.append(period_return)

    return pd.Series(returns)

def backtest_risk_strategies(strategies, historical_data):
    \"\"\"å›æµ‹é£é™©ç­–ç•¥\"\"\"
    results = []

    for strategy_name, strategy in strategies.items():
        returns = simulate_strategy_performance(strategy, historical_data)

        results.append({
            'Strategy': strategy_name,
            'Mean Return': returns.mean(),
            'Standard Deviation': returns.std(),
            'Sharpe Ratio': (returns.mean() - 0.02) / returns.std(),
            'Max Drawdown': min(returns)
        })

    return pd.DataFrame(results)

# ä½¿ç”¨ç¤ºä¾‹
# strategy = DiversificationStrategy()
# backtest_results = backtest_risk_strategies({
#     'Diversification': strategy
# }, historical_data)
# print("ç­–ç•¥å›æµ‹ç»“æœ:")
# print(backtest_results)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºé£é™©ç®¡ç†ç­–ç•¥å®ç°ï¼ŒåŒ…æ‹¬åˆ†æ•£åŒ–ç­–ç•¥ã€å¯¹å†²ç­–ç•¥å’Œé£é™©å¹³ä»·ç­–ç•¥ï¼Œå¹¶æä¾›ç­–ç•¥è¯„ä¼°å’Œå›æµ‹æ¡†æ¶ï¼Œä¸ºé£é™©ç®¡ç†å†³ç­–æä¾›æ”¯æŒã€‚"
    },
    {
        "topic_id": 8,
        "category_id": 6,
        "title": "å®Œæ•´é£é™©ç®¡ç†ç³»ç»Ÿæ¶æ„",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime, timedelta

class FinancialRiskManagementSystem:
    \"\"\"é‡‘èé£é™©ç®¡ç†ç³»ç»Ÿ\"\"\"

    def __init__(self):
        self.data_providers = {}
        self.risk_models = {}
        self.risk_limits = {}
        self.monitoring_alerts = []
        self.report_generators = []

    def register_data_provider(self, name, provider):
        \"\"\"æ³¨å†Œæ•°æ®æä¾›å•†\"\"\"
        self.data_providers[name] = provider

    def register_risk_model(self, name, model):
        \"\"\"æ³¨å†Œé£é™©æ¨¡å‹\"\"\"
        self.risk_models[name] = model

    def set_risk_limits(self, limits):
        \"\"\"è®¾ç½®é£é™©é™åˆ¶\"\"\"
        self.risk_limits = limits

    def generate_risk_report(self, portfolio, time_period):
        \"\"\"ç”Ÿæˆé£é™©æŠ¥å‘Š\"\"\"
        # æ”¶é›†æ•°æ®
        data = {name: provider.fetch_data(time_period) for name, provider in self.data_providers.items()}

        # è®¡ç®—é£é™©æŒ‡æ ‡
        risk_metrics = {name: model.calculate_risk(data) for name, model in self.risk_models.items()}

        # è¯„ä¼°é£é™©æš´éœ²
        risk_exposures = {}
        for metric, value in risk_metrics.items():
            if metric in self.risk_limits:
                risk_exposures[metric] = value['Value'] / self.risk_limits[metric]

        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report = {
            'Timestamp': datetime.now(),
            'Portfolio Value': portfolio['Value'].sum(),
            'Risk Metrics': risk_metrics,
            'Risk Exposures': risk_exposures,
            'Compliance Status': self.check_compliance(risk_exposures)
        }

        return pd.DataFrame([report])

    def check_compliance(self, risk_exposures):
        \"\"\"æ£€æŸ¥åˆè§„æ€§\"\"\"
        violations = []

        for metric, exposure in risk_exposures.items():
            if exposure > 1.0:
                violations.append(f"{metric}æš´éœ²è¶…è¿‡é™åˆ¶: {exposure:.2f}")

        return 'Compliant' if not violations else 'Non-compliant'

    def trigger_alerts(self, portfolio, time_period):
        \"\"\"è§¦å‘è­¦æŠ¥\"\"\"
        risk_report = self.generate_risk_report(portfolio, time_period)

        if risk_report['Compliance Status'].iloc[0] == 'Non-compliant':
            self.monitoring_alerts.append({
                'Alert Time': datetime.now(),
                'Portfolio Value': risk_report['Portfolio Value'].iloc[0],
                'Compliance Status': risk_report['Compliance Status'].iloc[0],
                'Details': risk_report['Risk Exposures'].iloc[0]
            })

    def optimize_risk_allocation(self, portfolio, target_risk):
        \"\"\"ä¼˜åŒ–é£é™©åˆ†é…\"\"\"
        # ç®€åŒ–çš„é£é™©åˆ†é…ä¼˜åŒ–
        asset_classes = portfolio.groupby('Asset Class')['Value'].sum()
        total_value = portfolio['Value'].sum()

        current_allocation = asset_classes / total_value

        # ç®€åŒ–çš„ç›®æ ‡é£é™©åˆ†é…é€»è¾‘
        target_allocation = {
            'Equities': min(current_allocation.get('Equities', 0.5) - 0.05, 0.4),
            'Fixed Income': max(current_allocation.get('Fixed Income', 0.3) + 0.03, 0.35),
            'Cash': 0.25
        }

        return pd.DataFrame([{
            'Asset Class': asset_class,
            'Current Allocation': current_allocation.get(asset_class, 0),
            'Target Allocation': target,
            'Change': target - current_allocation.get(asset_class, 0)
        } for asset_class, target in target_allocation.items()])

def create_risk_management_workflow():
    \"\"\"åˆ›å»ºé£é™©ç®¡ç†å·¥ä½œæµç¨‹\"\"\"
    system = FinancialRiskManagementSystem()

    # æ³¨å†Œæ•°æ®æä¾›å•†
    system.register_data_provider('Market Data', MarketDataProvider())
    system.register_data_provider('Credit Data', CreditDataProvider())
    system.register_data_provider('Operational Data', OperationalDataProvider())

    # æ³¨å†Œé£é™©æ¨¡å‹
    system.register_risk_model('Market Risk', MarketRiskModel())
    system.register_risk_model('Credit Risk', CreditRiskModel())
    system.register_risk_model('Operational Risk', OperationalRiskModel())

    # è®¾ç½®é£é™©é™åˆ¶
    system.set_risk_limits({
        'Market Risk': 0.03,
        'Credit Risk': 0.02,
        'Operational Risk': 0.01
    })

    return system

def run_risk_management_cycle(system, portfolio, time_period):
    \"\"\"è¿è¡Œé£é™©ç®¡ç†å¾ªç¯\"\"\"
    system.trigger_alerts(portfolio, time_period)

    optimization_result = system.optimize_risk_allocation(portfolio, target_risk=0.025)

    if not optimization_result.empty:
        print("é£é™©åˆ†é…ä¼˜åŒ–å»ºè®®:")
        print(optimization_result)

    return system.generate_risk_report(portfolio, time_period)

class MarketDataProvider:
    \"\"\"å¸‚åœºæ•°æ®æä¾›å•†\"\"\"
    def fetch_data(self, time_period):
        return fetch_risk_data(['SPY', 'AAPL', 'MSFT'], time_period['Start'], time_period['End'])

class CreditDataProvider:
    \"\"\"ä¿¡ç”¨æ•°æ®æä¾›å•†\"\"\"
    def fetch_data(self, time_period):
        return assess_credit_risk('BBB', 1000000, 500000)

class OperationalDataProvider:
    \"\"\"æ“ä½œæ•°æ®æä¾›å•†\"\"\"
    def fetch_data(self, time_period):
        return evaluate_operational_risk([], ['Trading', 'Operations'])

class MarketRiskModel:
    \"\"\"å¸‚åœºé£é™©æ¨¡å‹\"\"\"
    def calculate_risk(self, data):
        return {'Value': var_historical(data['Market Data'])}

class CreditRiskModel:
    \"\"\"ä¿¡ç”¨é£é™©æ¨¡å‹\"\"\"
    def calculate_risk(self, data):
        return {'Value': data['Credit Data']['Expected Loss']}

class OperationalRiskModel:
    \"\"\"æ“ä½œé£é™©æ¨¡å‹\"\"\"
    def calculate_risk(self, data):
        return {'Value': max(data['Operational Data'].values())}

# ä½¿ç”¨ç¤ºä¾‹
# system = create_risk_management_workflow()
#
# time_period = {
#     'Start': '2020-01-01',
#     'End': '2023-12-31'
# }
#
# portfolio = pd.DataFrame({
#     'Symbol': ['AAPL', 'MSFT', 'SPY', 'TLT'],
#     'Asset Class': ['Equities', 'Equities', 'Equities', 'Fixed Income'],
#     'Sector': ['Technology', 'Technology', 'Broad Market', 'Fixed Income'],
#     'Quantity': [100, 50, 20, 50],
#     'Price': [180, 400, 450, 95],
#     'Value': [18000, 20000, 9000, 4750]
# })
#
# risk_report = run_risk_management_cycle(system, portfolio, time_period)
# print("é£é™©æŠ¥å‘Š:")
# print(risk_report)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå®Œæ•´çš„é‡‘èé£é™©ç®¡ç†ç³»ç»Ÿæ¶æ„ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†ã€é£é™©è¯„ä¼°ã€åˆè§„æ€§æ£€æŸ¥å’Œä¼˜åŒ–å»ºè®®ã€‚è¯¥æ¶æ„æä¾›äº†å…¨é¢çš„é£é™©ç®¡ç†æ¡†æ¶ï¼Œé€‚ç”¨äºå®é™…çš„é‡‘èé£é™©ç®¡ç†éœ€æ±‚ã€‚"
    },
    # ä¸»é¢˜9ï¼šå¤–æ±‡äº¤æ˜“ç³»ç»Ÿ
    {
        "topic_id": 9,
        "category_id": 1,
        "title": "å¤–æ±‡æ•°æ®è·å–ä¸å¤„ç†",
        "code": """import pandas as pd
import numpy as np
import requests
import json
from datetime import datetime, timedelta

def fetch_exchange_rate(base_currency, target_currency, start_date, end_date):
    \"\"\"è·å–æ±‡ç‡æ•°æ®\"\"\"
    try:
        url = f"https://api.exchangerate-api.com/v4/latest/{base_currency}"
        response = requests.get(url)
        data = response.json()
        rate = data['rates'][target_currency]

        print(f"å½“å‰æ±‡ç‡: 1 {base_currency} = {rate} {target_currency}")
        return rate
    except Exception as e:
        print(f"è·å–æ±‡ç‡æ•°æ®å¤±è´¥: {e}")
        return None

def parse_forex_data(raw_data):
    \"\"\"è§£æå¤–æ±‡åŸå§‹æ•°æ®\"\"\"
    try:
        data = json.loads(raw_data)

        if 'Time Series FX (Daily)' in data:
            dates = []
            rates = []

            for date, values in data['Time Series FX (Daily)'].items():
                dates.append(date)
                rates.append(float(values['4. close']))

            df = pd.DataFrame({'Date': dates, 'Rate': rates})
            df['Date'] = pd.to_datetime(df['Date'])
            df = df.sort_values('Date')

            return df
        else:
            print("æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
            return pd.DataFrame()

    except Exception as e:
        print(f"è§£æå¤–æ±‡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def calculate_forex_returns(prices):
    \"\"\"è®¡ç®—æ±‡ç‡æ”¶ç›Šç‡\"\"\"
    returns = []

    for i in range(1, len(prices)):
        daily_return = (prices[i] - prices[i-1]) / prices[i-1]
        returns.append(daily_return)

    return returns

def preprocess_forex_data(df):
    \"\"\"é¢„å¤„ç†å¤–æ±‡æ•°æ®\"\"\"
    # æ£€æŸ¥ç¼ºå¤±å€¼
    if df.isnull().any().any():
        print("æ•°æ®åŒ…å«ç¼ºå¤±å€¼ï¼Œå°†è¿›è¡Œå¤„ç†")
        df = df.dropna()

    # è®¡ç®—æ”¶ç›Šç‡
    df['Return'] = df['Rate'].pct_change()

    # è®¡ç®—ç§»åŠ¨å¹³å‡
    df['MA5'] = df['Rate'].rolling(window=5).mean()
    df['MA20'] = df['Rate'].rolling(window=20).mean()

    # è®¡ç®—æ³¢åŠ¨ç‡
    df['Volatility'] = df['Return'].rolling(window=20).std() * np.sqrt(252)

    return df

def get_forex_data_from_file(file_path):
    \"\"\"ä»æ–‡ä»¶è¯»å–å¤–æ±‡æ•°æ®\"\"\"
    try:
        df = pd.read_csv(file_path)
        df['Date'] = pd.to_datetime(df['Date'])

        return df
    except Exception as e:
        print(f"ä»æ–‡ä»¶è¯»å–æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è·å–æ±‡ç‡æ•°æ®
    exchange_rate = fetch_exchange_rate("USD", "CNY")

    # ä»æ–‡ä»¶è¯»å–æ•°æ®
    data_file = "forex_data.csv"
    forex_data = get_forex_data_from_file(data_file)

    if not forex_data.empty:
        processed_data = preprocess_forex_data(forex_data)
        print(processed_data.head())
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¤–æ±‡äº¤æ˜“ç³»ç»Ÿä¸­çš„æ•°æ®è·å–ä¸å¤„ç†ï¼ŒåŒ…æ‹¬ä»APIè·å–å®æ—¶æ±‡ç‡ã€è§£æå†å²æ•°æ®ã€è®¡ç®—æ”¶ç›Šç‡ã€é¢„å¤„ç†æ•°æ®ä»¥åŠä»æ–‡ä»¶è¯»å–æ•°æ®ç­‰åŠŸèƒ½ã€‚è¿™äº›åŠŸèƒ½æ˜¯å¤–æ±‡äº¤æ˜“ç³»ç»Ÿçš„åŸºç¡€ã€‚"
    },
    {
        "topic_id": 9,
        "category_id": 2,
        "title": "æ±‡ç‡åˆ†æä¸é¢„æµ‹",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

def analyze_exchange_rate_trends(data, currency_pair):
    \"\"\"åˆ†ææ±‡ç‡è¶‹åŠ¿\"\"\"
    print(f"æ±‡ç‡è¶‹åŠ¿åˆ†æ ({currency_pair}):")

    # è®¡ç®—åŸºç¡€ç»Ÿè®¡æ•°æ®
    mean_rate = data['Rate'].mean()
    std_rate = data['Rate'].std()
    max_rate = data['Rate'].max()
    min_rate = data['Rate'].min()

    print(f"å¹³å‡æ±‡ç‡: {mean_rate:.4f}")
    print(f"æ±‡ç‡æ ‡å‡†å·®: {std_rate:.4f}")
    print(f"æœ€é«˜æ±‡ç‡: {max_rate:.4f}")
    print(f"æœ€ä½æ±‡ç‡: {min_rate:.4f}")

    return {'mean': mean_rate, 'std': std_rate, 'max': max_rate, 'min': min_rate}

def build_forex_prediction_model(data, model_type='linear'):
    \"\"\"æ„å»ºæ±‡ç‡é¢„æµ‹æ¨¡å‹\"\"\"
    # å‡†å¤‡ç‰¹å¾
    data['Lag1'] = data['Rate'].shift(1)
    data['Lag2'] = data['Rate'].shift(2)
    data['Lag3'] = data['Rate'].shift(3)
    data = data.dropna()

    X = data[['Lag1', 'Lag2', 'Lag3', 'MA5', 'MA20']]
    y = data['Rate']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if model_type == 'linear':
        model = LinearRegression()
    elif model_type == 'random_forest':
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹")

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"æ¨¡å‹æ€§èƒ½ - MSE: {mse:.4f}, RÂ²: {r2:.4f}")

    return model, X_test, y_test, y_pred

def plot_exchange_rate_predictions(data, actual, predicted):
    \"\"\"ç»˜åˆ¶æ±‡ç‡é¢„æµ‹ç»“æœ\"\"\"
    plt.figure(figsize=(12, 6))
    plt.plot(data.index[-len(actual):], actual, label='å®é™…æ±‡ç‡')
    plt.plot(data.index[-len(predicted):], predicted, label='é¢„æµ‹æ±‡ç‡', linestyle='--')
    plt.title('æ±‡ç‡é¢„æµ‹')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('æ±‡ç‡')
    plt.legend()
    plt.grid(True)
    plt.savefig('forex_prediction.png')
    plt.show()

def identify_forex_correlations(data, other_currency_data):
    \"\"\"è¯†åˆ«æ±‡ç‡ç›¸å…³æ€§\"\"\"
    # è®¡ç®—ç›¸å…³æ€§
    correlation = data['Rate'].corr(other_currency_data['Rate'])
    print(f"æ±‡ç‡ç›¸å…³æ€§: {correlation:.4f}")

    # ç»˜åˆ¶ç›¸å…³å›¾
    plt.figure(figsize=(10, 6))
    plt.scatter(data['Rate'], other_currency_data['Rate'])
    plt.title('æ±‡ç‡ç›¸å…³æ€§')
    plt.xlabel('æ±‡ç‡1')
    plt.ylabel('æ±‡ç‡2')
    plt.grid(True)
    plt.savefig('forex_correlation.png')
    plt.show()

    return correlation

def forecast_exchange_rate(model, features):
    \"\"\"é¢„æµ‹æœªæ¥æ±‡ç‡\"\"\"
    try:
        prediction = model.predict(features)
        return prediction
    except Exception as e:
        print(f"é¢„æµ‹å¤±è´¥: {e}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
# data_file = "forex_data.csv"
# forex_data = get_forex_data_from_file(data_file)
# processed_data = preprocess_forex_data(forex_data)
#
# # è¶‹åŠ¿åˆ†æ
# analyze_exchange_rate_trends(processed_data, "USD/CNY")
#
# # æ„å»ºé¢„æµ‹æ¨¡å‹
# model, X_test, y_test, y_pred = build_forex_prediction_model(processed_data)
# plot_exchange_rate_predictions(processed_data, y_test, y_pred)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºæ±‡ç‡åˆ†æä¸é¢„æµ‹åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¶‹åŠ¿åˆ†æã€æ„å»ºé¢„æµ‹æ¨¡å‹ã€ç»˜åˆ¶é¢„æµ‹ç»“æœã€è¯†åˆ«æ±‡ç‡ç›¸å…³æ€§ä»¥åŠé¢„æµ‹æœªæ¥æ±‡ç‡ç­‰ã€‚è¿™äº›åŠŸèƒ½å¸®åŠ©å¤–æ±‡äº¤æ˜“è€…åšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ã€‚"
    },
    {
        "topic_id": 9,
        "category_id": 3,
        "title": "å¤–æ±‡äº¤æ˜“ç­–ç•¥å®ç°",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

class ForexTradingStrategy:
    \"\"\"å¤–æ±‡äº¤æ˜“ç­–ç•¥åŸºç±»\"\"\"

    def __init__(self, name):
        self.name = name
        self.signals = []
        self.positions = []

    def generate_signals(self, data):
        \"\"\"ç”Ÿæˆäº¤æ˜“ä¿¡å·\"\"\"
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")

    def plot_signals(self, data):
        \"\"\"ç»˜åˆ¶äº¤æ˜“ä¿¡å·\"\"\"
        plt.figure(figsize=(12, 6))
        plt.plot(data['Date'], data['Rate'], label='æ±‡ç‡')

        for i, signal in enumerate(self.signals):
            date = data.iloc[i]['Date']
            rate = data.iloc[i]['Rate']

            if signal == 1:
                plt.scatter(date, rate, color='green', marker='^', label='ä¹°å…¥ä¿¡å·')
            elif signal == -1:
                plt.scatter(date, rate, color='red', marker='v', label='å–å‡ºä¿¡å·')

        plt.title(f"{self.name} - äº¤æ˜“ä¿¡å·")
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('æ±‡ç‡')
        plt.legend()
        plt.grid(True)
        plt.savefig(f'{self.name}_signals.png')
        plt.show()

class MovingAverageCrossoverStrategy(ForexTradingStrategy):
    \"\"\"ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥\"\"\"

    def __init__(self, short_window=5, long_window=20):
        super().__init__("ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥")
        self.short_window = short_window
        self.long_window = long_window

    def generate_signals(self, data):
        \"\"\"ç”Ÿæˆç§»åŠ¨å¹³å‡äº¤å‰ä¿¡å·\"\"\"
        self.signals = np.zeros(len(data))

        for i in range(self.long_window, len(data)):
            short_avg = data['Rate'][i - self.short_window:i].mean()
            long_avg = data['Rate'][i - self.long_window:i].mean()

            if short_avg > long_avg and self.signals[i-1] != 1:
                self.signals[i] = 1
            elif short_avg < long_avg and self.signals[i-1] != -1:
                self.signals[i] = -1
            else:
                self.signals[i] = self.signals[i-1]

        return self.signals

class BollingerBandsStrategy(ForexTradingStrategy):
    \"\"\"å¸ƒæ—å¸¦ç­–ç•¥\"\"\"

    def __init__(self, window=20, num_std=2):
        super().__init__("å¸ƒæ—å¸¦ç­–ç•¥")
        self.window = window
        self.num_std = num_std

    def generate_signals(self, data):
        \"\"\"ç”Ÿæˆå¸ƒæ—å¸¦äº¤æ˜“ä¿¡å·\"\"\"
        self.signals = np.zeros(len(data))

        for i in range(self.window, len(data)):
            prices = data['Rate'][i - self.window:i]
            mean = prices.mean()
            std = prices.std()
            upper_band = mean + self.num_std * std
            lower_band = mean - self.num_std * std

            current_price = data['Rate'][i]

            if current_price < lower_band and self.signals[i-1] != 1:
                self.signals[i] = 1
            elif current_price > upper_band and self.signals[i-1] != -1:
                self.signals[i] = -1
            else:
                self.signals[i] = self.signals[i-1]

        return self.signals

class RSIOverboughtOversoldStrategy(ForexTradingStrategy):
    \"\"\"RSIè¶…ä¹°è¶…å–ç­–ç•¥\"\"\"

    def __init__(self, window=14, overbought=70, oversold=30):
        super().__init__("RSIè¶…ä¹°è¶…å–ç­–ç•¥")
        self.window = window
        self.overbought = overbought
        self.oversold = oversold

    def calculate_rsi(self, data):
        \"\"\"è®¡ç®—RSIæŒ‡æ ‡\"\"\"
        delta = data['Rate'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=self.window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=self.window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))

        return rsi

    def generate_signals(self, data):
        \"\"\"ç”ŸæˆRSIäº¤æ˜“ä¿¡å·\"\"\"
        rsi = self.calculate_rsi(data)
        self.signals = np.zeros(len(data))

        for i in range(self.window, len(data)):
            if rsi[i] < self.oversold and self.signals[i-1] != 1:
                self.signals[i] = 1
            elif rsi[i] > self.overbought and self.signals[i-1] != -1:
                self.signals[i] = -1
            else:
                self.signals[i] = self.signals[i-1]

        return self.signals

def backtest_strategy(data, strategy):
    \"\"\"å›æµ‹äº¤æ˜“ç­–ç•¥\"\"\"
    # ç”Ÿæˆä¿¡å·
    signals = strategy.generate_signals(data)

    # æ¨¡æ‹Ÿäº¤æ˜“
    position = 0
    positions = []
    portfolio_value = [10000]  # åˆå§‹èµ„é‡‘

    for i in range(len(data)):
        if signals[i] == 1 and position == 0:
            position = 1
            shares = portfolio_value[-1] / data['Rate'][i]
            print(f"ä¹°å…¥: {data['Date'][i]}, ä»·æ ¼: {data['Rate'][i]:.4f}")
        elif signals[i] == -1 and position == 1:
            position = 0
            portfolio_value.append(shares * data['Rate'][i])
            print(f"å–å‡º: {data['Date'][i]}, ä»·æ ¼: {data['Rate'][i]:.4f}")

        positions.append(position)

    final_value = portfolio_value[-1]
    total_return = (final_value - 10000) / 10000 * 100
    print(f"æœ€ç»ˆä»·å€¼: ${final_value:.2f}")
    print(f"æ€»æ”¶ç›Šç‡: {total_return:.2f}%")

    return portfolio_value

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è¯»å–æ•°æ®
    data = pd.read_csv("forex_data.csv")
    data['Date'] = pd.to_datetime(data['Date'])

    # ä½¿ç”¨ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥
    strategy = MovingAverageCrossoverStrategy()
    signals = strategy.generate_signals(data)

    # å›æµ‹ç­–ç•¥
    backtest_strategy(data, strategy)

    # ç»˜åˆ¶ä¿¡å·å›¾
    strategy.plot_signals(data)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¤–æ±‡äº¤æ˜“ç­–ç•¥çš„å®ç°ï¼ŒåŒ…æ‹¬ç§»åŠ¨å¹³å‡äº¤å‰ç­–ç•¥ã€å¸ƒæ—å¸¦ç­–ç•¥å’ŒRSIè¶…ä¹°è¶…å–ç­–ç•¥ã€‚è¿˜åŒ…æ‹¬ç­–ç•¥å›æµ‹å’Œä¿¡å·å¯è§†åŒ–åŠŸèƒ½ï¼Œå¸®åŠ©äº¤æ˜“è€…ä¼˜åŒ–å’Œè¯„ä¼°äº¤æ˜“ç­–ç•¥ã€‚"
    },
    {
        "topic_id": 9,
        "category_id": 4,
        "title": "å¤–æ±‡é£é™©æ§åˆ¶ä¸èµ„é‡‘ç®¡ç†",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

class ForexRiskManager:
    \"\"\"å¤–æ±‡é£é™©ç®¡ç†å™¨\"\"\"

    def __init__(self, initial_capital, risk_per_trade):
        \"\"\"
        åˆå§‹åŒ–é£é™©ç®¡ç†å™¨
        å‚æ•°:
            initial_capital: åˆå§‹èµ„é‡‘
            risk_per_trade: æ¯ç¬”äº¤æ˜“é£é™©æ¯”ä¾‹ï¼ˆ0-1ï¼‰
        \"\"\"
        self.initial_capital = initial_capital
        self.current_capital = initial_capital
        self.risk_per_trade = risk_per_trade
        self.max_drawdown = 0
        self.drawdown = 0
        self.peak_value = initial_capital

    def calculate_position_size(self, entry_price, stop_loss_price):
        \"\"\"è®¡ç®—ä»“ä½å¤§å°\"\"\"
        risk_amount = self.current_capital * self.risk_per_trade

        risk_per_unit = entry_price - stop_loss_price

        if risk_per_unit <= 0:
            print("æ­¢æŸä»·æ ¼å¿…é¡»ä½äºå…¥åœºä»·æ ¼")
            return 0

        position_size = risk_amount / risk_per_unit

        return position_size

    def update_risk_metrics(self, current_portfolio_value):
        \"\"\"æ›´æ–°é£é™©æŒ‡æ ‡\"\"\"
        # æ›´æ–°å³°å€¼å’Œæœ€å¤§å›æ’¤
        if current_portfolio_value > self.peak_value:
            self.peak_value = current_portfolio_value
            self.drawdown = 0
        else:
            self.drawdown = (self.peak_value - current_portfolio_value) / self.peak_value

            if self.drawdown > self.max_drawdown:
                self.max_drawdown = self.drawdown

        # æ›´æ–°å½“å‰èµ„é‡‘
        self.current_capital = current_portfolio_value

    def calculate_sharpe_ratio(self, returns, risk_free_rate=0.02):
        \"\"\"è®¡ç®—å¤æ™®æ¯”ç‡\"\"\"
        excess_returns = np.array(returns) - risk_free_rate

        mean_excess_return = np.mean(excess_returns)
        std_excess_return = np.std(excess_returns)

        if std_excess_return == 0:
            return 0

        sharpe_ratio = mean_excess_return / std_excess_return

        return sharpe_ratio

    def calculate_sortino_ratio(self, returns, risk_free_rate=0.02, target_return=0):
        \"\"\"è®¡ç®—ç´¢æè¯ºæ¯”ç‡\"\"\"
        excess_returns = np.array(returns) - risk_free_rate

        downside_returns = np.where(excess_returns < target_return, excess_returns, 0)

        mean_downside = np.mean(downside_returns)
        std_downside = np.std(downside_returns)

        if std_downside == 0:
            return 0

        sortino_ratio = (np.mean(excess_returns) - target_return) / std_downside

        return sortino_ratio

    def print_risk_summary(self):
        \"\"\"æ‰“å°é£é™©æ¦‚è¦\"\"\"
        print("é£é™©æ¦‚è¦:")
        print(f"å½“å‰èµ„é‡‘: {self.current_capital:.2f}")
        print(f"åˆå§‹èµ„é‡‘: {self.initial_capital:.2f}")
        print(f"æœ€å¤§å›æ’¤: {self.max_drawdown:.2%}")
        print(f"é£é™©/äº¤æ˜“: {self.risk_per_trade:.2%}")

def plot_drawdown(portfolio_values):
    \"\"\"ç»˜åˆ¶å›æ’¤æ›²çº¿\"\"\"
    peak = portfolio_values[0]
    drawdowns = []

    for value in portfolio_values:
        if value > peak:
            peak = value

        drawdown = (peak - value) / peak
        drawdowns.append(drawdown)

    plt.figure(figsize=(12, 6))
    plt.plot(drawdowns)
    plt.title('æœ€å¤§å›æ’¤')
    plt.xlabel('æ—¶é—´')
    plt.ylabel('å›æ’¤')
    plt.grid(True)
    plt.savefig('drawdown.png')
    plt.show()

def calculate_drawdown(portfolio_values):
    \"\"\"è®¡ç®—æœ€å¤§å›æ’¤\"\"\"
    max_value = portfolio_values[0]
    max_drawdown = 0

    for value in portfolio_values:
        if value > max_value:
            max_value = value
        else:
            drawdown = (max_value - value) / max_value
            if drawdown > max_drawdown:
                max_drawdown = drawdown

    return max_drawdown

def risk_adjusted_position_sizing(volatility, risk_per_trade, current_price, initial_capital):
    \"\"\"é£é™©è°ƒæ•´ä»“ä½è§„æ¨¡\"\"\"
    daily_volatility = volatility / np.sqrt(252)

    stop_loss_distance = current_price * daily_volatility * 2

    risk_amount = initial_capital * risk_per_trade

    position_size = risk_amount / stop_loss_distance

    return position_size

def implement_trailing_stop_loss(data, entry_price, trail_distance):
    \"\"\"å®ç°è¿½è¸ªæ­¢æŸ\"\"\"
    stop_loss_prices = []

    highest_price = entry_price

    for i in range(len(data)):
        current_price = data['Rate'][i]

        if current_price > highest_price:
            highest_price = current_price

        stop_loss_price = highest_price * (1 - trail_distance)
        stop_loss_prices.append(stop_loss_price)

    return stop_loss_prices

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–é£é™©ç®¡ç†å™¨
    risk_manager = ForexRiskManager(10000, 0.02)

    # è®¡ç®—ä»“ä½å¤§å°
    entry_price = 6.90
    stop_loss_price = 6.85
    position_size = risk_manager.calculate_position_size(entry_price, stop_loss_price)
    print(f"å»ºè®®ä»“ä½å¤§å°: {position_size:.2f}")

    # æ›´æ–°é£é™©æŒ‡æ ‡
    portfolio_values = [10000, 10500, 10300, 11000, 10800, 12000]
    for value in portfolio_values:
        risk_manager.update_risk_metrics(value)

    # æ‰“å°é£é™©æ¦‚è¦
    risk_manager.print_risk_summary()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¤–æ±‡é£é™©æ§åˆ¶ä¸èµ„é‡‘ç®¡ç†ï¼ŒåŒ…æ‹¬é£é™©ç®¡ç†å™¨ç±»ã€ä»“ä½å¤§å°è®¡ç®—ã€é£é™©æŒ‡æ ‡è·Ÿè¸ªã€å›æ’¤åˆ†æã€é£é™©è°ƒæ•´ä»“ä½è§„æ¨¡ä»¥åŠè¿½è¸ªæ­¢æŸå®ç°ã€‚è¿™äº›åŠŸèƒ½å¸®åŠ©äº¤æ˜“è€…ç®¡ç†é£é™©ï¼Œä¿æŠ¤èµ„é‡‘ï¼Œå¹¶ä¼˜åŒ–äº¤æ˜“ç­–ç•¥çš„è¡¨ç°ã€‚"
    },
    {
        "topic_id": 9,
        "category_id": 5,
        "title": "å¤–æ±‡äº¤æ˜“æ‰§è¡Œä¸ç›‘æ§",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime
import time
from collections import deque

class ForexTradingSystem:
    \"\"\"å¤–æ±‡äº¤æ˜“ç³»ç»Ÿ\"\"\"

    def __init__(self, api_interface, strategy, risk_manager):
        self.api_interface = api_interface
        self.strategy = strategy
        self.risk_manager = risk_manager
        self.trade_history = []
        self.pending_orders = []
        self.current_position = 0

    def connect_to_exchange(self):
        \"\"\"è¿æ¥åˆ°äº¤æ˜“æ‰€\"\"\"
        if self.api_interface.connect():
            print("æˆåŠŸè¿æ¥åˆ°äº¤æ˜“æ‰€")
            return True
        else:
            print("è¿æ¥åˆ°äº¤æ˜“æ‰€å¤±è´¥")
            return False

    def execute_order(self, order_type, price, quantity):
        \"\"\"æ‰§è¡Œè®¢å•\"\"\"
        try:
            if order_type == "buy":
                order_id = self.api_interface.place_buy_order(price, quantity)
                print(f"ä¹°å…¥è®¢å•æ‰§è¡ŒæˆåŠŸï¼Œè®¢å•ID: {order_id}")
            elif order_type == "sell":
                order_id = self.api_interface.place_sell_order(price, quantity)
                print(f"å–å‡ºè®¢å•æ‰§è¡ŒæˆåŠŸï¼Œè®¢å•ID: {order_id}")

            # æ·»åŠ åˆ°è®¢å•å†å²
            self.trade_history.append({
                "order_id": order_id,
                "order_type": order_type,
                "price": price,
                "quantity": quantity,
                "timestamp": datetime.now()
            })

            return order_id
        except Exception as e:
            print(f"è®¢å•æ‰§è¡Œå¤±è´¥: {e}")
            return None

    def monitor_positions(self):
        \"\"\"ç›‘æ§æŒä»“\"\"\"
        positions = self.api_interface.get_positions()
        self.current_position = positions.get("USD/CNY", 0)

        print(f"å½“å‰æŒä»“: {self.current_position:.2f}")

        return self.current_position

    def monitor_pending_orders(self):
        \"\"\"ç›‘æ§å¾…å¤„ç†è®¢å•\"\"\"
        for order in self.pending_orders.copy():
            status = self.api_interface.get_order_status(order['order_id'])

            if status == "filled":
                print(f"è®¢å• {order['order_id']} å·²å®Œæˆ")
                self.trade_history.append(order)
                self.pending_orders.remove(order)
            elif status == "canceled":
                print(f"è®¢å• {order['order_id']} å·²å–æ¶ˆ")
                self.pending_orders.remove(order)
            elif status == "expired":
                print(f"è®¢å• {order['order_id']} å·²è¿‡æœŸ")
                self.pending_orders.remove(order)

    def run_trading_loop(self):
        \"\"\"è¿è¡Œäº¤æ˜“å¾ªç¯\"\"\"
        while True:
            # è·å–æœ€æ–°æ•°æ®
            latest_data = self.api_interface.get_latest_data()

            # ç”Ÿæˆä¿¡å·
            signal = self.strategy.generate_signals(latest_data)

            # ç›‘æ§æŒä»“å’Œè®¢å•
            positions = self.monitor_positions()
            self.monitor_pending_orders()

            # æ ¹æ®ä¿¡å·æ‰§è¡Œäº¤æ˜“
            if signal == 1 and positions == 0:
                entry_price = latest_data['Rate'].iloc[-1]
                stop_loss_price = entry_price * 0.99

                position_size = self.risk_manager.calculate_position_size(entry_price, stop_loss_price)

                if position_size > 0:
                    order_id = self.execute_order("buy", entry_price, position_size)

                    if order_id:
                        self.pending_orders.append({
                            "order_id": order_id,
                            "order_type": "buy",
                            "price": entry_price,
                            "quantity": position_size,
                            "timestamp": datetime.now()
                        })

            elif signal == -1 and positions > 0:
                exit_price = latest_data['Rate'].iloc[-1]
                order_id = self.execute_order("sell", exit_price, positions)

                if order_id:
                    self.pending_orders.append({
                        "order_id": order_id,
                        "order_type": "sell",
                        "price": exit_price,
                        "quantity": positions,
                        "timestamp": datetime.now()
                    })

            # æš‚åœ
            time.sleep(60)

class MockAPI:
    \"\"\"æ¨¡æ‹ŸAPIæ¥å£\"\"\"

    def __init__(self, initial_price=6.90):
        self.connection_status = False
        self.latest_price = initial_price
        self.orders = []
        self.positions = {}
        self.order_counter = 0

    def connect(self):
        \"\"\"æ¨¡æ‹Ÿè¿æ¥\"\"\"
        self.connection_status = True
        return True

    def disconnect(self):
        \"\"\"æ¨¡æ‹Ÿæ–­å¼€è¿æ¥\"\"\"
        self.connection_status = False
        return True

    def place_buy_order(self, price, quantity):
        \"\"\"æ¨¡æ‹Ÿä¹°å…¥è®¢å•\"\"\"
        order_id = f"BUY{self.order_counter:04d}"
        self.order_counter += 1

        self.orders.append({
            "order_id": order_id,
            "type": "buy",
            "price": price,
            "quantity": quantity,
            "status": "filled"
        })

        if "USD/CNY" not in self.positions:
            self.positions["USD/CNY"] = 0

        self.positions["USD/CNY"] += quantity

        return order_id

    def place_sell_order(self, price, quantity):
        \"\"\"æ¨¡æ‹Ÿå–å‡ºè®¢å•\"\"\"
        order_id = f"SELL{self.order_counter:04d}"
        self.order_counter += 1

        self.orders.append({
            "order_id": order_id,
            "type": "sell",
            "price": price,
            "quantity": quantity,
            "status": "filled"
        })

        if "USD/CNY" in self.positions:
            self.positions["USD/CNY"] -= quantity

            if self.positions["USD/CNY"] < 0:
                self.positions["USD/CNY"] = 0

        return order_id

    def get_positions(self):
        \"\"\"è·å–æŒä»“\"\"\"
        return self.positions

    def get_order_status(self, order_id):
        \"\"\"è·å–è®¢å•çŠ¶æ€\"\"\"
        for order in self.orders:
            if order["order_id"] == order_id:
                return order["status"]

        return "not_found"

    def get_latest_data(self):
        \"\"\"è·å–æœ€æ–°æ•°æ®\"\"\"
        # æ¨¡æ‹Ÿæ±‡ç‡å˜åŒ–
        random_change = (np.random.random() - 0.5) * 0.01
        self.latest_price *= (1 + random_change)

        # æ„é€ æ•°æ®
        data = pd.DataFrame({
            "Date": [datetime.now()],
            "Rate": [self.latest_price],
            "Volume": [10000]
        })

        return data

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ç»„ä»¶
    api = MockAPI()
    strategy = MovingAverageCrossoverStrategy()
    risk_manager = ForexRiskManager(10000, 0.02)

    # åˆå§‹åŒ–äº¤æ˜“ç³»ç»Ÿ
    trading_system = ForexTradingSystem(api, strategy, risk_manager)

    # è¿æ¥åˆ°äº¤æ˜“æ‰€
    trading_system.connect_to_exchange()

    # è·å–æœ€æ–°æ•°æ®
    latest_data = api.get_latest_data()

    # ç›‘æ§æŒä»“
    positions = trading_system.monitor_positions()
    print(f"å½“å‰æŒä»“: {positions}")

    # è¿è¡Œäº¤æ˜“å¾ªç¯ï¼ˆæ¨¡æ‹Ÿï¼‰
    try:
        for i in range(10):
            print(f"\\n=== äº¤æ˜“å¾ªç¯ {i+1} ===")

            # è·å–æœ€æ–°æ•°æ®
            latest_data = api.get_latest_data()
            print(f"æœ€æ–°æ±‡ç‡: {latest_data['Rate'].iloc[-1]:.4f}")

            # æ¨¡æ‹Ÿäº¤æ˜“
            if i % 3 == 0 and positions == 0:
                entry_price = latest_data['Rate'].iloc[-1]
                stop_loss_price = entry_price * 0.99
                position_size = risk_manager.calculate_position_size(entry_price, stop_loss_price)
                order_id = trading_system.execute_order("buy", entry_price, position_size)
                print(f"ä¹°å…¥è®¢å•: {order_id}")
            elif i % 5 == 0 and positions > 0:
                exit_price = latest_data['Rate'].iloc[-1]
                order_id = trading_system.execute_order("sell", exit_price, positions)
                print(f"å–å‡ºè®¢å•: {order_id}")

            # æ›´æ–°é£é™©æŒ‡æ ‡
            trading_system.monitor_positions()

            time.sleep(1)
    except KeyboardInterrupt:
        print("äº¤æ˜“å¾ªç¯å·²åœæ­¢")
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå¤–æ±‡äº¤æ˜“æ‰§è¡Œä¸ç›‘æ§ç³»ç»Ÿï¼ŒåŒ…æ‹¬äº¤æ˜“ç³»ç»Ÿæ¶æ„ã€è®¢å•æ‰§è¡Œã€é£é™©ç®¡ç†å’Œäº¤æ˜“ç›‘æ§ã€‚è¿˜åŒ…å«æ¨¡æ‹ŸAPIæ¥å£ï¼Œå¯ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºäº¤æ˜“ç³»ç»ŸåŠŸèƒ½ã€‚"
    },
    {
        "topic_id": 9,
        "category_id": 6,
        "title": "å®Œæ•´å¤–æ±‡äº¤æ˜“ç³»ç»Ÿé¡¹ç›®",
        "code": """import pandas as pd
import numpy as np
from datetime import datetime
import sys
import os

class CompleteForexTradingSystem:
    \"\"\"å®Œæ•´çš„å¤–æ±‡äº¤æ˜“ç³»ç»Ÿ\"\"\"

    def __init__(self, config_file="config.json"):
        self.config = self.load_config(config_file)
        self.api = None
        self.strategy = None
        self.risk_manager = None
        self.data_processor = None

    def load_config(self, config_file):
        \"\"\"åŠ è½½é…ç½®æ–‡ä»¶\"\"\"
        if not os.path.exists(config_file):
            print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return self.default_config()

        try:
            import json
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return self.default_config()

    def default_config(self):
        \"\"\"é»˜è®¤é…ç½®\"\"\"
        return {
            "api": {
                "type": "mock",
                "key": "test_key"
            },
            "strategy": {
                "type": "ma_crossover",
                "parameters": {
                    "short_window": 5,
                    "long_window": 20
                }
            },
            "risk": {
                "initial_capital": 10000,
                "risk_per_trade": 0.02,
                "max_drawdown": 0.2
            }
        }

    def initialize_components(self):
        \"\"\"åˆå§‹åŒ–å„ä¸ªç»„ä»¶\"\"\"
        print("åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")

        # åˆå§‹åŒ–APIæ¥å£
        if self.config["api"]["type"] == "mock":
            class MockAPI:
                def __init__(self, initial_price=6.90):
                    self.connection_status = False
                    self.latest_price = initial_price
                    self.orders = []
                    self.positions = {}
                    self.order_counter = 0

                def connect(self):
                    self.connection_status = True
                    return True

                def get_latest_data(self):
                    return pd.DataFrame({
                        "Date": [datetime.now()],
                        "Rate": [self.latest_price],
                        "Volume": [10000]
                    })

            self.api = MockAPI()
        else:
            raise NotImplementedError("å®é™…APIæ¥å£æœªå®ç°")

        # åˆå§‹åŒ–ç­–ç•¥
        if self.config["strategy"]["type"] == "ma_crossover":
            class MovingAverageCrossoverStrategy:
                def __init__(self, short_window=5, long_window=20):
                    self.short_window = short_window
                    self.long_window = long_window

                def generate_signals(self, data):
                    return 1 if np.random.random() > 0.5 else -1

            self.strategy = MovingAverageCrossoverStrategy()

        # åˆå§‹åŒ–é£é™©ç®¡ç†å™¨
        class ForexRiskManager:
            def __init__(self, initial_capital, risk_per_trade):
                self.initial_capital = initial_capital
                self.current_capital = initial_capital
                self.risk_per_trade = risk_per_trade
                self.max_drawdown = 0
                self.drawdown = 0
                self.peak_value = initial_capital

            def calculate_position_size(self, entry_price, stop_loss_price):
                return 1000

            def update_risk_metrics(self, current_portfolio_value):
                pass

        self.risk_manager = ForexRiskManager(
            self.config["risk"]["initial_capital"],
            self.config["risk"]["risk_per_trade"]
        )

    def connect(self):
        \"\"\"è¿æ¥åˆ°äº¤æ˜“æ¥å£\"\"\"
        print("è¿æ¥åˆ°äº¤æ˜“æ¥å£...")
        return self.api.connect()

    def load_data(self):
        \"\"\"åŠ è½½å†å²æ•°æ®\"\"\"
        print("åŠ è½½å†å²æ•°æ®...")

        data = pd.DataFrame({
            "Date": pd.date_range(start="2023-01-01", periods=30),
            "Rate": np.random.uniform(6.8, 7.2, 30)
        })

        return data

    def backtest_strategy(self, data):
        \"\"\"å›æµ‹ç­–ç•¥\"\"\"
        print("å¼€å§‹å›æµ‹ç­–ç•¥...")

        # é¢„å¤„ç†æ•°æ®
        data['Return'] = data['Rate'].pct_change()
        data['MA5'] = data['Rate'].rolling(window=5).mean()
        data['MA20'] = data['Rate'].rolling(window=20).mean()

        # ç”Ÿæˆäº¤æ˜“ä¿¡å·
        signals = [0] * len(data)
        for i in range(20, len(data)):
            if data['MA5'][i] > data['MA20'][i] and signals[i-1] != 1:
                signals[i] = 1
            elif data['MA5'][i] < data['MA20'][i] and signals[i-1] != -1:
                signals[i] = -1
            else:
                signals[i] = signals[i-1]

        # å›æµ‹ç­–ç•¥
        portfolio_values = [10000]
        position = 0
        shares = 0

        for i in range(len(data)):
            if signals[i] == 1 and position == 0:
                position = 1
                shares = portfolio_values[-1] / data['Rate'][i]
                print(f"ä¹°å…¥: {data['Date'][i]}, ä»·æ ¼: {data['Rate'][i]:.4f}")
            elif signals[i] == -1 and position == 1:
                position = 0
                portfolio_values.append(shares * data['Rate'][i])
                print(f"å–å‡º: {data['Date'][i]}, ä»·æ ¼: {data['Rate'][i]:.4f}")

        return data, signals, portfolio_values

    def run_live_trading(self):
        \"\"\"è¿è¡Œå®æ—¶äº¤æ˜“\"\"\"
        print("å¯åŠ¨å®æ—¶äº¤æ˜“...")

        try:
            while True:
                # è·å–æœ€æ–°æ•°æ®
                latest_data = self.api.get_latest_data()

                # é¢„å¤„ç†æ•°æ®
                latest_data['Return'] = latest_data['Rate'].pct_change()
                latest_data['MA5'] = latest_data['Rate'].rolling(window=5).mean()
                latest_data['MA20'] = latest_data['Rate'].rolling(window=20).mean()

                # ç”Ÿæˆäº¤æ˜“ä¿¡å·
                signal = self.strategy.generate_signals(latest_data)

                # æ‰§è¡Œäº¤æ˜“
                self.execute_trade(signal, latest_data)

                # æ›´æ–°é£é™©æŒ‡æ ‡
                self.risk_manager.update_risk_metrics(self.api.get_positions())

                # æ‰“å°çŠ¶æ€
                self.print_status()

                # æš‚åœ
                import time
                time.sleep(self.config.get("trading_interval", 60))

        except KeyboardInterrupt:
            print("äº¤æ˜“å·²åœæ­¢")
            return

    def execute_trade(self, signal, data):
        \"\"\"æ‰§è¡Œäº¤æ˜“\"\"\"
        if signal == 1 and self.api.get_positions().get("USD/CNY", 0) == 0:
            entry_price = data['Rate'].iloc[-1]
            stop_loss_price = entry_price * 0.99

            position_size = self.risk_manager.calculate_position_size(entry_price, stop_loss_price)

            if position_size > 0:
                order_id = self.api.place_buy_order(entry_price, position_size)

                if order_id:
                    self.pending_orders.append({
                        "order_id": order_id,
                        "order_type": "buy",
                        "price": entry_price,
                        "quantity": position_size,
                        "timestamp": datetime.now()
                    })

        elif signal == -1 and self.api.get_positions().get("USD/CNY", 0) > 0:
            exit_price = data['Rate'].iloc[-1]
            order_id = self.api.place_sell_order(exit_price, self.api.get_positions().get("USD/CNY", 0))

            if order_id:
                self.pending_orders.append({
                    "order_id": order_id,
                    "order_type": "sell",
                    "price": exit_price,
                    "quantity": self.api.get_positions().get("USD/CNY", 0),
                    "timestamp": datetime.now()
                })

    def print_status(self):
        \"\"\"æ‰“å°çŠ¶æ€\"\"\"
        positions = self.api.get_positions()
        print(f"\\n=== ç³»ç»ŸçŠ¶æ€ ===\\næ—¶é—´: {datetime.now()}\\næŒä»“: {positions.get('USD/CNY', 0):.2f}")

def main():
    \"\"\"ä¸»å‡½æ•°\"\"\"
    # åˆ›å»ºäº¤æ˜“ç³»ç»Ÿ
    system = CompleteForexTradingSystem()

    # åˆå§‹åŒ–ç³»ç»Ÿ
    system.initialize_components()

    # è¿æ¥åˆ°äº¤æ˜“æ¥å£
    connected = system.connect()
    if not connected:
        print("è¿æ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return

    # åŠ è½½å†å²æ•°æ®
    data = system.load_data()
    if data.empty:
        print("æ•°æ®åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return

    # å›æµ‹ç­–ç•¥
    processed_data, signals, portfolio_values = system.backtest_strategy(data)

    # ç”ŸæˆæŠ¥å‘Š
    system.generate_report(processed_data, signals, portfolio_values)

    # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦è¿è¡Œå®æ—¶äº¤æ˜“
    if "--live" in sys.argv:
        system.run_live_trading()

if __name__ == "__main__":
    main()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºå®Œæ•´çš„å¤–æ±‡äº¤æ˜“ç³»ç»Ÿé¡¹ç›®ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæ¶æ„ã€ç»„ä»¶åˆå§‹åŒ–ã€å†å²æ•°æ®å›æµ‹ã€å®æ—¶äº¤æ˜“è¿è¡Œå’ŒæŠ¥å‘Šç”Ÿæˆã€‚è¯¥é¡¹ç›®æä¾›äº†å®Œæ•´çš„ä»£ç ç»“æ„ï¼Œå¯ä½œä¸ºå®é™…å¤–æ±‡äº¤æ˜“ç³»ç»Ÿå¼€å‘çš„åŸºç¡€æ¡†æ¶ã€‚"
    },
    # ä¸»é¢˜10ï¼šæ•°æ®åˆ†æå¯è§†åŒ–
    {
        "topic_id": 10,
        "category_id": 1,
        "title": "é‡‘èæ•°æ®å¯è§†åŒ–åŸºç¡€",
        "code": """import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

def create_basic_plot():
    \"\"\"åˆ›å»ºåŸºç¡€å›¾è¡¨\"\"\"
    x = np.linspace(0, 10, 100)
    y = np.sin(x)

    plt.figure(figsize=(10, 6))
    plt.plot(x, y)
    plt.title("åŸºç¡€æŠ˜çº¿å›¾")
    plt.xlabel("Xè½´")
    plt.ylabel("Yè½´")
    plt.grid(True)
    plt.savefig("basic_plot.png")
    plt.show()

def plot_multiple_data():
    \"\"\"ç»˜åˆ¶å¤šç»„æ•°æ®\"\"\"
    x = np.linspace(0, 10, 100)
    y1 = np.sin(x)
    y2 = np.cos(x)

    plt.figure(figsize=(10, 6))
    plt.plot(x, y1, label="sin(x)", color="blue", linewidth=2)
    plt.plot(x, y2, label="cos(x)", color="red", linewidth=2, linestyle="--")

    plt.title("å¤šä¸ªå‡½æ•°çš„å¯è§†åŒ–")
    plt.xlabel("Xè½´")
    plt.ylabel("Yè½´")
    plt.legend()
    plt.grid(True)
    plt.savefig("multiple_data_plot.png")
    plt.show()

def create_scatter_plot():
    \"\"\"åˆ›å»ºæ•£ç‚¹å›¾\"\"\"
    np.random.seed(42)
    x = np.random.rand(100)
    y = np.random.rand(100)
    size = 1000 * np.random.rand(100)
    color = np.random.rand(100)

    plt.figure(figsize=(10, 6))
    plt.scatter(x, y, s=size, c=color, alpha=0.5, cmap="viridis")

    plt.title("å½©è‰²æ•£ç‚¹å›¾")
    plt.xlabel("Xè½´")
    plt.ylabel("Yè½´")
    plt.colorbar(label="é¢œè‰²")
    plt.savefig("scatter_plot.png")
    plt.show()

def basic_statistical_plot():
    \"\"\"åˆ›å»ºç»Ÿè®¡å›¾è¡¨\"\"\"
    np.random.seed(42)
    data = np.random.randn(1000)

    plt.figure(figsize=(10, 6))
    plt.hist(data, bins=30, alpha=0.7, density=True)

    mu, sigma = np.mean(data), np.std(data)
    x = np.linspace(data.min(), data.max(), 100)
    y = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((x - mu)/sigma)**2)
    plt.plot(x, y, color="red", linewidth=2, label="æ­£æ€åˆ†å¸ƒ")

    plt.title("ç›´æ–¹å›¾ä¸æ¦‚ç‡å¯†åº¦æ›²çº¿")
    plt.xlabel("å€¼")
    plt.ylabel("é¢‘ç‡")
    plt.legend()
    plt.savefig("statistical_plot.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("åˆ›å»ºåŸºç¡€å›¾è¡¨")
    create_basic_plot()

    print("ç»˜åˆ¶å¤šç»„æ•°æ®")
    plot_multiple_data()

    print("åˆ›å»ºæ•£ç‚¹å›¾")
    create_scatter_plot()

    print("åˆ›å»ºç»Ÿè®¡å›¾è¡¨")
    basic_statistical_plot()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†é‡‘èæ•°æ®å¯è§†åŒ–çš„åŸºç¡€å†…å®¹ï¼ŒåŒ…æ‹¬ç»˜åˆ¶åŸºç¡€å›¾è¡¨ã€å¤šç»„æ•°æ®ã€æ•£ç‚¹å›¾å’Œç»Ÿè®¡å›¾è¡¨ç­‰åŸºæœ¬æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•é€‚ç”¨äºå„ç§é‡‘èæ•°æ®åˆ†æåœºæ™¯ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 2,
        "title": "é‡‘èæ•°æ®å¯è§†åŒ–è¿›é˜¶",
        "code": """import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

def financial_time_series_plot():
    \"\"\"ç»˜åˆ¶é‡‘èæ—¶é—´åºåˆ—å›¾è¡¨\"\"\"
    np.random.seed(42)
    dates = pd.date_range(start="2020-01-01", periods=365, freq="D")
    values = np.random.randn(365).cumsum()

    df = pd.DataFrame({"Date": dates, "Value": values})

    plt.figure(figsize=(12, 6))
    plt.plot(df["Date"], df["Value"], color="blue", linewidth=1.5)

    plt.title("é‡‘èæ—¶é—´åºåˆ—å›¾è¡¨")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("å€¼")
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    plt.savefig("time_series_plot.png")
    plt.show()

def candlestick_chart():
    \"\"\"åˆ›å»ºKçº¿å›¾\"\"\"
    np.random.seed(42)
    dates = pd.date_range(start="2020-01-01", periods=100, freq="D")
    open_price = 100 + np.random.randn(100).cumsum()
    high_price = open_price + np.random.rand(100) * 2
    low_price = open_price - np.random.rand(100) * 2
    close_price = open_price + np.random.randn(100)

    df = pd.DataFrame({
        "Date": dates,
        "Open": open_price,
        "High": high_price,
        "Low": low_price,
        "Close": close_price
    })

    plt.figure(figsize=(12, 6))

    for i in range(len(df)):
        color = "green" if df["Close"][i] >= df["Open"][i] else "red"
        plt.vlines(df["Date"][i], df["Low"][i], df["High"][i], color=color, linewidth=1)
        plt.hlines(df["Open"][i], df["Date"][i] - pd.Timedelta(days=0.25),
                  df["Date"][i] + pd.Timedelta(days=0.25), color=color, linewidth=2)
        plt.hlines(df["Close"][i], df["Date"][i] - pd.Timedelta(days=0.25),
                  df["Date"][i] + pd.Timedelta(days=0.25), color=color, linewidth=2)

    plt.title("Kçº¿å›¾")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("ä»·æ ¼")
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    plt.savefig("candlestick_chart.png")
    plt.show()

def financial_heatmap():
    \"\"\"åˆ›å»ºé‡‘èæ•°æ®çƒ­åŠ›å›¾\"\"\"
    np.random.seed(42)
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    dates = pd.date_range(start="2020-01-01", periods=5, freq="D")
    returns = np.random.randn(len(tickers), len(dates))

    df = pd.DataFrame(returns, index=tickers, columns=dates)

    plt.figure(figsize=(10, 8))
    sns.heatmap(df, annot=True, cmap="RdYlGn", center=0)

    plt.title("è‚¡ç¥¨æ”¶ç›Šç‡çƒ­åŠ›å›¾")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("è‚¡ç¥¨ä»£ç ")

    plt.savefig("financial_heatmap.png")
    plt.show()

def financial_box_plot():
    \"\"\"åˆ›å»ºé‡‘èæ•°æ®ç®±çº¿å›¾\"\"\"
    np.random.seed(42)
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    data = []

    for _ in range(len(tickers)):
        data.append(np.random.randn(100) + np.random.rand())

    plt.figure(figsize=(10, 6))
    plt.boxplot(data, labels=tickers)

    plt.title("è‚¡ç¥¨æ”¶ç›Šç‡ç®±çº¿å›¾")
    plt.xlabel("è‚¡ç¥¨ä»£ç ")
    plt.ylabel("æ”¶ç›Šç‡")
    plt.grid(True, alpha=0.3)

    plt.savefig("financial_box_plot.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ç»˜åˆ¶é‡‘èæ—¶é—´åºåˆ—å›¾è¡¨")
    financial_time_series_plot()

    print("åˆ›å»ºKçº¿å›¾")
    candlestick_chart()

    print("åˆ›å»ºé‡‘èæ•°æ®çƒ­åŠ›å›¾")
    financial_heatmap()

    print("åˆ›å»ºé‡‘èæ•°æ®ç®±çº¿å›¾")
    financial_box_plot()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†é‡‘èæ•°æ®å¯è§†åŒ–çš„è¿›é˜¶å†…å®¹ï¼ŒåŒ…æ‹¬æ—¶é—´åºåˆ—å›¾è¡¨ã€Kçº¿å›¾ã€çƒ­åŠ›å›¾å’Œç®±çº¿å›¾ç­‰ã€‚è¿™äº›å›¾è¡¨åœ¨é‡‘èæ•°æ®åˆ†æä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 3,
        "title": "äº¤äº’å¼æ•°æ®å¯è§†åŒ–",
        "code": """import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

def interactive_time_series():
    \"\"\"åˆ›å»ºäº¤äº’å¼æ—¶é—´åºåˆ—å›¾è¡¨\"\"\"
    np.random.seed(42)
    dates = pd.date_range(start="2020-01-01", periods=365, freq="D")
    values = np.random.randn(365).cumsum()

    df = pd.DataFrame({"Date": dates, "Value": values})

    fig = px.line(df, x="Date", y="Value",
                  title="äº¤äº’å¼æ—¶é—´åºåˆ—å›¾è¡¨",
                  labels={"Date": "æ—¥æœŸ", "Value": "å€¼"},
                  hover_data={"Date": "|%Y-%m-%d", "Value": ":.2f"})

    fig.update_traces(line_color="blue", line_width=1.5)
    fig.update_layout(
        hovermode="x unified",
        xaxis=dict(showgrid=True, gridcolor="rgba(0,0,0,0.1)"),
        yaxis=dict(showgrid=True, gridcolor="rgba(0,0,0,0.1)")
    )

    fig.write_html("interactive_time_series.html")
    fig.show()

def interactive_candlestick():
    \"\"\"åˆ›å»ºäº¤äº’å¼Kçº¿å›¾\"\"\"
    np.random.seed(42)
    dates = pd.date_range(start="2020-01-01", periods=100, freq="D")
    open_price = 100 + np.random.randn(100).cumsum()
    high_price = open_price + np.random.rand(100) * 2
    low_price = open_price - np.random.rand(100) * 2
    close_price = open_price + np.random.randn(100)

    df = pd.DataFrame({
        "Date": dates,
        "Open": open_price,
        "High": high_price,
        "Low": low_price,
        "Close": close_price
    })

    fig = go.Figure(data=[go.Candlestick(x=df["Date"],
                open=df["Open"],
                high=df["High"],
                low=df["Low"],
                close=df["Close"])])

    fig.update_layout(
        title="äº¤äº’å¼Kçº¿å›¾",
        yaxis_title="ä»·æ ¼",
        xaxis_rangeslider_visible=False
    )

    fig.write_html("interactive_candlestick.html")
    fig.show()

def interactive_scatter_plot():
    \"\"\"åˆ›å»ºäº¤äº’å¼æ•£ç‚¹å›¾\"\"\"
    np.random.seed(42)
    x = np.random.rand(100)
    y = np.random.rand(100)
    size = 1000 * np.random.rand(100)
    color = np.random.rand(100)

    df = pd.DataFrame({"X": x, "Y": y, "Size": size, "Color": color})

    fig = px.scatter(df, x="X", y="Y", size="Size", color="Color",
                     title="äº¤äº’å¼æ•£ç‚¹å›¾",
                     labels={"X": "Xè½´", "Y": "Yè½´", "Size": "å¤§å°", "Color": "é¢œè‰²"},
                     size_max=30,
                     color_continuous_scale="viridis")

    fig.update_layout(
        hovermode="closest",
        xaxis=dict(showgrid=True, gridcolor="rgba(0,0,0,0.1)"),
        yaxis=dict(showgrid=True, gridcolor="rgba(0,0,0,0.1)")
    )

    fig.write_html("interactive_scatter.html")
    fig.show()

def interactive_heatmap():
    \"\"\"åˆ›å»ºäº¤äº’å¼çƒ­åŠ›å›¾\"\"\"
    np.random.seed(42)
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    dates = pd.date_range(start="2020-01-01", periods=5, freq="D")
    returns = np.random.randn(len(tickers), len(dates))

    df = pd.DataFrame(returns, index=tickers, columns=dates)

    fig = px.imshow(df,
                    x=dates,
                    y=tickers,
                    title="äº¤äº’å¼çƒ­åŠ›å›¾",
                    labels={"x": "æ—¥æœŸ", "y": "è‚¡ç¥¨ä»£ç ", "color": "æ”¶ç›Šç‡"},
                    color_continuous_scale="RdYlGn",
                    zmin=-2, zmax=2)

    fig.update_xaxes(tickangle=45)
    fig.update_layout(width=1000, height=600)

    fig.write_html("interactive_heatmap.html")
    fig.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("åˆ›å»ºäº¤äº’å¼æ—¶é—´åºåˆ—å›¾è¡¨")
    interactive_time_series()

    print("åˆ›å»ºäº¤äº’å¼Kçº¿å›¾")
    interactive_candlestick()

    print("åˆ›å»ºäº¤äº’å¼æ•£ç‚¹å›¾")
    interactive_scatter_plot()

    print("åˆ›å»ºäº¤äº’å¼çƒ­åŠ›å›¾")
    interactive_heatmap()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†äº¤äº’å¼æ•°æ®å¯è§†åŒ–æŠ€æœ¯ï¼Œä½¿ç”¨Plotlyåº“åˆ›å»ºäº†å¯äº¤äº’çš„å›¾è¡¨ï¼ŒåŒ…æ‹¬æ—¶é—´åºåˆ—ã€Kçº¿å›¾ã€æ•£ç‚¹å›¾å’Œçƒ­åŠ›å›¾ã€‚è¿™äº›å›¾è¡¨æ”¯æŒç¼©æ”¾ã€å¹³ç§»ã€æ‚¬åœç­‰äº¤äº’åŠŸèƒ½ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 4,
        "title": "é‡‘èæ•°æ®å¯è§†åŒ–æœ€ä½³å®è·µ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def choose_appropriate_chart():
    \"\"\"é€‰æ‹©åˆé€‚çš„å›¾è¡¨ç±»å‹\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial",
        "axes.labelsize": 14,
        "axes.titlesize": 16,
        "xtick.labelsize": 10,
        "ytick.labelsize": 10
    })

    np.random.seed(42)
    data = np.random.randn(1000)

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    axes[0, 0].hist(data, bins=30, alpha=0.7, density=True)
    axes[0, 0].set_title("ç›´æ–¹å›¾")
    axes[0, 0].set_xlabel("å€¼")
    axes[0, 0].set_ylabel("é¢‘ç‡")

    axes[0, 1].boxplot(data)
    axes[0, 1].set_title("ç®±çº¿å›¾")
    axes[0, 1].set_ylabel("å€¼")

    axes[1, 0].scatter(range(len(data)), data, alpha=0.3, s=2)
    axes[1, 0].set_title("æ•£ç‚¹å›¾")
    axes[1, 0].set_xlabel("ç´¢å¼•")
    axes[1, 0].set_ylabel("å€¼")

    sns.kdeplot(data, ax=axes[1, 1])
    axes[1, 1].set_title("æ ¸å¯†åº¦ä¼°è®¡")
    axes[1, 1].set_xlabel("å€¼")
    axes[1, 1].set_ylabel("å¯†åº¦")

    plt.tight_layout()
    plt.savefig("chart_comparison.png")
    plt.show()

def color_usage():
    \"\"\"é¢œè‰²ä½¿ç”¨æœ€ä½³å®è·µ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    np.random.seed(42)
    x = np.linspace(0, 10, 100)
    y1 = np.sin(x)
    y2 = np.cos(x)
    y3 = np.tan(x)

    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    axes[0].plot(x, y1, color="red", label="sin(x)", linewidth=2)
    axes[0].plot(x, y2, color="blue", label="cos(x)", linewidth=2)
    axes[0].plot(x, y3, color="green", label="tan(x)", linewidth=2)
    axes[0].set_title("ä¸è‰¯é¢œè‰²æ­é…")
    axes[0].legend()

    axes[1].plot(x, y1, color="#1f77b4", label="sin(x)", linewidth=2)
    axes[1].plot(x, y2, color="#ff7f0e", label="cos(x)", linewidth=2)
    axes[1].plot(x, y3, color="#2ca02c", label="tan(x)", linewidth=2)
    axes[1].set_title("è‰¯å¥½é¢œè‰²æ­é…")
    axes[1].legend()

    plt.tight_layout()
    plt.savefig("color_usage.png")
    plt.show()

def label_and_annotation():
    \"\"\"æ ‡ç­¾å’Œæ³¨é‡Šæœ€ä½³å®è·µ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    np.random.seed(42)
    dates = pd.date_range(start="2020-01-01", periods=365, freq="D")
    values = np.random.randn(365).cumsum()

    df = pd.DataFrame({"Date": dates, "Value": values})

    plt.figure(figsize=(12, 6))
    plt.plot(df["Date"], df["Value"], color="blue", linewidth=1.5)

    plt.title("é‡‘èæ—¶é—´åºåˆ—å›¾è¡¨ - æ ‡ç­¾å’Œæ³¨é‡Šç¤ºä¾‹")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("å€¼")
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    # æ·»åŠ é‡è¦ç‚¹çš„æ ‡ç­¾
    important_dates = [
        pd.Timestamp("2020-03-15"),
        pd.Timestamp("2020-06-30"),
        pd.Timestamp("2020-09-01")
    ]

    for date in important_dates:
        value = df.loc[df["Date"] == date, "Value"].iloc[0]
        plt.annotate(f"é‡è¦æ—¥æœŸ",
                    xy=(date, value),
                    xytext=(10, 10),
                    textcoords="offset points",
                    arrowprops=dict(arrowstyle="->", color="red"))

    plt.tight_layout()
    plt.savefig("annotation_example.png")
    plt.show()

def layout_optimization():
    \"\"\"å¸ƒå±€ä¼˜åŒ–æœ€ä½³å®è·µ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    np.random.seed(42)
    x = np.linspace(0, 10, 100)
    y1 = np.sin(x)
    y2 = np.cos(x)
    y3 = np.tan(x)

    fig = plt.figure(figsize=(12, 8))

    gs = fig.add_gridspec(2, 2)

    ax1 = fig.add_subplot(gs[0, :])
    ax1.plot(x, y1, color="#1f77b4", linewidth=2)
    ax1.set_title("sin(x)")

    ax2 = fig.add_subplot(gs[1, 0])
    ax2.plot(x, y2, color="#ff7f0e", linewidth=2)
    ax2.set_title("cos(x)")

    ax3 = fig.add_subplot(gs[1, 1])
    ax3.plot(x, y3, color="#2ca02c", linewidth=2)
    ax3.set_title("tan(x)")
    ax3.set_ylim(-10, 10)

    plt.tight_layout()
    plt.savefig("layout_optimization.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("å›¾è¡¨ç±»å‹é€‰æ‹©")
    choose_appropriate_chart()

    print("é¢œè‰²ä½¿ç”¨æœ€ä½³å®è·µ")
    color_usage()

    print("æ ‡ç­¾å’Œæ³¨é‡Šç¤ºä¾‹")
    label_and_annotation()

    print("å¸ƒå±€ä¼˜åŒ–æœ€ä½³å®è·µ")
    layout_optimization()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†é‡‘èæ•°æ®å¯è§†åŒ–çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬å›¾è¡¨ç±»å‹é€‰æ‹©ã€é¢œè‰²ä½¿ç”¨ã€æ ‡ç­¾å’Œæ³¨é‡Šã€å¸ƒå±€ä¼˜åŒ–ç­‰ã€‚éµå¾ªè¿™äº›æœ€ä½³å®è·µå¯ä»¥åˆ›å»ºå‡ºæ›´æ¸…æ™°ã€æ›´æœ‰æ•ˆçš„å¯è§†åŒ–å›¾è¡¨ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 5,
        "title": "æœºå™¨å­¦ä¹ ç»“æœå¯è§†åŒ–",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix

def data_reduction_visualization():
    \"\"\"æ•°æ®é™ç»´å¯è§†åŒ–\"\"\"
    np.random.seed(42)
    X = np.random.rand(100, 10)
    y = np.random.randint(0, 3, size=100)

    # ä½¿ç”¨PCAé™ç»´
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X)

    # ä½¿ç”¨t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42)
    X_tsne = tsne.fit_transform(X)

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap="viridis")
    plt.title("PCAé™ç»´å¯è§†åŒ–")
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.colorbar()

    plt.subplot(1, 2, 2)
    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap="viridis")
    plt.title("t-SNEé™ç»´å¯è§†åŒ–")
    plt.xlabel("Component 1")
    plt.ylabel("Component 2")
    plt.colorbar()

    plt.tight_layout()
    plt.savefig("dimensionality_reduction.png")
    plt.show()

def cluster_visualization():
    \"\"\"èšç±»ç»“æœå¯è§†åŒ–\"\"\"
    np.random.seed(42)
    X = np.random.rand(100, 2)
    y = np.random.randint(0, 3, size=100)

    # ä½¿ç”¨KMeansèšç±»
    kmeans = KMeans(n_clusters=3, random_state=42)
    y_pred = kmeans.fit_predict(X)

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap="viridis")
    plt.title("çœŸå®æ ‡ç­¾")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.colorbar()

    plt.subplot(1, 2, 2)
    plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap="viridis")
    plt.title("KMeansèšç±»ç»“æœ")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.colorbar()

    plt.tight_layout()
    plt.savefig("cluster_visualization.png")
    plt.show()

def feature_importance():
    \"\"\"ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–\"\"\"
    np.random.seed(42)
    X = np.random.rand(100, 10)
    y = np.random.randint(0, 2, size=100)

    # ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)

    # è·å–ç‰¹å¾é‡è¦æ€§
    feature_importances = clf.feature_importances_
    features = [f"Feature {i}" for i in range(10)]

    plt.figure(figsize=(10, 6))
    plt.barh(range(len(features)), feature_importances, color="#1f77b4")
    plt.yticks(range(len(features)), features)
    plt.title("ç‰¹å¾é‡è¦æ€§")
    plt.xlabel("é‡è¦æ€§")

    plt.tight_layout()
    plt.savefig("feature_importance.png")
    plt.show()

def confusion_matrix_visualization():
    \"\"\"æ··æ·†çŸ©é˜µå¯è§†åŒ–\"\"\"
    np.random.seed(42)
    y_true = np.random.randint(0, 3, size=100)
    y_pred = np.random.randint(0, 3, size=100)

    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, cmap="viridis")
    plt.title("æ··æ·†çŸ©é˜µ")
    plt.colorbar()

    # æ·»åŠ æ ‡ç­¾
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, cm[i, j], ha="center", va="center", color="white", fontsize=12)

    plt.xlabel("é¢„æµ‹æ ‡ç­¾")
    plt.ylabel("çœŸå®æ ‡ç­¾")

    plt.tight_layout()
    plt.savefig("confusion_matrix.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("æ•°æ®é™ç»´å¯è§†åŒ–")
    data_reduction_visualization()

    print("èšç±»ç»“æœå¯è§†åŒ–")
    cluster_visualization()

    print("ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–")
    feature_importance()

    print("æ··æ·†çŸ©é˜µå¯è§†åŒ–")
    confusion_matrix_visualization()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†æœºå™¨å­¦ä¹ ç»“æœçš„å¯è§†åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬æ•°æ®é™ç»´å¯è§†åŒ–ã€èšç±»ç»“æœå¯è§†åŒ–ã€ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–å’Œæ··æ·†çŸ©é˜µå¯è§†åŒ–ç­‰ã€‚è¿™äº›å¯è§†åŒ–æ–¹æ³•å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¡Œä¸ºå’Œæ€§èƒ½ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 6,
        "title": "é‡‘èæ•°æ®åˆ†æå¯è§†åŒ–å®æˆ˜",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf

def stock_price_analysis():
    \"\"\"è‚¡ç¥¨ä»·æ ¼åˆ†æ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    # è·å–è‹¹æœå…¬å¸è‚¡ç¥¨æ•°æ®
    apple = yf.Ticker("AAPL")
    df = apple.history(start="2020-01-01", end="2021-01-01")

    # æ•°æ®é¢„å¤„ç†
    df["Date"] = df.index
    df["Return"] = df["Close"].pct_change()
    df["Volatility"] = df["Return"].rolling(window=20).std() * np.sqrt(252)
    df["MA5"] = df["Close"].rolling(window=5).mean()
    df["MA20"] = df["Close"].rolling(window=20).mean()

    plt.figure(figsize=(12, 8))

    gs = plt.GridSpec(3, 1, height_ratios=[2, 1, 1])

    ax1 = plt.subplot(gs[0])
    ax1.plot(df["Date"], df["Close"], label="ä»·æ ¼", color="#1f77b4", linewidth=1.5)
    ax1.plot(df["Date"], df["MA5"], label="5æ—¥å‡çº¿", color="#ff7f0e", linewidth=1)
    ax1.plot(df["Date"], df["MA20"], label="20æ—¥å‡çº¿", color="#2ca02c", linewidth=1)
    ax1.set_title("è‹¹æœå…¬å¸è‚¡ç¥¨ä»·æ ¼åˆ†æ")
    ax1.legend(loc="upper left")

    ax2 = plt.subplot(gs[1])
    ax2.bar(df["Date"], df["Volume"], label="æˆäº¤é‡", color="#1f77b4")
    ax2.set_title("æˆäº¤é‡")
    ax2.set_ylabel("æˆäº¤é‡")

    ax3 = plt.subplot(gs[2])
    ax3.plot(df["Date"], df["Volatility"], label="æ³¢åŠ¨ç‡", color="#1f77b4")
    ax3.set_title("æ³¢åŠ¨ç‡")
    ax3.set_ylabel("æ³¢åŠ¨ç‡")

    plt.tight_layout()
    plt.savefig("stock_analysis.png")
    plt.show()

def portfolio_analysis():
    \"\"\"æŠ•èµ„ç»„åˆåˆ†æ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    # è·å–å‡ åªè‚¡ç¥¨çš„æ•°æ®
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    data = pd.DataFrame()

    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            df = stock.history(start="2020-01-01", end="2021-01-01")
            data[ticker] = df["Close"]
        except Exception as e:
            print(f"è·å–{ticker}æ•°æ®å¤±è´¥: {e}")

    # è®¡ç®—æŠ•èµ„ç»„åˆä»·å€¼
    weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2])
    returns = data.pct_change()

    # è®¡ç®—æŠ•èµ„ç»„åˆæ”¶ç›Šç‡å’Œé£é™©
    portfolio_return = (returns * weights).sum(axis=1)
    portfolio_value = 100000 * (1 + portfolio_return).cumprod()

    plt.figure(figsize=(12, 8))

    gs = plt.GridSpec(2, 2, height_ratios=[2, 1])

    ax1 = plt.subplot(gs[0, :])
    for ticker in tickers:
        ax1.plot(data.index, data[ticker]/data[ticker].iloc[0], label=ticker)
    ax1.plot(data.index, portfolio_value/portfolio_value.iloc[0], label="æŠ•èµ„ç»„åˆ", linewidth=2)
    ax1.set_title("æŠ•èµ„ç»„åˆåˆ†æ")
    ax1.legend(loc="upper left")

    ax2 = plt.subplot(gs[1, 0])
    sns.heatmap(returns.corr(), annot=True, cmap="RdYlGn", center=0)
    ax2.set_title("ç›¸å…³æ€§çŸ©é˜µ")

    ax3 = plt.subplot(gs[1, 1])
    ax3.scatter(returns.std() * np.sqrt(252), returns.mean() * 252, s=100, color="#1f77b4")

    for i, ticker in enumerate(tickers):
        ax3.annotate(ticker, (returns.std()[i] * np.sqrt(252), returns.mean()[i] * 252),
                    textcoords="offset points", xytext=(10, 5), fontsize=10)

    ax3.set_title("é£é™©æ”¶ç›Šåˆ†æ")
    ax3.set_xlabel("é£é™© (æ³¢åŠ¨ç‡)")
    ax3.set_ylabel("æ”¶ç›Š (å¹´åŒ–æ”¶ç›Šç‡)")

    plt.tight_layout()
    plt.savefig("portfolio_analysis.png")
    plt.show()

def risk_return_analysis():
    \"\"\"é£é™©æ”¶ç›Šåˆ†æ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    # è·å–å‡ åªè‚¡ç¥¨çš„æ•°æ®
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    data = pd.DataFrame()

    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            df = stock.history(start="2020-01-01", end="2021-01-01")
            data[ticker] = df["Close"]
        except Exception as e:
            print(f"è·å–{ticker}æ•°æ®å¤±è´¥: {e}")

    returns = data.pct_change()

    # è®¡ç®—é£é™©å’Œæ”¶ç›Š
    mean_returns = returns.mean() * 252
    std_returns = returns.std() * np.sqrt(252)

    plt.figure(figsize=(10, 6))
    plt.scatter(std_returns, mean_returns, s=100, color="#1f77b4")

    # æ·»åŠ æ ‡ç­¾
    for i, ticker in enumerate(tickers):
        plt.annotate(ticker, (std_returns[i], mean_returns[i]),
                    textcoords="offset points", xytext=(10, 5), fontsize=10)

    plt.title("é£é™©æ”¶ç›Šåˆ†æ")
    plt.xlabel("é£é™© (æ³¢åŠ¨ç‡)")
    plt.ylabel("æ”¶ç›Š (å¹´åŒ–æ”¶ç›Šç‡)")
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("risk_return.png")
    plt.show()

def correlation_analysis():
    \"\"\"ç›¸å…³æ€§åˆ†æ\"\"\"
    plt.rcParams.update({
        "font.size": 12,
        "font.family": "Arial"
    })

    # è·å–å‡ åªè‚¡ç¥¨çš„æ•°æ®
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    data = pd.DataFrame()

    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            df = stock.history(start="2020-01-01", end="2021-01-01")
            data[ticker] = df["Close"]
        except Exception as e:
            print(f"è·å–{ticker}æ•°æ®å¤±è´¥: {e}")

    returns = data.pct_change()

    plt.figure(figsize=(10, 8))
    sns.heatmap(returns.corr(), annot=True, cmap="RdYlGn", center=0, square=True)
    plt.title("è‚¡ç¥¨æ”¶ç›Šç‡ç›¸å…³æ€§")

    plt.tight_layout()
    plt.savefig("correlation_matrix.png")
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("è‚¡ç¥¨ä»·æ ¼åˆ†æ")
    stock_price_analysis()

    print("æŠ•èµ„ç»„åˆåˆ†æ")
    portfolio_analysis()

    print("é£é™©æ”¶ç›Šåˆ†æ")
    risk_return_analysis()

    print("ç›¸å…³æ€§åˆ†æ")
    correlation_analysis()
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†é‡‘èæ•°æ®åˆ†æå¯è§†åŒ–çš„å®æˆ˜æ¡ˆä¾‹ï¼ŒåŒ…æ‹¬è‚¡ç¥¨ä»·æ ¼åˆ†æã€æŠ•èµ„ç»„åˆåˆ†æã€é£é™©æ”¶ç›Šåˆ†æå’Œç›¸å…³æ€§åˆ†æã€‚è¿™äº›æ¡ˆä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¯è§†åŒ–æŠ€æœ¯å¸®åŠ©ç†è§£é‡‘èæ•°æ®å’Œåšå‡ºæŠ•èµ„å†³ç­–ã€‚"
    },
    {
        "topic_id": 10,
        "category_id": 6,
        "title": "å®Œæ•´çš„æ•°æ®å¯è§†åŒ–ç³»ç»Ÿ",
        "code": """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta

class FinancialVisualizationSystem:
    \"\"\"å®Œæ•´çš„é‡‘èæ•°æ®å¯è§†åŒ–ç³»ç»Ÿ\"\"\"

    def __init__(self):
        self.data = {}
        self.results = {}

    def fetch_data(self, tickers, start_date, end_date):
        \"\"\"è·å–æ•°æ®\"\"\"
        for ticker in tickers:
            try:
                stock = yf.Ticker(ticker)
                df = stock.history(start=start_date, end=end_date)
                self.data[ticker] = df
                print(f"æˆåŠŸè·å–{ticker}æ•°æ®")
            except Exception as e:
                print(f"è·å–{ticker}æ•°æ®å¤±è´¥: {e}")
                self.data[ticker] = pd.DataFrame()

    def preprocess_data(self):
        \"\"\"é¢„å¤„ç†æ•°æ®\"\"\"
        for ticker, df in self.data.items():
            if not df.empty:
                df["Date"] = df.index
                df["Return"] = df["Close"].pct_change()
                df["Volatility"] = df["Return"].rolling(window=20).std() * np.sqrt(252)
                df["MA5"] = df["Close"].rolling(window=5).mean()
                df["MA20"] = df["Close"].rolling(window=20).mean()

    def create_stock_plots(self):
        \"\"\"åˆ›å»ºè‚¡ç¥¨å›¾è¡¨\"\"\"
        for ticker, df in self.data.items():
            if not df.empty:
                plt.figure(figsize=(12, 8))

                gs = plt.GridSpec(3, 1, height_ratios=[2, 1, 1])

                ax1 = plt.subplot(gs[0])
                ax1.plot(df["Date"], df["Close"], label="ä»·æ ¼", color="#1f77b4", linewidth=1.5)
                ax1.plot(df["Date"], df["MA5"], label="5æ—¥å‡çº¿", color="#ff7f0e", linewidth=1)
                ax1.plot(df["Date"], df["MA20"], label="20æ—¥å‡çº¿", color="#2ca02c", linewidth=1)
                ax1.set_title(f"{ticker}è‚¡ç¥¨ä»·æ ¼åˆ†æ")
                ax1.legend(loc="upper left")

                ax2 = plt.subplot(gs[1])
                ax2.bar(df["Date"], df["Volume"], label="æˆäº¤é‡", color="#1f77b4")
                ax2.set_title("æˆäº¤é‡")
                ax2.set_ylabel("æˆäº¤é‡")

                ax3 = plt.subplot(gs[2])
                ax3.plot(df["Date"], df["Volatility"], label="æ³¢åŠ¨ç‡", color="#1f77b4")
                ax3.set_title("æ³¢åŠ¨ç‡")
                ax3.set_ylabel("æ³¢åŠ¨ç‡")

                plt.tight_layout()
                plt.savefig(f"{ticker}_analysis.png")
                plt.close()

                print(f"å·²ä¿å­˜{ticker}åˆ†æå›¾è¡¨")

    def create_portfolio_plots(self):
        \"\"\"åˆ›å»ºæŠ•èµ„ç»„åˆå›¾è¡¨\"\"\"
        tickers = list(self.data.keys())

        # å‡†å¤‡æ•°æ®
        returns = pd.DataFrame()

        for ticker in tickers:
            if not self.data[ticker].empty:
                returns[ticker] = self.data[ticker]["Return"]

        if len(returns.columns) > 0:
            # è®¡ç®—æŠ•èµ„ç»„åˆä»·å€¼
            weights = np.array([1/len(tickers) for _ in range(len(tickers))])
            portfolio_return = (returns * weights).sum(axis=1)
            initial_investment = 100000
            portfolio_value = initial_investment * (1 + portfolio_return).cumprod()

            # è®¡ç®—é£é™©å’Œæ”¶ç›Š
            mean_returns = returns.mean() * 252
            std_returns = returns.std() * np.sqrt(252)

            plt.figure(figsize=(12, 8))

            gs = plt.GridSpec(2, 2, height_ratios=[2, 1])

            ax1 = plt.subplot(gs[0, :])
            for ticker in tickers:
                if not self.data[ticker].empty:
                    ax1.plot(self.data[ticker]["Date"], self.data[ticker]["Close"]/self.data[ticker]["Close"].iloc[0],
                            label=ticker)
            ax1.plot(self.data[tickers[0]]["Date"], portfolio_value/portfolio_value.iloc[0],
                    label="æŠ•èµ„ç»„åˆ", linewidth=2)
            ax1.set_title("æŠ•èµ„ç»„åˆåˆ†æ")
            ax1.legend(loc="upper left")

            ax2 = plt.subplot(gs[1, 0])
            sns.heatmap(returns.corr(), annot=True, cmap="RdYlGn", center=0)
            ax2.set_title("ç›¸å…³æ€§çŸ©é˜µ")

            ax3 = plt.subplot(gs[1, 1])
            ax3.scatter(std_returns, mean_returns, s=100, color="#1f77b4")

            for i, ticker in enumerate(tickers):
                ax3.annotate(ticker, (std_returns[i], mean_returns[i]),
                            textcoords="offset points", xytext=(10, 5), fontsize=10)

            ax3.set_title("é£é™©æ”¶ç›Šåˆ†æ")
            ax3.set_xlabel("é£é™© (æ³¢åŠ¨ç‡)")
            ax3.set_ylabel("æ”¶ç›Š (å¹´åŒ–æ”¶ç›Šç‡)")

            plt.tight_layout()
            plt.savefig("portfolio_analysis.png")
            plt.close()

            print("å·²ä¿å­˜æŠ•èµ„ç»„åˆåˆ†æå›¾è¡¨")

    def create_summary_report(self):
        \"\"\"åˆ›å»ºæ±‡æ€»æŠ¥å‘Š\"\"\"
        if not self.data:
            print("æ— æ•°æ®å¯ç”ŸæˆæŠ¥å‘Š")
            return

        report = []

        report.append("# é‡‘èæ•°æ®å¯è§†åŒ–ç³»ç»ŸæŠ¥å‘Š")
        report.append("## æ•°æ®è·å–")
        report.append(f"- æ—¶é—´èŒƒå›´: {list(self.data.values())[0]['Date'].iloc[0].strftime('%Y-%m-%d')} è‡³ {list(self.data.values())[0]['Date'].iloc[-1].strftime('%Y-%m-%d')}")
        report.append(f"- è‚¡ç¥¨æ•°é‡: {len(self.data)}")

        report.append("## ä¸»è¦ç»“æœ")

        for ticker, df in self.data.items():
            if not df.empty:
                max_price = df["Close"].max()
                min_price = df["Close"].min()
                mean_volume = df["Volume"].mean()

                report.append(f"### {ticker}")
                report.append(f"- æœ€é«˜ä»·æ ¼: ${max_price:.2f}")
                report.append(f"- æœ€ä½ä»·æ ¼: ${min_price:.2f}")
                report.append(f"- å¹³å‡æˆäº¤é‡: {mean_volume:.0f}")

        # ä¿å­˜æŠ¥å‘Š
        with open("financial_report.md", "w", encoding="utf-8") as f:
            f.write("\n".join(report))

        print("å·²ç”ŸæˆæŠ¥å‘Š: financial_report.md")

    def run(self, tickers, start_date, end_date):
        \"\"\"è¿è¡Œæ•´ä¸ªç³»ç»Ÿ\"\"\"
        print("å¼€å§‹é‡‘èæ•°æ®å¯è§†åŒ–åˆ†æ")

        self.fetch_data(tickers, start_date, end_date)

        if any(df.empty for df in self.data.values()):
            print("æ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return

        self.preprocess_data()

        print("åˆ›å»ºè‚¡ç¥¨å›¾è¡¨")
        self.create_stock_plots()

        print("åˆ›å»ºæŠ•èµ„ç»„åˆå›¾è¡¨")
        self.create_portfolio_plots()

        print("åˆ›å»ºæ±‡æ€»æŠ¥å‘Š")
        self.create_summary_report()

        print("åˆ†æå®Œæˆ")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    system = FinancialVisualizationSystem()

    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
    end_date = datetime.now().strftime("%Y-%m-%d")

    system.run(tickers, start_date, end_date)
""",
        "explanation": "æ­¤ä»£ç æ¼”ç¤ºäº†å®Œæ•´çš„é‡‘èæ•°æ®å¯è§†åŒ–ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ•°æ®è·å–ã€é¢„å¤„ç†ã€å›¾è¡¨ç”Ÿæˆå’ŒæŠ¥å‘Šç”Ÿæˆã€‚è¯¥ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ¶æ„ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œæ‰©å±•å’Œæ”¹è¿›ã€‚"
    }
]

@app.route("/")
def index():
    return render_template("index.html", topics=FINANCIAL_TOPICS)

@app.route("/topic/<int:topic_id>")
def topic_detail(topic_id):
    topic = next((t for t in FINANCIAL_TOPICS if t["id"] == topic_id), None)
    if not topic:
        return "ä¸»é¢˜æœªæ‰¾åˆ°", 404
    return render_template("topic_detail.html", topic=topic, categories=TOPIC_CATEGORIES)

@app.route("/topic/<int:topic_id>/category/<int:category_id>")
def category_detail(topic_id, category_id):
    topic = next((t for t in FINANCIAL_TOPICS if t["id"] == topic_id), None)
    category = next((c for c in TOPIC_CATEGORIES if c["id"] == category_id), None)

    if not topic or not category:
        return "é¡µé¢æœªæ‰¾åˆ°", 404

    examples = [e for e in EXAMPLE_CODES if e["topic_id"] == topic_id and e["category_id"] == category_id]

    return render_template("category_detail.html", topic=topic, category=category, examples=examples)

if __name__ == "__main__":
    app.run(debug=True)
else:
    # For Vercel serverless deployment
    application = app
